{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin_Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim_1, hidden_dim_2, act_function):\n",
    "        super(Lin_Net, self).__init__()\n",
    "        self.act_function = act_function\n",
    "        \n",
    "        self.lin1 = nn.Linear(input_dim, hidden_dim_1)\n",
    "        self.lin2 = nn.Linear(hidden_dim_1, hidden_dim_2)\n",
    "        self.lin3 = nn.Linear(hidden_dim_2, hidden_dim_1)\n",
    "        self.lin4 = nn.Linear(hidden_dim_1, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # act_funtion = F.sigmoid oder F.relu\n",
    "        x = self.act_function(self.lin1(x))\n",
    "        x = self.act_function(self.lin2(x))\n",
    "        x = self.act_function(self.lin3(x))\n",
    "        x = self.lin4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(D.Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = torch.from_numpy(x_tensor)\n",
    "        self.y = torch.from_numpy(y_tensor)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(dataset, features, batch_size, debug=False):\n",
    "    datasets = []\n",
    "    for file in dataset:\n",
    "        datasets.append(\"../\" + pd.read_csv(file))\n",
    "    dataset = pd.concat(datasets, axis=0, ignore_index=True)\n",
    "    \n",
    "    target = dataset[\"affect\"]\n",
    "    dataset_full = dataset[[\"word_count\", \"upper_word_count\", \"ent_word_count\", \"h_count\", \"s_count\", \"a_count\", \"f_count\", \"cons_punct_count\"]]\n",
    "    dataset_nolex = dataset[[\"word_count\", \"upper_word_count\", \"ent_word_count\", \"cons_punct_count\"]]\n",
    "    dataset_lex = dataset[[\"h_count\", \"s_count\", \"a_count\", \"f_count\"]]\n",
    "    \n",
    "    # make train and test sets\n",
    "    if features == \"full\": \n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_full, target, test_size=0.2)\n",
    "    elif features == \"nolex\":\n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_nolex, target, test_size=0.2)\n",
    "    elif features == \"lex\": \n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_lex, target, test_size=0.2)\n",
    "\n",
    "    # make data loaders\n",
    "    train_data = MyDataset(train_x.to_numpy(), train_y.to_numpy())\n",
    "    test_data = MyDataset(test_x.to_numpy(), test_y.to_numpy())\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    \n",
    "    if debug: \n",
    "        dataset_full = dataset_full.iloc[:10]\n",
    "        target = target[:10]\n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_full, target, test_size=0.8)\n",
    "        train_data = MyDataset(train_x.to_numpy(), train_y.to_numpy())\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "        test_loader = DataLoader(dataset=train_data, batch_size=1)\n",
    "    return train_loader, test_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(summary, file):\n",
    "    log = open(file, \"a\")\n",
    "    log.write(summary)\n",
    "    log.close()\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, epochs, criterion, print_every, save_name, cuda, lr):\n",
    "    open(save_name + \"_train_log\", \"w\").close()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.5)\n",
    "    error_curve = []\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        for index, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.float(), targets.long()\n",
    "            if cuda: \n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "                net = net.cuda()\n",
    "            pred = net(inputs)\n",
    "            loss = criterion(pred.float(), targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if ((index) % print_every == 0):\n",
    "                log(\"batch: {}/{} in epoch {}/{} \\n... loss: {}\\n\".\n",
    "                    format((index+1), len(train_loader), (epoch+1), epochs, loss.item()), \n",
    "                    save_name + \"_train_log\")\n",
    "        # save network after every epoch\n",
    "        torch.save(net.state_dict(), save_name + \".pt\")  \n",
    "        # after every epoch save the error\n",
    "        error_curve.append([epoch, loss.item()])\n",
    "    log(\"\\n\" + str(error_curve), save_name + \"_train_log\")\n",
    "    return error_curve\n",
    "\n",
    "def test(test_loader, net, criterion, print_every, save_name, cuda):\n",
    "    open(save_name + \"_test_log\", \"w\").close()\n",
    "    confusion = []\n",
    "    net.eval()\n",
    "    loss_sum, correct, correct2 = 0, 0, 0\n",
    "    for index, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.float(), targets.long()\n",
    "        if cuda: \n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            net = net.cuda()\n",
    "        pred = net(inputs)\n",
    "        pred_class = torch.max(pred.data, 1)[1]\n",
    "        loss_sum += criterion(pred, targets).item()\n",
    "        confusion.append([targets.item(), pred_class.item()])\n",
    "        if pred_class.item() == targets.item(): \n",
    "            correct += 1\n",
    "        if ((index) % print_every == 0):\n",
    "            log(\"batch: {}/{}\\n... correct: {}\\n\".\n",
    "                format((index+1), len(test_loader), correct), \n",
    "                save_name + \"_test_log\")\n",
    "           \n",
    "    # give end report\n",
    "    log(\"average test loss: {}, relative correct: {}\\n\\nconfusion:\\n{}\".\n",
    "        format((loss_sum / len(test_loader)), (correct / len(test_loader)),str(confusion)), \n",
    "        save_name + \"test_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating variables\n",
      "creating datasets\n",
      "... done\n"
     ]
    }
   ],
   "source": [
    "# create variables \n",
    "print(\"creating variables\")\n",
    "emotion_dataset = [\"emotion_classification_1_clean.csv\", \"emotion_classification_2_clean.csv\", \"emotion_classification_3_clean.csv\", \"emotion_classification_4_clean.csv\", \"emotion_classification_5_clean.csv\", \"emotion_classification_6_clean.csv\", \"emotion_classification_7_clean.csv\", \"emotion_classification_8_clean.csv\"]\n",
    "tweet_dataset = [\"crowdflower_clean.csv\", \"emoint_clean.csv\", \"tec_clean.csv\"]\n",
    "act_function = torch.sigmoid\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# create datasets\n",
    "print(\"creating datasets\")\n",
    "train_loader_emotion_full, test_loader_emotion_full = make_data(emotion_dataset, \"full\", 25)\n",
    "train_loader_emotion_nolex, test_loader_emotion_nolex = make_data(emotion_dataset, \"nolex\", 25)\n",
    "train_loader_emotion_lex, test_loader_emotion_lex = make_data(emotion_dataset, \"lex\", 25)\n",
    "train_loader_tweet_full, test_loader_tweet_full = make_data(tweet_dataset, \"full\", 25)\n",
    "train_loader_tweet_nolex, test_loader_tweet_nolex = make_data(tweet_dataset, \"nolex\", 25)\n",
    "train_loader_tweet_lex, test_loader_tweet_lex = make_data(tweet_dataset, \"lex\", 25)\n",
    "train_loader_debug, test_loader_debug = make_data(emotion_dataset, \"full\", 25, True)\n",
    "print(\"... done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- net_lin_emotion_full\n",
      "(tensor([[6.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [3.3000e+01, 0.0000e+00, 3.0000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]], dtype=torch.float64), tensor([0, 1]))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 1/1000 \n",
      "... loss: 1.3776636123657227\n",
      "\n",
      "batch: 1/1 in epoch 2/1000 \n",
      "... loss: 1.2420530319213867\n",
      "\n",
      "batch: 1/1 in epoch 3/1000 \n",
      "... loss: 1.0579910278320312\n",
      "\n",
      "batch: 1/1 in epoch 4/1000 \n",
      "... loss: 0.8742104172706604\n",
      "\n",
      "batch: 1/1 in epoch 5/1000 \n",
      "... loss: 0.7135658264160156\n",
      "\n",
      "batch: 1/1 in epoch 6/1000 \n",
      "... loss: 0.582996129989624\n",
      "\n",
      "batch: 1/1 in epoch 7/1000 \n",
      "... loss: 0.4809767007827759\n",
      "\n",
      "batch: 1/1 in epoch 8/1000 \n",
      "... loss: 0.4026193618774414\n",
      "\n",
      "batch: 1/1 in epoch 9/1000 \n",
      "... loss: 0.3425494432449341\n",
      "\n",
      "batch: 1/1 in epoch 10/1000 \n",
      "... loss: 0.29613444209098816\n",
      "\n",
      "batch: 1/1 in epoch 11/1000 \n",
      "... loss: 0.2597839832305908\n",
      "\n",
      "batch: 1/1 in epoch 12/1000 \n",
      "... loss: 0.23085461556911469\n",
      "\n",
      "batch: 1/1 in epoch 13/1000 \n",
      "... loss: 0.20744377374649048\n",
      "\n",
      "batch: 1/1 in epoch 14/1000 \n",
      "... loss: 0.1881902515888214\n",
      "\n",
      "batch: 1/1 in epoch 15/1000 \n",
      "... loss: 0.17211714386940002\n",
      "\n",
      "batch: 1/1 in epoch 16/1000 \n",
      "... loss: 0.15851622819900513\n",
      "\n",
      "batch: 1/1 in epoch 17/1000 \n",
      "... loss: 0.14686760306358337\n",
      "\n",
      "batch: 1/1 in epoch 18/1000 \n",
      "... loss: 0.13678394258022308\n",
      "\n",
      "batch: 1/1 in epoch 19/1000 \n",
      "... loss: 0.1279723048210144\n",
      "\n",
      "batch: 1/1 in epoch 20/1000 \n",
      "... loss: 0.12020787596702576\n",
      "\n",
      "batch: 1/1 in epoch 21/1000 \n",
      "... loss: 0.11331532895565033\n",
      "\n",
      "batch: 1/1 in epoch 22/1000 \n",
      "... loss: 0.10715645551681519\n",
      "\n",
      "batch: 1/1 in epoch 23/1000 \n",
      "... loss: 0.10162036865949631\n",
      "\n",
      "batch: 1/1 in epoch 24/1000 \n",
      "... loss: 0.09661777317523956\n",
      "\n",
      "batch: 1/1 in epoch 25/1000 \n",
      "... loss: 0.09207554161548615\n",
      "\n",
      "batch: 1/1 in epoch 26/1000 \n",
      "... loss: 0.08793331682682037\n",
      "\n",
      "batch: 1/1 in epoch 27/1000 \n",
      "... loss: 0.08414061367511749\n",
      "\n",
      "batch: 1/1 in epoch 28/1000 \n",
      "... loss: 0.0806553065776825\n",
      "\n",
      "batch: 1/1 in epoch 29/1000 \n",
      "... loss: 0.07744182646274567\n",
      "\n",
      "batch: 1/1 in epoch 30/1000 \n",
      "... loss: 0.07446970045566559\n",
      "\n",
      "batch: 1/1 in epoch 31/1000 \n",
      "... loss: 0.07171282917261124\n",
      "\n",
      "batch: 1/1 in epoch 32/1000 \n",
      "... loss: 0.06914886832237244\n",
      "\n",
      "batch: 1/1 in epoch 33/1000 \n",
      "... loss: 0.06675848364830017\n",
      "\n",
      "batch: 1/1 in epoch 34/1000 \n",
      "... loss: 0.06452459841966629\n",
      "\n",
      "batch: 1/1 in epoch 35/1000 \n",
      "... loss: 0.06243255361914635\n",
      "\n",
      "batch: 1/1 in epoch 36/1000 \n",
      "... loss: 0.06046926975250244\n",
      "\n",
      "batch: 1/1 in epoch 37/1000 \n",
      "... loss: 0.05862332507967949\n",
      "\n",
      "batch: 1/1 in epoch 38/1000 \n",
      "... loss: 0.056884560734033585\n",
      "\n",
      "batch: 1/1 in epoch 39/1000 \n",
      "... loss: 0.05524395778775215\n",
      "\n",
      "batch: 1/1 in epoch 40/1000 \n",
      "... loss: 0.05369347333908081\n",
      "\n",
      "batch: 1/1 in epoch 41/1000 \n",
      "... loss: 0.05222600698471069\n",
      "\n",
      "batch: 1/1 in epoch 42/1000 \n",
      "... loss: 0.05083507299423218\n",
      "\n",
      "batch: 1/1 in epoch 43/1000 \n",
      "... loss: 0.04951487481594086\n",
      "\n",
      "batch: 1/1 in epoch 44/1000 \n",
      "... loss: 0.048260290175676346\n",
      "\n",
      "batch: 1/1 in epoch 45/1000 \n",
      "... loss: 0.047066397964954376\n",
      "\n",
      "batch: 1/1 in epoch 46/1000 \n",
      "... loss: 0.04592909291386604\n",
      "\n",
      "batch: 1/1 in epoch 47/1000 \n",
      "... loss: 0.04484429210424423\n",
      "\n",
      "batch: 1/1 in epoch 48/1000 \n",
      "... loss: 0.0438084602355957\n",
      "\n",
      "batch: 1/1 in epoch 49/1000 \n",
      "... loss: 0.04281872510910034\n",
      "\n",
      "batch: 1/1 in epoch 50/1000 \n",
      "... loss: 0.041871801018714905\n",
      "\n",
      "batch: 1/1 in epoch 51/1000 \n",
      "... loss: 0.0409649983048439\n",
      "\n",
      "batch: 1/1 in epoch 52/1000 \n",
      "... loss: 0.04009585082530975\n",
      "\n",
      "batch: 1/1 in epoch 53/1000 \n",
      "... loss: 0.03926216810941696\n",
      "\n",
      "batch: 1/1 in epoch 54/1000 \n",
      "... loss: 0.03846180438995361\n",
      "\n",
      "batch: 1/1 in epoch 55/1000 \n",
      "... loss: 0.037692710757255554\n",
      "\n",
      "batch: 1/1 in epoch 56/1000 \n",
      "... loss: 0.03695324435830116\n",
      "\n",
      "batch: 1/1 in epoch 57/1000 \n",
      "... loss: 0.0362415686249733\n",
      "\n",
      "batch: 1/1 in epoch 58/1000 \n",
      "... loss: 0.035556480288505554\n",
      "\n",
      "batch: 1/1 in epoch 59/1000 \n",
      "... loss: 0.03489607572555542\n",
      "\n",
      "batch: 1/1 in epoch 60/1000 \n",
      "... loss: 0.034259483218193054\n",
      "\n",
      "batch: 1/1 in epoch 61/1000 \n",
      "... loss: 0.03364507853984833\n",
      "\n",
      "batch: 1/1 in epoch 62/1000 \n",
      "... loss: 0.03305209428071976\n",
      "\n",
      "batch: 1/1 in epoch 63/1000 \n",
      "... loss: 0.0324791818857193\n",
      "\n",
      "batch: 1/1 in epoch 64/1000 \n",
      "... loss: 0.03192534297704697\n",
      "\n",
      "batch: 1/1 in epoch 65/1000 \n",
      "... loss: 0.031389735639095306\n",
      "\n",
      "batch: 1/1 in epoch 66/1000 \n",
      "... loss: 0.03087141364812851\n",
      "\n",
      "batch: 1/1 in epoch 67/1000 \n",
      "... loss: 0.030369646847248077\n",
      "\n",
      "batch: 1/1 in epoch 68/1000 \n",
      "... loss: 0.029883652925491333\n",
      "\n",
      "batch: 1/1 in epoch 69/1000 \n",
      "... loss: 0.0294126458466053\n",
      "\n",
      "batch: 1/1 in epoch 70/1000 \n",
      "... loss: 0.028956007212400436\n",
      "\n",
      "batch: 1/1 in epoch 71/1000 \n",
      "... loss: 0.028513005003333092\n",
      "\n",
      "batch: 1/1 in epoch 72/1000 \n",
      "... loss: 0.028083136305212975\n",
      "\n",
      "batch: 1/1 in epoch 73/1000 \n",
      "... loss: 0.027665723115205765\n",
      "\n",
      "batch: 1/1 in epoch 74/1000 \n",
      "... loss: 0.027260370552539825\n",
      "\n",
      "batch: 1/1 in epoch 75/1000 \n",
      "... loss: 0.02686646208167076\n",
      "\n",
      "batch: 1/1 in epoch 76/1000 \n",
      "... loss: 0.026483483612537384\n",
      "\n",
      "batch: 1/1 in epoch 77/1000 \n",
      "... loss: 0.026111219078302383\n",
      "\n",
      "batch: 1/1 in epoch 78/1000 \n",
      "... loss: 0.025748923420906067\n",
      "\n",
      "batch: 1/1 in epoch 79/1000 \n",
      "... loss: 0.025396432727575302\n",
      "\n",
      "batch: 1/1 in epoch 80/1000 \n",
      "... loss: 0.025053292512893677\n",
      "\n",
      "batch: 1/1 in epoch 81/1000 \n",
      "... loss: 0.02471904642879963\n",
      "\n",
      "batch: 1/1 in epoch 82/1000 \n",
      "... loss: 0.02439347468316555\n",
      "\n",
      "batch: 1/1 in epoch 83/1000 \n",
      "... loss: 0.024076290428638458\n",
      "\n",
      "batch: 1/1 in epoch 84/1000 \n",
      "... loss: 0.02376692183315754\n",
      "\n",
      "batch: 1/1 in epoch 85/1000 \n",
      "... loss: 0.023465316742658615\n",
      "\n",
      "batch: 1/1 in epoch 86/1000 \n",
      "... loss: 0.02317119389772415\n",
      "\n",
      "batch: 1/1 in epoch 87/1000 \n",
      "... loss: 0.022884149104356766\n",
      "\n",
      "batch: 1/1 in epoch 88/1000 \n",
      "... loss: 0.022604014724493027\n",
      "\n",
      "batch: 1/1 in epoch 89/1000 \n",
      "... loss: 0.022330446168780327\n",
      "\n",
      "batch: 1/1 in epoch 90/1000 \n",
      "... loss: 0.02206333354115486\n",
      "\n",
      "batch: 1/1 in epoch 91/1000 \n",
      "... loss: 0.0218025054782629\n",
      "\n",
      "batch: 1/1 in epoch 92/1000 \n",
      "... loss: 0.021547500044107437\n",
      "\n",
      "batch: 1/1 in epoch 93/1000 \n",
      "... loss: 0.021298326551914215\n",
      "\n",
      "batch: 1/1 in epoch 94/1000 \n",
      "... loss: 0.021054863929748535\n",
      "\n",
      "batch: 1/1 in epoch 95/1000 \n",
      "... loss: 0.02081659995019436\n",
      "\n",
      "batch: 1/1 in epoch 96/1000 \n",
      "... loss: 0.020583707839250565\n",
      "\n",
      "batch: 1/1 in epoch 97/1000 \n",
      "... loss: 0.020355960354208946\n",
      "\n",
      "batch: 1/1 in epoch 98/1000 \n",
      "... loss: 0.02013283222913742\n",
      "\n",
      "batch: 1/1 in epoch 99/1000 \n",
      "... loss: 0.019914623349905014\n",
      "\n",
      "batch: 1/1 in epoch 100/1000 \n",
      "... loss: 0.01970098167657852\n",
      "\n",
      "batch: 1/1 in epoch 101/1000 \n",
      "... loss: 0.019491679966449738\n",
      "\n",
      "batch: 1/1 in epoch 102/1000 \n",
      "... loss: 0.019286837428808212\n",
      "\n",
      "batch: 1/1 in epoch 103/1000 \n",
      "... loss: 0.01908610202372074\n",
      "\n",
      "batch: 1/1 in epoch 104/1000 \n",
      "... loss: 0.018889421597123146\n",
      "\n",
      "batch: 1/1 in epoch 105/1000 \n",
      "... loss: 0.018696680665016174\n",
      "\n",
      "batch: 1/1 in epoch 106/1000 \n",
      "... loss: 0.018507765606045723\n",
      "\n",
      "batch: 1/1 in epoch 107/1000 \n",
      "... loss: 0.018322616815567017\n",
      "\n",
      "batch: 1/1 in epoch 108/1000 \n",
      "... loss: 0.0181410051882267\n",
      "\n",
      "batch: 1/1 in epoch 109/1000 \n",
      "... loss: 0.01796281524002552\n",
      "\n",
      "batch: 1/1 in epoch 110/1000 \n",
      "... loss: 0.017788104712963104\n",
      "\n",
      "batch: 1/1 in epoch 111/1000 \n",
      "... loss: 0.01761670410633087\n",
      "\n",
      "batch: 1/1 in epoch 112/1000 \n",
      "... loss: 0.017448436468839645\n",
      "\n",
      "batch: 1/1 in epoch 113/1000 \n",
      "... loss: 0.0172833614051342\n",
      "\n",
      "batch: 1/1 in epoch 114/1000 \n",
      "... loss: 0.017121247947216034\n",
      "\n",
      "batch: 1/1 in epoch 115/1000 \n",
      "... loss: 0.016962215304374695\n",
      "\n",
      "batch: 1/1 in epoch 116/1000 \n",
      "... loss: 0.016805969178676605\n",
      "\n",
      "batch: 1/1 in epoch 117/1000 \n",
      "... loss: 0.01665257290005684\n",
      "\n",
      "batch: 1/1 in epoch 118/1000 \n",
      "... loss: 0.016501788049936295\n",
      "\n",
      "batch: 1/1 in epoch 119/1000 \n",
      "... loss: 0.01635373942553997\n",
      "\n",
      "batch: 1/1 in epoch 120/1000 \n",
      "... loss: 0.01620824821293354\n",
      "\n",
      "batch: 1/1 in epoch 121/1000 \n",
      "... loss: 0.016065258532762527\n",
      "\n",
      "batch: 1/1 in epoch 122/1000 \n",
      "... loss: 0.015924770385026932\n",
      "\n",
      "batch: 1/1 in epoch 123/1000 \n",
      "... loss: 0.015786610543727875\n",
      "\n",
      "batch: 1/1 in epoch 124/1000 \n",
      "... loss: 0.015650834888219833\n",
      "\n",
      "batch: 1/1 in epoch 125/1000 \n",
      "... loss: 0.015517331659793854\n",
      "\n",
      "batch: 1/1 in epoch 126/1000 \n",
      "... loss: 0.01538598258048296\n",
      "\n",
      "batch: 1/1 in epoch 127/1000 \n",
      "... loss: 0.015256786718964577\n",
      "\n",
      "batch: 1/1 in epoch 128/1000 \n",
      "... loss: 0.015129806473851204\n",
      "\n",
      "batch: 1/1 in epoch 129/1000 \n",
      "... loss: 0.01500486396253109\n",
      "\n",
      "batch: 1/1 in epoch 130/1000 \n",
      "... loss: 0.014881845563650131\n",
      "\n",
      "batch: 1/1 in epoch 131/1000 \n",
      "... loss: 0.014760807156562805\n",
      "\n",
      "batch: 1/1 in epoch 132/1000 \n",
      "... loss: 0.014641692861914635\n",
      "\n",
      "batch: 1/1 in epoch 133/1000 \n",
      "... loss: 0.014524385333061218\n",
      "\n",
      "batch: 1/1 in epoch 134/1000 \n",
      "... loss: 0.014409061521291733\n",
      "\n",
      "batch: 1/1 in epoch 135/1000 \n",
      "... loss: 0.014295371249318123\n",
      "\n",
      "batch: 1/1 in epoch 136/1000 \n",
      "... loss: 0.014183547347784042\n",
      "\n",
      "batch: 1/1 in epoch 137/1000 \n",
      "... loss: 0.014073297381401062\n",
      "\n",
      "batch: 1/1 in epoch 138/1000 \n",
      "... loss: 0.013964798301458359\n",
      "\n",
      "batch: 1/1 in epoch 139/1000 \n",
      "... loss: 0.01385793462395668\n",
      "\n",
      "batch: 1/1 in epoch 140/1000 \n",
      "... loss: 0.013752587139606476\n",
      "\n",
      "batch: 1/1 in epoch 141/1000 \n",
      "... loss: 0.013648875057697296\n",
      "\n",
      "batch: 1/1 in epoch 142/1000 \n",
      "... loss: 0.013546681962907314\n",
      "\n",
      "batch: 1/1 in epoch 143/1000 \n",
      "... loss: 0.013445889577269554\n",
      "\n",
      "batch: 1/1 in epoch 144/1000 \n",
      "... loss: 0.013346615247428417\n",
      "\n",
      "batch: 1/1 in epoch 145/1000 \n",
      "... loss: 0.013248860836029053\n",
      "\n",
      "batch: 1/1 in epoch 146/1000 \n",
      "... loss: 0.013152332976460457\n",
      "\n",
      "batch: 1/1 in epoch 147/1000 \n",
      "... loss: 0.013057323172688484\n",
      "\n",
      "batch: 1/1 in epoch 148/1000 \n",
      "... loss: 0.01296360045671463\n",
      "\n",
      "batch: 1/1 in epoch 149/1000 \n",
      "... loss: 0.01287110522389412\n",
      "\n",
      "batch: 1/1 in epoch 150/1000 \n",
      "... loss: 0.01278001256287098\n",
      "\n",
      "batch: 1/1 in epoch 151/1000 \n",
      "... loss: 0.012690089643001556\n",
      "\n",
      "batch: 1/1 in epoch 152/1000 \n",
      "... loss: 0.012601394206285477\n",
      "\n",
      "batch: 1/1 in epoch 153/1000 \n",
      "... loss: 0.012513985857367516\n",
      "\n",
      "batch: 1/1 in epoch 154/1000 \n",
      "... loss: 0.012427687644958496\n",
      "\n",
      "batch: 1/1 in epoch 155/1000 \n",
      "... loss: 0.012342561036348343\n",
      "\n",
      "batch: 1/1 in epoch 156/1000 \n",
      "... loss: 0.012258604168891907\n",
      "\n",
      "batch: 1/1 in epoch 157/1000 \n",
      "... loss: 0.012175758369266987\n",
      "\n",
      "batch: 1/1 in epoch 158/1000 \n",
      "... loss: 0.012093907222151756\n",
      "\n",
      "batch: 1/1 in epoch 159/1000 \n",
      "... loss: 0.012013226747512817\n",
      "\n",
      "batch: 1/1 in epoch 160/1000 \n",
      "... loss: 0.011933600530028343\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 161/1000 \n",
      "... loss: 0.011855028569698334\n",
      "\n",
      "batch: 1/1 in epoch 162/1000 \n",
      "... loss: 0.011777333915233612\n",
      "\n",
      "batch: 1/1 in epoch 163/1000 \n",
      "... loss: 0.01170063391327858\n",
      "\n",
      "batch: 1/1 in epoch 164/1000 \n",
      "... loss: 0.011624989099800587\n",
      "\n",
      "batch: 1/1 in epoch 165/1000 \n",
      "... loss: 0.011550339870154858\n",
      "\n",
      "batch: 1/1 in epoch 166/1000 \n",
      "... loss: 0.011476568877696991\n",
      "\n",
      "batch: 1/1 in epoch 167/1000 \n",
      "... loss: 0.011403735727071762\n",
      "\n",
      "batch: 1/1 in epoch 168/1000 \n",
      "... loss: 0.011331722140312195\n",
      "\n",
      "batch: 1/1 in epoch 169/1000 \n",
      "... loss: 0.011260705068707466\n",
      "\n",
      "batch: 1/1 in epoch 170/1000 \n",
      "... loss: 0.011190509423613548\n",
      "\n",
      "batch: 1/1 in epoch 171/1000 \n",
      "... loss: 0.011121073737740517\n",
      "\n",
      "batch: 1/1 in epoch 172/1000 \n",
      "... loss: 0.011052576825022697\n",
      "\n",
      "batch: 1/1 in epoch 173/1000 \n",
      "... loss: 0.01098489947617054\n",
      "\n",
      "batch: 1/1 in epoch 174/1000 \n",
      "... loss: 0.010918045416474342\n",
      "\n",
      "batch: 1/1 in epoch 175/1000 \n",
      "... loss: 0.010852009989321232\n",
      "\n",
      "batch: 1/1 in epoch 176/1000 \n",
      "... loss: 0.01078661996871233\n",
      "\n",
      "batch: 1/1 in epoch 177/1000 \n",
      "... loss: 0.01072211004793644\n",
      "\n",
      "batch: 1/1 in epoch 178/1000 \n",
      "... loss: 0.010658244602382183\n",
      "\n",
      "batch: 1/1 in epoch 179/1000 \n",
      "... loss: 0.010595260187983513\n",
      "\n",
      "batch: 1/1 in epoch 180/1000 \n",
      "... loss: 0.010532919317483902\n",
      "\n",
      "batch: 1/1 in epoch 181/1000 \n",
      "... loss: 0.010471401736140251\n",
      "\n",
      "batch: 1/1 in epoch 182/1000 \n",
      "... loss: 0.010410410352051258\n",
      "\n",
      "batch: 1/1 in epoch 183/1000 \n",
      "... loss: 0.010350299999117851\n",
      "\n",
      "batch: 1/1 in epoch 184/1000 \n",
      "... loss: 0.01029065903276205\n",
      "\n",
      "batch: 1/1 in epoch 185/1000 \n",
      "... loss: 0.01023172214627266\n",
      "\n",
      "batch: 1/1 in epoch 186/1000 \n",
      "... loss: 0.010173607617616653\n",
      "\n",
      "batch: 1/1 in epoch 187/1000 \n",
      "... loss: 0.01011602021753788\n",
      "\n",
      "batch: 1/1 in epoch 188/1000 \n",
      "... loss: 0.010059019550681114\n",
      "\n",
      "batch: 1/1 in epoch 189/1000 \n",
      "... loss: 0.010002784430980682\n",
      "\n",
      "batch: 1/1 in epoch 190/1000 \n",
      "... loss: 0.009947016835212708\n",
      "\n",
      "batch: 1/1 in epoch 191/1000 \n",
      "... loss: 0.009892072528600693\n",
      "\n",
      "batch: 1/1 in epoch 192/1000 \n",
      "... loss: 0.009837479330599308\n",
      "\n",
      "batch: 1/1 in epoch 193/1000 \n",
      "... loss: 0.009783592075109482\n",
      "\n",
      "batch: 1/1 in epoch 194/1000 \n",
      "... loss: 0.009730173274874687\n",
      "\n",
      "batch: 1/1 in epoch 195/1000 \n",
      "... loss: 0.009677400812506676\n",
      "\n",
      "batch: 1/1 in epoch 196/1000 \n",
      "... loss: 0.009625334292650223\n",
      "\n",
      "batch: 1/1 in epoch 197/1000 \n",
      "... loss: 0.009573619812726974\n",
      "\n",
      "batch: 1/1 in epoch 198/1000 \n",
      "... loss: 0.009522492997348309\n",
      "\n",
      "batch: 1/1 in epoch 199/1000 \n",
      "... loss: 0.00947195291519165\n",
      "\n",
      "batch: 1/1 in epoch 200/1000 \n",
      "... loss: 0.009421765804290771\n",
      "\n",
      "batch: 1/1 in epoch 201/1000 \n",
      "... loss: 0.009372225031256676\n",
      "\n",
      "batch: 1/1 in epoch 202/1000 \n",
      "... loss: 0.009323213249444962\n",
      "\n",
      "batch: 1/1 in epoch 203/1000 \n",
      "... loss: 0.009274671785533428\n",
      "\n",
      "batch: 1/1 in epoch 204/1000 \n",
      "... loss: 0.009226659312844276\n",
      "\n",
      "batch: 1/1 in epoch 205/1000 \n",
      "... loss: 0.009179058484733105\n",
      "\n",
      "batch: 1/1 in epoch 206/1000 \n",
      "... loss: 0.00913192704319954\n",
      "\n",
      "batch: 1/1 in epoch 207/1000 \n",
      "... loss: 0.009085385128855705\n",
      "\n",
      "batch: 1/1 in epoch 208/1000 \n",
      "... loss: 0.009039253927767277\n",
      "\n",
      "batch: 1/1 in epoch 209/1000 \n",
      "... loss: 0.008993592113256454\n",
      "\n",
      "batch: 1/1 in epoch 210/1000 \n",
      "... loss: 0.008948284201323986\n",
      "\n",
      "batch: 1/1 in epoch 211/1000 \n",
      "... loss: 0.008903564885258675\n",
      "\n",
      "batch: 1/1 in epoch 212/1000 \n",
      "... loss: 0.008859196677803993\n",
      "\n",
      "batch: 1/1 in epoch 213/1000 \n",
      "... loss: 0.008815182372927666\n",
      "\n",
      "batch: 1/1 in epoch 214/1000 \n",
      "... loss: 0.008771639317274094\n",
      "\n",
      "batch: 1/1 in epoch 215/1000 \n",
      "... loss: 0.00872868299484253\n",
      "\n",
      "batch: 1/1 in epoch 216/1000 \n",
      "... loss: 0.008686021901667118\n",
      "\n",
      "batch: 1/1 in epoch 217/1000 \n",
      "... loss: 0.008643712848424911\n",
      "\n",
      "batch: 1/1 in epoch 218/1000 \n",
      "... loss: 0.00860181637108326\n",
      "\n",
      "batch: 1/1 in epoch 219/1000 \n",
      "... loss: 0.008560331538319588\n",
      "\n",
      "batch: 1/1 in epoch 220/1000 \n",
      "... loss: 0.008519317954778671\n",
      "\n",
      "batch: 1/1 in epoch 221/1000 \n",
      "... loss: 0.00847865641117096\n",
      "\n",
      "batch: 1/1 in epoch 222/1000 \n",
      "... loss: 0.008438289165496826\n",
      "\n",
      "batch: 1/1 in epoch 223/1000 \n",
      "... loss: 0.008398334495723248\n",
      "\n",
      "batch: 1/1 in epoch 224/1000 \n",
      "... loss: 0.008358791470527649\n",
      "\n",
      "batch: 1/1 in epoch 225/1000 \n",
      "... loss: 0.008319542743265629\n",
      "\n",
      "batch: 1/1 in epoch 226/1000 \n",
      "... loss: 0.008280705660581589\n",
      "\n",
      "batch: 1/1 in epoch 227/1000 \n",
      "... loss: 0.008242163807153702\n",
      "\n",
      "batch: 1/1 in epoch 228/1000 \n",
      "... loss: 0.008204033598303795\n",
      "\n",
      "batch: 1/1 in epoch 229/1000 \n",
      "... loss: 0.008166197687387466\n",
      "\n",
      "batch: 1/1 in epoch 230/1000 \n",
      "... loss: 0.008128715679049492\n",
      "\n",
      "batch: 1/1 in epoch 231/1000 \n",
      "... loss: 0.008091645315289497\n",
      "\n",
      "batch: 1/1 in epoch 232/1000 \n",
      "... loss: 0.008054869249463081\n",
      "\n",
      "batch: 1/1 in epoch 233/1000 \n",
      "... loss: 0.008018387481570244\n",
      "\n",
      "batch: 1/1 in epoch 234/1000 \n",
      "... loss: 0.007982200011610985\n",
      "\n",
      "batch: 1/1 in epoch 235/1000 \n",
      "... loss: 0.00794642511755228\n",
      "\n",
      "batch: 1/1 in epoch 236/1000 \n",
      "... loss: 0.007910944521427155\n",
      "\n",
      "batch: 1/1 in epoch 237/1000 \n",
      "... loss: 0.007875639945268631\n",
      "\n",
      "batch: 1/1 in epoch 238/1000 \n",
      "... loss: 0.007840808480978012\n",
      "\n",
      "batch: 1/1 in epoch 239/1000 \n",
      "... loss: 0.007806151639670134\n",
      "\n",
      "batch: 1/1 in epoch 240/1000 \n",
      "... loss: 0.007771849632263184\n",
      "\n",
      "batch: 1/1 in epoch 241/1000 \n",
      "... loss: 0.0077379010617733\n",
      "\n",
      "batch: 1/1 in epoch 242/1000 \n",
      "... loss: 0.007704246789216995\n",
      "\n",
      "batch: 1/1 in epoch 243/1000 \n",
      "... loss: 0.0076707093976438046\n",
      "\n",
      "batch: 1/1 in epoch 244/1000 \n",
      "... loss: 0.007637585513293743\n",
      "\n",
      "batch: 1/1 in epoch 245/1000 \n",
      "... loss: 0.007604696787893772\n",
      "\n",
      "batch: 1/1 in epoch 246/1000 \n",
      "... loss: 0.007572102826088667\n",
      "\n",
      "batch: 1/1 in epoch 247/1000 \n",
      "... loss: 0.007539744488894939\n",
      "\n",
      "batch: 1/1 in epoch 248/1000 \n",
      "... loss: 0.007507799193263054\n",
      "\n",
      "batch: 1/1 in epoch 249/1000 \n",
      "... loss: 0.00747597124427557\n",
      "\n",
      "batch: 1/1 in epoch 250/1000 \n",
      "... loss: 0.007444438058882952\n",
      "\n",
      "batch: 1/1 in epoch 251/1000 \n",
      "... loss: 0.007413200102746487\n",
      "\n",
      "batch: 1/1 in epoch 252/1000 \n",
      "... loss: 0.007382138166576624\n",
      "\n",
      "batch: 1/1 in epoch 253/1000 \n",
      "... loss: 0.007351430132985115\n",
      "\n",
      "batch: 1/1 in epoch 254/1000 \n",
      "... loss: 0.007320958189666271\n",
      "\n",
      "batch: 1/1 in epoch 255/1000 \n",
      "... loss: 0.007290663197636604\n",
      "\n",
      "batch: 1/1 in epoch 256/1000 \n",
      "... loss: 0.0072606028988957405\n",
      "\n",
      "batch: 1/1 in epoch 257/1000 \n",
      "... loss: 0.007230779156088829\n",
      "\n",
      "batch: 1/1 in epoch 258/1000 \n",
      "... loss: 0.007201428059488535\n",
      "\n",
      "batch: 1/1 in epoch 259/1000 \n",
      "... loss: 0.007172076031565666\n",
      "\n",
      "batch: 1/1 in epoch 260/1000 \n",
      "... loss: 0.007143018767237663\n",
      "\n",
      "batch: 1/1 in epoch 261/1000 \n",
      "... loss: 0.007114078849554062\n",
      "\n",
      "batch: 1/1 in epoch 262/1000 \n",
      "... loss: 0.007085552904754877\n",
      "\n",
      "batch: 1/1 in epoch 263/1000 \n",
      "... loss: 0.007057144306600094\n",
      "\n",
      "batch: 1/1 in epoch 264/1000 \n",
      "... loss: 0.007029030472040176\n",
      "\n",
      "batch: 1/1 in epoch 265/1000 \n",
      "... loss: 0.007001094054430723\n",
      "\n",
      "batch: 1/1 in epoch 266/1000 \n",
      "... loss: 0.0069732749834656715\n",
      "\n",
      "batch: 1/1 in epoch 267/1000 \n",
      "... loss: 0.006945750676095486\n",
      "\n",
      "batch: 1/1 in epoch 268/1000 \n",
      "... loss: 0.0069185225293040276\n",
      "\n",
      "batch: 1/1 in epoch 269/1000 \n",
      "... loss: 0.006891411263495684\n",
      "\n",
      "batch: 1/1 in epoch 270/1000 \n",
      "... loss: 0.006864476948976517\n",
      "\n",
      "batch: 1/1 in epoch 271/1000 \n",
      "... loss: 0.006837897002696991\n",
      "\n",
      "batch: 1/1 in epoch 272/1000 \n",
      "... loss: 0.006811435334384441\n",
      "\n",
      "batch: 1/1 in epoch 273/1000 \n",
      "... loss: 0.006785149686038494\n",
      "\n",
      "batch: 1/1 in epoch 274/1000 \n",
      "... loss: 0.006758982315659523\n",
      "\n",
      "batch: 1/1 in epoch 275/1000 \n",
      "... loss: 0.0067332289181649685\n",
      "\n",
      "batch: 1/1 in epoch 276/1000 \n",
      "... loss: 0.006707474589347839\n",
      "\n",
      "batch: 1/1 in epoch 277/1000 \n",
      "... loss: 0.006681956350803375\n",
      "\n",
      "batch: 1/1 in epoch 278/1000 \n",
      "... loss: 0.006656615063548088\n",
      "\n",
      "batch: 1/1 in epoch 279/1000 \n",
      "... loss: 0.006631509866565466\n",
      "\n",
      "batch: 1/1 in epoch 280/1000 \n",
      "... loss: 0.00660652294754982\n",
      "\n",
      "batch: 1/1 in epoch 281/1000 \n",
      "... loss: 0.006581890396773815\n",
      "\n",
      "batch: 1/1 in epoch 282/1000 \n",
      "... loss: 0.006557316519320011\n",
      "\n",
      "batch: 1/1 in epoch 283/1000 \n",
      "... loss: 0.006532919593155384\n",
      "\n",
      "batch: 1/1 in epoch 284/1000 \n",
      "... loss: 0.006508699618279934\n",
      "\n",
      "batch: 1/1 in epoch 285/1000 \n",
      "... loss: 0.006484656594693661\n",
      "\n",
      "batch: 1/1 in epoch 286/1000 \n",
      "... loss: 0.006460731849074364\n",
      "\n",
      "batch: 1/1 in epoch 287/1000 \n",
      "... loss: 0.00643710233271122\n",
      "\n",
      "batch: 1/1 in epoch 288/1000 \n",
      "... loss: 0.006413531489670277\n",
      "\n",
      "batch: 1/1 in epoch 289/1000 \n",
      "... loss: 0.006390138063579798\n",
      "\n",
      "batch: 1/1 in epoch 290/1000 \n",
      "... loss: 0.006366981193423271\n",
      "\n",
      "batch: 1/1 in epoch 291/1000 \n",
      "... loss: 0.006344000808894634\n",
      "\n",
      "batch: 1/1 in epoch 292/1000 \n",
      "... loss: 0.006321079563349485\n",
      "\n",
      "batch: 1/1 in epoch 293/1000 \n",
      "... loss: 0.006298394408077002\n",
      "\n",
      "batch: 1/1 in epoch 294/1000 \n",
      "... loss: 0.006275886669754982\n",
      "\n",
      "batch: 1/1 in epoch 295/1000 \n",
      "... loss: 0.006253437604755163\n",
      "\n",
      "batch: 1/1 in epoch 296/1000 \n",
      "... loss: 0.0062312837690114975\n",
      "\n",
      "batch: 1/1 in epoch 297/1000 \n",
      "... loss: 0.006209189537912607\n",
      "\n",
      "batch: 1/1 in epoch 298/1000 \n",
      "... loss: 0.006187272258102894\n",
      "\n",
      "batch: 1/1 in epoch 299/1000 \n",
      "... loss: 0.006165413185954094\n",
      "\n",
      "batch: 1/1 in epoch 300/1000 \n",
      "... loss: 0.006143850274384022\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 301/1000 \n",
      "... loss: 0.00612234603613615\n",
      "\n",
      "batch: 1/1 in epoch 302/1000 \n",
      "... loss: 0.006101078353822231\n",
      "\n",
      "batch: 1/1 in epoch 303/1000 \n",
      "... loss: 0.006079810205847025\n",
      "\n",
      "batch: 1/1 in epoch 304/1000 \n",
      "... loss: 0.006058778613805771\n",
      "\n",
      "batch: 1/1 in epoch 305/1000 \n",
      "... loss: 0.006037924438714981\n",
      "\n",
      "batch: 1/1 in epoch 306/1000 \n",
      "... loss: 0.00601718807592988\n",
      "\n",
      "batch: 1/1 in epoch 307/1000 \n",
      "... loss: 0.005996569991111755\n",
      "\n",
      "batch: 1/1 in epoch 308/1000 \n",
      "... loss: 0.005976010579615831\n",
      "\n",
      "batch: 1/1 in epoch 309/1000 \n",
      "... loss: 0.005955747328698635\n",
      "\n",
      "batch: 1/1 in epoch 310/1000 \n",
      "... loss: 0.005935483146458864\n",
      "\n",
      "batch: 1/1 in epoch 311/1000 \n",
      "... loss: 0.005915396846830845\n",
      "\n",
      "batch: 1/1 in epoch 312/1000 \n",
      "... loss: 0.005895428359508514\n",
      "\n",
      "batch: 1/1 in epoch 313/1000 \n",
      "... loss: 0.005875636823475361\n",
      "\n",
      "batch: 1/1 in epoch 314/1000 \n",
      "... loss: 0.005855964031070471\n",
      "\n",
      "batch: 1/1 in epoch 315/1000 \n",
      "... loss: 0.005836468189954758\n",
      "\n",
      "batch: 1/1 in epoch 316/1000 \n",
      "... loss: 0.005817031487822533\n",
      "\n",
      "batch: 1/1 in epoch 317/1000 \n",
      "... loss: 0.005797713063657284\n",
      "\n",
      "batch: 1/1 in epoch 318/1000 \n",
      "... loss: 0.005778512451797724\n",
      "\n",
      "batch: 1/1 in epoch 319/1000 \n",
      "... loss: 0.005759489722549915\n",
      "\n",
      "batch: 1/1 in epoch 320/1000 \n",
      "... loss: 0.00574052520096302\n",
      "\n",
      "batch: 1/1 in epoch 321/1000 \n",
      "... loss: 0.005721738561987877\n",
      "\n",
      "batch: 1/1 in epoch 322/1000 \n",
      "... loss: 0.005703129805624485\n",
      "\n",
      "batch: 1/1 in epoch 323/1000 \n",
      "... loss: 0.005684460513293743\n",
      "\n",
      "batch: 1/1 in epoch 324/1000 \n",
      "... loss: 0.005665969103574753\n",
      "\n",
      "batch: 1/1 in epoch 325/1000 \n",
      "... loss: 0.005647714249789715\n",
      "\n",
      "batch: 1/1 in epoch 326/1000 \n",
      "... loss: 0.005629459396004677\n",
      "\n",
      "batch: 1/1 in epoch 327/1000 \n",
      "... loss: 0.005611381493508816\n",
      "\n",
      "batch: 1/1 in epoch 328/1000 \n",
      "... loss: 0.005593481939285994\n",
      "\n",
      "batch: 1/1 in epoch 329/1000 \n",
      "... loss: 0.005575581453740597\n",
      "\n",
      "batch: 1/1 in epoch 330/1000 \n",
      "... loss: 0.0055577997118234634\n",
      "\n",
      "batch: 1/1 in epoch 331/1000 \n",
      "... loss: 0.005540076643228531\n",
      "\n",
      "batch: 1/1 in epoch 332/1000 \n",
      "... loss: 0.005522590130567551\n",
      "\n",
      "batch: 1/1 in epoch 333/1000 \n",
      "... loss: 0.005505162291228771\n",
      "\n",
      "batch: 1/1 in epoch 334/1000 \n",
      "... loss: 0.0054878536611795425\n",
      "\n",
      "batch: 1/1 in epoch 335/1000 \n",
      "... loss: 0.005470544099807739\n",
      "\n",
      "batch: 1/1 in epoch 336/1000 \n",
      "... loss: 0.005453471094369888\n",
      "\n",
      "batch: 1/1 in epoch 337/1000 \n",
      "... loss: 0.005436516832560301\n",
      "\n",
      "batch: 1/1 in epoch 338/1000 \n",
      "... loss: 0.005419562570750713\n",
      "\n",
      "batch: 1/1 in epoch 339/1000 \n",
      "... loss: 0.005402844399213791\n",
      "\n",
      "batch: 1/1 in epoch 340/1000 \n",
      "... loss: 0.00538606708869338\n",
      "\n",
      "batch: 1/1 in epoch 341/1000 \n",
      "... loss: 0.005369408056139946\n",
      "\n",
      "batch: 1/1 in epoch 342/1000 \n",
      "... loss: 0.005353044718503952\n",
      "\n",
      "batch: 1/1 in epoch 343/1000 \n",
      "... loss: 0.005336503963917494\n",
      "\n",
      "batch: 1/1 in epoch 344/1000 \n",
      "... loss: 0.005320259369909763\n",
      "\n",
      "batch: 1/1 in epoch 345/1000 \n",
      "... loss: 0.005304073449224234\n",
      "\n",
      "batch: 1/1 in epoch 346/1000 \n",
      "... loss: 0.005287887062877417\n",
      "\n",
      "batch: 1/1 in epoch 347/1000 \n",
      "... loss: 0.005271937698125839\n",
      "\n",
      "batch: 1/1 in epoch 348/1000 \n",
      "... loss: 0.005255929194390774\n",
      "\n",
      "batch: 1/1 in epoch 349/1000 \n",
      "... loss: 0.005240216851234436\n",
      "\n",
      "batch: 1/1 in epoch 350/1000 \n",
      "... loss: 0.005224444437772036\n",
      "\n",
      "batch: 1/1 in epoch 351/1000 \n",
      "... loss: 0.005208790767937899\n",
      "\n",
      "batch: 1/1 in epoch 352/1000 \n",
      "... loss: 0.00519319623708725\n",
      "\n",
      "batch: 1/1 in epoch 353/1000 \n",
      "... loss: 0.005177779123187065\n",
      "\n",
      "batch: 1/1 in epoch 354/1000 \n",
      "... loss: 0.005162420682609081\n",
      "\n",
      "batch: 1/1 in epoch 355/1000 \n",
      "... loss: 0.005147181451320648\n",
      "\n",
      "batch: 1/1 in epoch 356/1000 \n",
      "... loss: 0.005132000893354416\n",
      "\n",
      "batch: 1/1 in epoch 357/1000 \n",
      "... loss: 0.005116760730743408\n",
      "\n",
      "batch: 1/1 in epoch 358/1000 \n",
      "... loss: 0.005101816728711128\n",
      "\n",
      "batch: 1/1 in epoch 359/1000 \n",
      "... loss: 0.005086932331323624\n",
      "\n",
      "batch: 1/1 in epoch 360/1000 \n",
      "... loss: 0.0050720470026135445\n",
      "\n",
      "batch: 1/1 in epoch 361/1000 \n",
      "... loss: 0.005057280883193016\n",
      "\n",
      "batch: 1/1 in epoch 362/1000 \n",
      "... loss: 0.005042573437094688\n",
      "\n",
      "batch: 1/1 in epoch 363/1000 \n",
      "... loss: 0.0050279246643185616\n",
      "\n",
      "batch: 1/1 in epoch 364/1000 \n",
      "... loss: 0.005013513378798962\n",
      "\n",
      "batch: 1/1 in epoch 365/1000 \n",
      "... loss: 0.004999102093279362\n",
      "\n",
      "batch: 1/1 in epoch 366/1000 \n",
      "... loss: 0.004984749015420675\n",
      "\n",
      "batch: 1/1 in epoch 367/1000 \n",
      "... loss: 0.00497051514685154\n",
      "\n",
      "batch: 1/1 in epoch 368/1000 \n",
      "... loss: 0.004956280812621117\n",
      "\n",
      "batch: 1/1 in epoch 369/1000 \n",
      "... loss: 0.00494216475635767\n",
      "\n",
      "batch: 1/1 in epoch 370/1000 \n",
      "... loss: 0.004928108304738998\n",
      "\n",
      "batch: 1/1 in epoch 371/1000 \n",
      "... loss: 0.004914228804409504\n",
      "\n",
      "batch: 1/1 in epoch 372/1000 \n",
      "... loss: 0.004900231491774321\n",
      "\n",
      "batch: 1/1 in epoch 373/1000 \n",
      "... loss: 0.004886529874056578\n",
      "\n",
      "batch: 1/1 in epoch 374/1000 \n",
      "... loss: 0.004872709512710571\n",
      "\n",
      "batch: 1/1 in epoch 375/1000 \n",
      "... loss: 0.0048591261729598045\n",
      "\n",
      "batch: 1/1 in epoch 376/1000 \n",
      "... loss: 0.004845602437853813\n",
      "\n",
      "batch: 1/1 in epoch 377/1000 \n",
      "... loss: 0.0048320782370865345\n",
      "\n",
      "batch: 1/1 in epoch 378/1000 \n",
      "... loss: 0.004818612709641457\n",
      "\n",
      "batch: 1/1 in epoch 379/1000 \n",
      "... loss: 0.0048052663914859295\n",
      "\n",
      "batch: 1/1 in epoch 380/1000 \n",
      "... loss: 0.004791978746652603\n",
      "\n",
      "batch: 1/1 in epoch 381/1000 \n",
      "... loss: 0.004778750240802765\n",
      "\n",
      "batch: 1/1 in epoch 382/1000 \n",
      "... loss: 0.00476564047858119\n",
      "\n",
      "batch: 1/1 in epoch 383/1000 \n",
      "... loss: 0.0047526489943265915\n",
      "\n",
      "batch: 1/1 in epoch 384/1000 \n",
      "... loss: 0.004739538766443729\n",
      "\n",
      "batch: 1/1 in epoch 385/1000 \n",
      "... loss: 0.004726725164800882\n",
      "\n",
      "batch: 1/1 in epoch 386/1000 \n",
      "... loss: 0.00471385195851326\n",
      "\n",
      "batch: 1/1 in epoch 387/1000 \n",
      "... loss: 0.004701037425547838\n",
      "\n",
      "batch: 1/1 in epoch 388/1000 \n",
      "... loss: 0.004688282497227192\n",
      "\n",
      "batch: 1/1 in epoch 389/1000 \n",
      "... loss: 0.004675646312534809\n",
      "\n",
      "batch: 1/1 in epoch 390/1000 \n",
      "... loss: 0.004663068801164627\n",
      "\n",
      "batch: 1/1 in epoch 391/1000 \n",
      "... loss: 0.004650550428777933\n",
      "\n",
      "batch: 1/1 in epoch 392/1000 \n",
      "... loss: 0.0046380916610360146\n",
      "\n",
      "batch: 1/1 in epoch 393/1000 \n",
      "... loss: 0.004625632427632809\n",
      "\n",
      "batch: 1/1 in epoch 394/1000 \n",
      "... loss: 0.004613351076841354\n",
      "\n",
      "batch: 1/1 in epoch 395/1000 \n",
      "... loss: 0.0046010697260499\n",
      "\n",
      "batch: 1/1 in epoch 396/1000 \n",
      "... loss: 0.004588966257870197\n",
      "\n",
      "batch: 1/1 in epoch 397/1000 \n",
      "... loss: 0.004576862324029207\n",
      "\n",
      "batch: 1/1 in epoch 398/1000 \n",
      "... loss: 0.004564698785543442\n",
      "\n",
      "batch: 1/1 in epoch 399/1000 \n",
      "... loss: 0.004552713595330715\n",
      "\n",
      "batch: 1/1 in epoch 400/1000 \n",
      "... loss: 0.004540668800473213\n",
      "\n",
      "batch: 1/1 in epoch 401/1000 \n",
      "... loss: 0.004528861492872238\n",
      "\n",
      "batch: 1/1 in epoch 402/1000 \n",
      "... loss: 0.0045169941149652\n",
      "\n",
      "batch: 1/1 in epoch 403/1000 \n",
      "... loss: 0.004505245480686426\n",
      "\n",
      "batch: 1/1 in epoch 404/1000 \n",
      "... loss: 0.00449355598539114\n",
      "\n",
      "batch: 1/1 in epoch 405/1000 \n",
      "... loss: 0.004481866955757141\n",
      "\n",
      "batch: 1/1 in epoch 406/1000 \n",
      "... loss: 0.004470354877412319\n",
      "\n",
      "batch: 1/1 in epoch 407/1000 \n",
      "... loss: 0.004458664916455746\n",
      "\n",
      "batch: 1/1 in epoch 408/1000 \n",
      "... loss: 0.0044472720474004745\n",
      "\n",
      "batch: 1/1 in epoch 409/1000 \n",
      "... loss: 0.004435878247022629\n",
      "\n",
      "batch: 1/1 in epoch 410/1000 \n",
      "... loss: 0.004424485377967358\n",
      "\n",
      "batch: 1/1 in epoch 411/1000 \n",
      "... loss: 0.004413209855556488\n",
      "\n",
      "batch: 1/1 in epoch 412/1000 \n",
      "... loss: 0.004401934798806906\n",
      "\n",
      "batch: 1/1 in epoch 413/1000 \n",
      "... loss: 0.004390719346702099\n",
      "\n",
      "batch: 1/1 in epoch 414/1000 \n",
      "... loss: 0.004379621706902981\n",
      "\n",
      "batch: 1/1 in epoch 415/1000 \n",
      "... loss: 0.004368583671748638\n",
      "\n",
      "batch: 1/1 in epoch 416/1000 \n",
      "... loss: 0.004357605241239071\n",
      "\n",
      "batch: 1/1 in epoch 417/1000 \n",
      "... loss: 0.004346566274762154\n",
      "\n",
      "batch: 1/1 in epoch 418/1000 \n",
      "... loss: 0.0043357061222195625\n",
      "\n",
      "batch: 1/1 in epoch 419/1000 \n",
      "... loss: 0.004324786365032196\n",
      "\n",
      "batch: 1/1 in epoch 420/1000 \n",
      "... loss: 0.004314044490456581\n",
      "\n",
      "batch: 1/1 in epoch 421/1000 \n",
      "... loss: 0.004303183406591415\n",
      "\n",
      "batch: 1/1 in epoch 422/1000 \n",
      "... loss: 0.004292501136660576\n",
      "\n",
      "batch: 1/1 in epoch 423/1000 \n",
      "... loss: 0.004281936213374138\n",
      "\n",
      "batch: 1/1 in epoch 424/1000 \n",
      "... loss: 0.004271253477782011\n",
      "\n",
      "batch: 1/1 in epoch 425/1000 \n",
      "... loss: 0.004260748624801636\n",
      "\n",
      "batch: 1/1 in epoch 426/1000 \n",
      "... loss: 0.004250243306159973\n",
      "\n",
      "batch: 1/1 in epoch 427/1000 \n",
      "... loss: 0.0042397379875183105\n",
      "\n",
      "batch: 1/1 in epoch 428/1000 \n",
      "... loss: 0.004229350946843624\n",
      "\n",
      "batch: 1/1 in epoch 429/1000 \n",
      "... loss: 0.004219023510813713\n",
      "\n",
      "batch: 1/1 in epoch 430/1000 \n",
      "... loss: 0.00420875521376729\n",
      "\n",
      "batch: 1/1 in epoch 431/1000 \n",
      "... loss: 0.004198427777737379\n",
      "\n",
      "batch: 1/1 in epoch 432/1000 \n",
      "... loss: 0.004188396502286196\n",
      "\n",
      "batch: 1/1 in epoch 433/1000 \n",
      "... loss: 0.004178068600594997\n",
      "\n",
      "batch: 1/1 in epoch 434/1000 \n",
      "... loss: 0.0041680969297885895\n",
      "\n",
      "batch: 1/1 in epoch 435/1000 \n",
      "... loss: 0.004157946910709143\n",
      "\n",
      "batch: 1/1 in epoch 436/1000 \n",
      "... loss: 0.0041479747742414474\n",
      "\n",
      "batch: 1/1 in epoch 437/1000 \n",
      "... loss: 0.00413806177675724\n",
      "\n",
      "batch: 1/1 in epoch 438/1000 \n",
      "... loss: 0.004128089640289545\n",
      "\n",
      "batch: 1/1 in epoch 439/1000 \n",
      "... loss: 0.004118176642805338\n",
      "\n",
      "batch: 1/1 in epoch 440/1000 \n",
      "... loss: 0.00410850066691637\n",
      "\n",
      "batch: 1/1 in epoch 441/1000 \n",
      "... loss: 0.004098647274076939\n",
      "\n",
      "batch: 1/1 in epoch 442/1000 \n",
      "... loss: 0.004088970832526684\n",
      "\n",
      "batch: 1/1 in epoch 443/1000 \n",
      "... loss: 0.004079295322299004\n",
      "\n",
      "batch: 1/1 in epoch 444/1000 \n",
      "... loss: 0.004069619346410036\n",
      "\n",
      "batch: 1/1 in epoch 445/1000 \n",
      "... loss: 0.004060002509504557\n",
      "\n",
      "batch: 1/1 in epoch 446/1000 \n",
      "... loss: 0.004050444811582565\n",
      "\n",
      "batch: 1/1 in epoch 447/1000 \n",
      "... loss: 0.004040946718305349\n",
      "\n",
      "batch: 1/1 in epoch 448/1000 \n",
      "... loss: 0.004031448625028133\n",
      "\n",
      "batch: 1/1 in epoch 449/1000 \n",
      "... loss: 0.004022068344056606\n",
      "\n",
      "batch: 1/1 in epoch 450/1000 \n",
      "... loss: 0.004012688994407654\n",
      "\n",
      "batch: 1/1 in epoch 451/1000 \n",
      "... loss: 0.0040034279227256775\n",
      "\n",
      "batch: 1/1 in epoch 452/1000 \n",
      "... loss: 0.003993988037109375\n",
      "\n",
      "batch: 1/1 in epoch 453/1000 \n",
      "... loss: 0.0039848461747169495\n",
      "\n",
      "batch: 1/1 in epoch 454/1000 \n",
      "... loss: 0.003975643776357174\n",
      "\n",
      "batch: 1/1 in epoch 455/1000 \n",
      "... loss: 0.003966441843658686\n",
      "\n",
      "batch: 1/1 in epoch 456/1000 \n",
      "... loss: 0.0039572990499436855\n",
      "\n",
      "batch: 1/1 in epoch 457/1000 \n",
      "... loss: 0.003948274999856949\n",
      "\n",
      "batch: 1/1 in epoch 458/1000 \n",
      "... loss: 0.003939132206141949\n",
      "\n",
      "batch: 1/1 in epoch 459/1000 \n",
      "... loss: 0.003930225968360901\n",
      "\n",
      "batch: 1/1 in epoch 460/1000 \n",
      "... loss: 0.003921201918274164\n",
      "\n",
      "batch: 1/1 in epoch 461/1000 \n",
      "... loss: 0.003912236541509628\n",
      "\n",
      "batch: 1/1 in epoch 462/1000 \n",
      "... loss: 0.0039034495130181313\n",
      "\n",
      "batch: 1/1 in epoch 463/1000 \n",
      "... loss: 0.003894602879881859\n",
      "\n",
      "batch: 1/1 in epoch 464/1000 \n",
      "... loss: 0.0038856971077620983\n",
      "\n",
      "batch: 1/1 in epoch 465/1000 \n",
      "... loss: 0.0038770283572375774\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 466/1000 \n",
      "... loss: 0.0038682410959154367\n",
      "\n",
      "batch: 1/1 in epoch 467/1000 \n",
      "... loss: 0.003859572345390916\n",
      "\n",
      "batch: 1/1 in epoch 468/1000 \n",
      "... loss: 0.0038509629666805267\n",
      "\n",
      "batch: 1/1 in epoch 469/1000 \n",
      "... loss: 0.003842353355139494\n",
      "\n",
      "batch: 1/1 in epoch 470/1000 \n",
      "... loss: 0.003833743743598461\n",
      "\n",
      "batch: 1/1 in epoch 471/1000 \n",
      "... loss: 0.0038251937367022038\n",
      "\n",
      "batch: 1/1 in epoch 472/1000 \n",
      "... loss: 0.0038168213795870543\n",
      "\n",
      "batch: 1/1 in epoch 473/1000 \n",
      "... loss: 0.003808271139860153\n",
      "\n",
      "batch: 1/1 in epoch 474/1000 \n",
      "... loss: 0.0037997798062860966\n",
      "\n",
      "batch: 1/1 in epoch 475/1000 \n",
      "... loss: 0.0037914076820015907\n",
      "\n",
      "batch: 1/1 in epoch 476/1000 \n",
      "... loss: 0.0037830350920557976\n",
      "\n",
      "batch: 1/1 in epoch 477/1000 \n",
      "... loss: 0.003774721873924136\n",
      "\n",
      "batch: 1/1 in epoch 478/1000 \n",
      "... loss: 0.0037665273994207382\n",
      "\n",
      "batch: 1/1 in epoch 479/1000 \n",
      "... loss: 0.003758273320272565\n",
      "\n",
      "batch: 1/1 in epoch 480/1000 \n",
      "... loss: 0.003750019473955035\n",
      "\n",
      "batch: 1/1 in epoch 481/1000 \n",
      "... loss: 0.00374182453379035\n",
      "\n",
      "batch: 1/1 in epoch 482/1000 \n",
      "... loss: 0.0037336298264563084\n",
      "\n",
      "batch: 1/1 in epoch 483/1000 \n",
      "... loss: 0.003725613234564662\n",
      "\n",
      "batch: 1/1 in epoch 484/1000 \n",
      "... loss: 0.003717477899044752\n",
      "\n",
      "batch: 1/1 in epoch 485/1000 \n",
      "... loss: 0.003709461074322462\n",
      "\n",
      "batch: 1/1 in epoch 486/1000 \n",
      "... loss: 0.003701444249600172\n",
      "\n",
      "batch: 1/1 in epoch 487/1000 \n",
      "... loss: 0.00369348656386137\n",
      "\n",
      "batch: 1/1 in epoch 488/1000 \n",
      "... loss: 0.003685528878122568\n",
      "\n",
      "batch: 1/1 in epoch 489/1000 \n",
      "... loss: 0.003677571192383766\n",
      "\n",
      "batch: 1/1 in epoch 490/1000 \n",
      "... loss: 0.0036697322502732277\n",
      "\n",
      "batch: 1/1 in epoch 491/1000 \n",
      "... loss: 0.003661893308162689\n",
      "\n",
      "batch: 1/1 in epoch 492/1000 \n",
      "... loss: 0.0036540543660521507\n",
      "\n",
      "batch: 1/1 in epoch 493/1000 \n",
      "... loss: 0.003646333934739232\n",
      "\n",
      "batch: 1/1 in epoch 494/1000 \n",
      "... loss: 0.003638553898781538\n",
      "\n",
      "batch: 1/1 in epoch 495/1000 \n",
      "... loss: 0.0036309524439275265\n",
      "\n",
      "batch: 1/1 in epoch 496/1000 \n",
      "... loss: 0.003623231779783964\n",
      "\n",
      "batch: 1/1 in epoch 497/1000 \n",
      "... loss: 0.0036155704874545336\n",
      "\n",
      "batch: 1/1 in epoch 498/1000 \n",
      "... loss: 0.0036079687997698784\n",
      "\n",
      "batch: 1/1 in epoch 499/1000 \n",
      "... loss: 0.003600485622882843\n",
      "\n",
      "batch: 1/1 in epoch 500/1000 \n",
      "... loss: 0.0035929428413510323\n",
      "\n",
      "batch: 1/1 in epoch 501/1000 \n",
      "... loss: 0.0035852815490216017\n",
      "\n",
      "batch: 1/1 in epoch 502/1000 \n",
      "... loss: 0.0035778575111180544\n",
      "\n",
      "batch: 1/1 in epoch 503/1000 \n",
      "... loss: 0.0035703741014003754\n",
      "\n",
      "batch: 1/1 in epoch 504/1000 \n",
      "... loss: 0.003562950063496828\n",
      "\n",
      "batch: 1/1 in epoch 505/1000 \n",
      "... loss: 0.0035555853974074125\n",
      "\n",
      "batch: 1/1 in epoch 506/1000 \n",
      "... loss: 0.00354810175485909\n",
      "\n",
      "batch: 1/1 in epoch 507/1000 \n",
      "... loss: 0.003540914971381426\n",
      "\n",
      "batch: 1/1 in epoch 508/1000 \n",
      "... loss: 0.0035334909334778786\n",
      "\n",
      "batch: 1/1 in epoch 509/1000 \n",
      "... loss: 0.0035263041500002146\n",
      "\n",
      "batch: 1/1 in epoch 510/1000 \n",
      "... loss: 0.003518998622894287\n",
      "\n",
      "batch: 1/1 in epoch 511/1000 \n",
      "... loss: 0.0035117524676024914\n",
      "\n",
      "batch: 1/1 in epoch 512/1000 \n",
      "... loss: 0.003504624590277672\n",
      "\n",
      "batch: 1/1 in epoch 513/1000 \n",
      "... loss: 0.003497437806800008\n",
      "\n",
      "batch: 1/1 in epoch 514/1000 \n",
      "... loss: 0.003490310162305832\n",
      "\n",
      "batch: 1/1 in epoch 515/1000 \n",
      "... loss: 0.003483182517811656\n",
      "\n",
      "batch: 1/1 in epoch 516/1000 \n",
      "... loss: 0.003476114245131612\n",
      "\n",
      "batch: 1/1 in epoch 517/1000 \n",
      "... loss: 0.003469045739620924\n",
      "\n",
      "batch: 1/1 in epoch 518/1000 \n",
      "... loss: 0.0034620368387550116\n",
      "\n",
      "batch: 1/1 in epoch 519/1000 \n",
      "... loss: 0.0034551466815173626\n",
      "\n",
      "batch: 1/1 in epoch 520/1000 \n",
      "... loss: 0.003448018804192543\n",
      "\n",
      "batch: 1/1 in epoch 521/1000 \n",
      "... loss: 0.003441247157752514\n",
      "\n",
      "batch: 1/1 in epoch 522/1000 \n",
      "... loss: 0.003434238024055958\n",
      "\n",
      "batch: 1/1 in epoch 523/1000 \n",
      "... loss: 0.003427347633987665\n",
      "\n",
      "batch: 1/1 in epoch 524/1000 \n",
      "... loss: 0.0034205163829028606\n",
      "\n",
      "batch: 1/1 in epoch 525/1000 \n",
      "... loss: 0.0034136257600039244\n",
      "\n",
      "batch: 1/1 in epoch 526/1000 \n",
      "... loss: 0.0034068538807332516\n",
      "\n",
      "batch: 1/1 in epoch 527/1000 \n",
      "... loss: 0.0034000822342932224\n",
      "\n",
      "batch: 1/1 in epoch 528/1000 \n",
      "... loss: 0.003393310122191906\n",
      "\n",
      "batch: 1/1 in epoch 529/1000 \n",
      "... loss: 0.003386597614735365\n",
      "\n",
      "batch: 1/1 in epoch 530/1000 \n",
      "... loss: 0.003379885107278824\n",
      "\n",
      "batch: 1/1 in epoch 531/1000 \n",
      "... loss: 0.003373172599822283\n",
      "\n",
      "batch: 1/1 in epoch 532/1000 \n",
      "... loss: 0.0033665786031633615\n",
      "\n",
      "batch: 1/1 in epoch 533/1000 \n",
      "... loss: 0.0033599254675209522\n",
      "\n",
      "batch: 1/1 in epoch 534/1000 \n",
      "... loss: 0.0033533908426761627\n",
      "\n",
      "batch: 1/1 in epoch 535/1000 \n",
      "... loss: 0.0033467968460172415\n",
      "\n",
      "batch: 1/1 in epoch 536/1000 \n",
      "... loss: 0.003340262221172452\n",
      "\n",
      "batch: 1/1 in epoch 537/1000 \n",
      "... loss: 0.0033337275963276625\n",
      "\n",
      "batch: 1/1 in epoch 538/1000 \n",
      "... loss: 0.0033272523432970047\n",
      "\n",
      "batch: 1/1 in epoch 539/1000 \n",
      "... loss: 0.0033207174856215715\n",
      "\n",
      "batch: 1/1 in epoch 540/1000 \n",
      "... loss: 0.0033142422325909138\n",
      "\n",
      "batch: 1/1 in epoch 541/1000 \n",
      "... loss: 0.003307826118543744\n",
      "\n",
      "batch: 1/1 in epoch 542/1000 \n",
      "... loss: 0.003301469376310706\n",
      "\n",
      "batch: 1/1 in epoch 543/1000 \n",
      "... loss: 0.0032951720058918\n",
      "\n",
      "batch: 1/1 in epoch 544/1000 \n",
      "... loss: 0.003288756124675274\n",
      "\n",
      "batch: 1/1 in epoch 545/1000 \n",
      "... loss: 0.003282399382442236\n",
      "\n",
      "batch: 1/1 in epoch 546/1000 \n",
      "... loss: 0.003276101779192686\n",
      "\n",
      "batch: 1/1 in epoch 547/1000 \n",
      "... loss: 0.0032698637805879116\n",
      "\n",
      "batch: 1/1 in epoch 548/1000 \n",
      "... loss: 0.0032635661773383617\n",
      "\n",
      "batch: 1/1 in epoch 549/1000 \n",
      "... loss: 0.0032574469223618507\n",
      "\n",
      "batch: 1/1 in epoch 550/1000 \n",
      "... loss: 0.003251090180128813\n",
      "\n",
      "batch: 1/1 in epoch 551/1000 \n",
      "... loss: 0.00324503006413579\n",
      "\n",
      "batch: 1/1 in epoch 552/1000 \n",
      "... loss: 0.00323873246088624\n",
      "\n",
      "batch: 1/1 in epoch 553/1000 \n",
      "... loss: 0.003232672344893217\n",
      "\n",
      "batch: 1/1 in epoch 554/1000 \n",
      "... loss: 0.003226612228900194\n",
      "\n",
      "batch: 1/1 in epoch 555/1000 \n",
      "... loss: 0.0032205521129071712\n",
      "\n",
      "batch: 1/1 in epoch 556/1000 \n",
      "... loss: 0.0032144919969141483\n",
      "\n",
      "batch: 1/1 in epoch 557/1000 \n",
      "... loss: 0.0032084318809211254\n",
      "\n",
      "batch: 1/1 in epoch 558/1000 \n",
      "... loss: 0.0032023717649281025\n",
      "\n",
      "batch: 1/1 in epoch 559/1000 \n",
      "... loss: 0.003196311416104436\n",
      "\n",
      "batch: 1/1 in epoch 560/1000 \n",
      "... loss: 0.0031903106719255447\n",
      "\n",
      "batch: 1/1 in epoch 561/1000 \n",
      "... loss: 0.0031843690667301416\n",
      "\n",
      "batch: 1/1 in epoch 562/1000 \n",
      "... loss: 0.003178487066179514\n",
      "\n",
      "batch: 1/1 in epoch 563/1000 \n",
      "... loss: 0.0031724858563393354\n",
      "\n",
      "batch: 1/1 in epoch 564/1000 \n",
      "... loss: 0.003166662994772196\n",
      "\n",
      "batch: 1/1 in epoch 565/1000 \n",
      "... loss: 0.0031607216224074364\n",
      "\n",
      "batch: 1/1 in epoch 566/1000 \n",
      "... loss: 0.003154898528009653\n",
      "\n",
      "batch: 1/1 in epoch 567/1000 \n",
      "... loss: 0.003149075899273157\n",
      "\n",
      "batch: 1/1 in epoch 568/1000 \n",
      "... loss: 0.003143252804875374\n",
      "\n",
      "batch: 1/1 in epoch 569/1000 \n",
      "... loss: 0.003137429943308234\n",
      "\n",
      "batch: 1/1 in epoch 570/1000 \n",
      "... loss: 0.003131725825369358\n",
      "\n",
      "batch: 1/1 in epoch 571/1000 \n",
      "... loss: 0.00312596233561635\n",
      "\n",
      "batch: 1/1 in epoch 572/1000 \n",
      "... loss: 0.0031202579848468304\n",
      "\n",
      "batch: 1/1 in epoch 573/1000 \n",
      "... loss: 0.0031144944950938225\n",
      "\n",
      "batch: 1/1 in epoch 574/1000 \n",
      "... loss: 0.003108908887952566\n",
      "\n",
      "batch: 1/1 in epoch 575/1000 \n",
      "... loss: 0.0031032045371830463\n",
      "\n",
      "batch: 1/1 in epoch 576/1000 \n",
      "... loss: 0.0030975001864135265\n",
      "\n",
      "batch: 1/1 in epoch 577/1000 \n",
      "... loss: 0.003091855440288782\n",
      "\n",
      "batch: 1/1 in epoch 578/1000 \n",
      "... loss: 0.0030863292049616575\n",
      "\n",
      "batch: 1/1 in epoch 579/1000 \n",
      "... loss: 0.003080743597820401\n",
      "\n",
      "batch: 1/1 in epoch 580/1000 \n",
      "... loss: 0.003075098618865013\n",
      "\n",
      "batch: 1/1 in epoch 581/1000 \n",
      "... loss: 0.0030695723835378885\n",
      "\n",
      "batch: 1/1 in epoch 582/1000 \n",
      "... loss: 0.003064046148210764\n",
      "\n",
      "batch: 1/1 in epoch 583/1000 \n",
      "... loss: 0.0030585199128836393\n",
      "\n",
      "batch: 1/1 in epoch 584/1000 \n",
      "... loss: 0.003053052816540003\n",
      "\n",
      "batch: 1/1 in epoch 585/1000 \n",
      "... loss: 0.00304758595302701\n",
      "\n",
      "batch: 1/1 in epoch 586/1000 \n",
      "... loss: 0.003042119089514017\n",
      "\n",
      "batch: 1/1 in epoch 587/1000 \n",
      "... loss: 0.0030367709696292877\n",
      "\n",
      "batch: 1/1 in epoch 588/1000 \n",
      "... loss: 0.003031303873285651\n",
      "\n",
      "batch: 1/1 in epoch 589/1000 \n",
      "... loss: 0.00302589638158679\n",
      "\n",
      "batch: 1/1 in epoch 590/1000 \n",
      "... loss: 0.0030204886570572853\n",
      "\n",
      "batch: 1/1 in epoch 591/1000 \n",
      "... loss: 0.003015140537172556\n",
      "\n",
      "batch: 1/1 in epoch 592/1000 \n",
      "... loss: 0.0030098515562713146\n",
      "\n",
      "batch: 1/1 in epoch 593/1000 \n",
      "... loss: 0.0030045032035559416\n",
      "\n",
      "batch: 1/1 in epoch 594/1000 \n",
      "... loss: 0.0029992142226547003\n",
      "\n",
      "batch: 1/1 in epoch 595/1000 \n",
      "... loss: 0.0029939846135675907\n",
      "\n",
      "batch: 1/1 in epoch 596/1000 \n",
      "... loss: 0.0029886956326663494\n",
      "\n",
      "batch: 1/1 in epoch 597/1000 \n",
      "... loss: 0.0029834662564098835\n",
      "\n",
      "batch: 1/1 in epoch 598/1000 \n",
      "... loss: 0.002978177275508642\n",
      "\n",
      "batch: 1/1 in epoch 599/1000 \n",
      "... loss: 0.0029730070382356644\n",
      "\n",
      "batch: 1/1 in epoch 600/1000 \n",
      "... loss: 0.0029678368009626865\n",
      "\n",
      "batch: 1/1 in epoch 601/1000 \n",
      "... loss: 0.0029625478200614452\n",
      "\n",
      "batch: 1/1 in epoch 602/1000 \n",
      "... loss: 0.002957496326416731\n",
      "\n",
      "batch: 1/1 in epoch 603/1000 \n",
      "... loss: 0.0029522664844989777\n",
      "\n",
      "batch: 1/1 in epoch 604/1000 \n",
      "... loss: 0.0029472149908542633\n",
      "\n",
      "batch: 1/1 in epoch 605/1000 \n",
      "... loss: 0.002942163497209549\n",
      "\n",
      "batch: 1/1 in epoch 606/1000 \n",
      "... loss: 0.002936993259936571\n",
      "\n",
      "batch: 1/1 in epoch 607/1000 \n",
      "... loss: 0.0029319417662918568\n",
      "\n",
      "batch: 1/1 in epoch 608/1000 \n",
      "... loss: 0.0029269494116306305\n",
      "\n",
      "batch: 1/1 in epoch 609/1000 \n",
      "... loss: 0.002921897917985916\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 610/1000 \n",
      "... loss: 0.002916846191510558\n",
      "\n",
      "batch: 1/1 in epoch 611/1000 \n",
      "... loss: 0.0029119134414941072\n",
      "\n",
      "batch: 1/1 in epoch 612/1000 \n",
      "... loss: 0.0029069213196635246\n",
      "\n",
      "batch: 1/1 in epoch 613/1000 \n",
      "... loss: 0.0029019289650022984\n",
      "\n",
      "batch: 1/1 in epoch 614/1000 \n",
      "... loss: 0.002896936610341072\n",
      "\n",
      "batch: 1/1 in epoch 615/1000 \n",
      "... loss: 0.002891944255679846\n",
      "\n",
      "batch: 1/1 in epoch 616/1000 \n",
      "... loss: 0.0028871302492916584\n",
      "\n",
      "batch: 1/1 in epoch 617/1000 \n",
      "... loss: 0.002882137894630432\n",
      "\n",
      "batch: 1/1 in epoch 618/1000 \n",
      "... loss: 0.0028772642835974693\n",
      "\n",
      "batch: 1/1 in epoch 619/1000 \n",
      "... loss: 0.002872450277209282\n",
      "\n",
      "batch: 1/1 in epoch 620/1000 \n",
      "... loss: 0.0028675172943621874\n",
      "\n",
      "batch: 1/1 in epoch 621/1000 \n",
      "... loss: 0.0028627626597881317\n",
      "\n",
      "batch: 1/1 in epoch 622/1000 \n",
      "... loss: 0.0028578294441103935\n",
      "\n",
      "batch: 1/1 in epoch 623/1000 \n",
      "... loss: 0.002853074576705694\n",
      "\n",
      "batch: 1/1 in epoch 624/1000 \n",
      "... loss: 0.0028482009656727314\n",
      "\n",
      "batch: 1/1 in epoch 625/1000 \n",
      "... loss: 0.002843565074726939\n",
      "\n",
      "batch: 1/1 in epoch 626/1000 \n",
      "... loss: 0.0028388104401528835\n",
      "\n",
      "batch: 1/1 in epoch 627/1000 \n",
      "... loss: 0.002833995968103409\n",
      "\n",
      "batch: 1/1 in epoch 628/1000 \n",
      "... loss: 0.002829359844326973\n",
      "\n",
      "batch: 1/1 in epoch 629/1000 \n",
      "... loss: 0.0028246049769222736\n",
      "\n",
      "batch: 1/1 in epoch 630/1000 \n",
      "... loss: 0.0028198501095175743\n",
      "\n",
      "batch: 1/1 in epoch 631/1000 \n",
      "... loss: 0.0028152139857411385\n",
      "\n",
      "batch: 1/1 in epoch 632/1000 \n",
      "... loss: 0.0028105778619647026\n",
      "\n",
      "batch: 1/1 in epoch 633/1000 \n",
      "... loss: 0.0028058229945600033\n",
      "\n",
      "batch: 1/1 in epoch 634/1000 \n",
      "... loss: 0.0028011868707835674\n",
      "\n",
      "batch: 1/1 in epoch 635/1000 \n",
      "... loss: 0.002796669490635395\n",
      "\n",
      "batch: 1/1 in epoch 636/1000 \n",
      "... loss: 0.002792092738673091\n",
      "\n",
      "batch: 1/1 in epoch 637/1000 \n",
      "... loss: 0.002787515986710787\n",
      "\n",
      "batch: 1/1 in epoch 638/1000 \n",
      "... loss: 0.0027828796301037073\n",
      "\n",
      "batch: 1/1 in epoch 639/1000 \n",
      "... loss: 0.0027782435063272715\n",
      "\n",
      "batch: 1/1 in epoch 640/1000 \n",
      "... loss: 0.0027737258933484554\n",
      "\n",
      "batch: 1/1 in epoch 641/1000 \n",
      "... loss: 0.0027692681178450584\n",
      "\n",
      "batch: 1/1 in epoch 642/1000 \n",
      "... loss: 0.0027646911330521107\n",
      "\n",
      "batch: 1/1 in epoch 643/1000 \n",
      "... loss: 0.002760114148259163\n",
      "\n",
      "batch: 1/1 in epoch 644/1000 \n",
      "... loss: 0.0027557751163840294\n",
      "\n",
      "batch: 1/1 in epoch 645/1000 \n",
      "... loss: 0.0027511981315910816\n",
      "\n",
      "batch: 1/1 in epoch 646/1000 \n",
      "... loss: 0.002746859099715948\n",
      "\n",
      "batch: 1/1 in epoch 647/1000 \n",
      "... loss: 0.0027422821149230003\n",
      "\n",
      "batch: 1/1 in epoch 648/1000 \n",
      "... loss: 0.002737942850217223\n",
      "\n",
      "batch: 1/1 in epoch 649/1000 \n",
      "... loss: 0.0027333658654242754\n",
      "\n",
      "batch: 1/1 in epoch 650/1000 \n",
      "... loss: 0.00272908597253263\n",
      "\n",
      "batch: 1/1 in epoch 651/1000 \n",
      "... loss: 0.002724687336012721\n",
      "\n",
      "batch: 1/1 in epoch 652/1000 \n",
      "... loss: 0.0027202884666621685\n",
      "\n",
      "batch: 1/1 in epoch 653/1000 \n",
      "... loss: 0.0027159489691257477\n",
      "\n",
      "batch: 1/1 in epoch 654/1000 \n",
      "... loss: 0.002711490960791707\n",
      "\n",
      "batch: 1/1 in epoch 655/1000 \n",
      "... loss: 0.002707210835069418\n",
      "\n",
      "batch: 1/1 in epoch 656/1000 \n",
      "... loss: 0.0027029309421777725\n",
      "\n",
      "batch: 1/1 in epoch 657/1000 \n",
      "... loss: 0.002698651049286127\n",
      "\n",
      "batch: 1/1 in epoch 658/1000 \n",
      "... loss: 0.0026943711563944817\n",
      "\n",
      "batch: 1/1 in epoch 659/1000 \n",
      "... loss: 0.0026900912635028362\n",
      "\n",
      "batch: 1/1 in epoch 660/1000 \n",
      "... loss: 0.002685811137780547\n",
      "\n",
      "batch: 1/1 in epoch 661/1000 \n",
      "... loss: 0.0026815906167030334\n",
      "\n",
      "batch: 1/1 in epoch 662/1000 \n",
      "... loss: 0.0026773104909807444\n",
      "\n",
      "batch: 1/1 in epoch 663/1000 \n",
      "... loss: 0.0026730303652584553\n",
      "\n",
      "batch: 1/1 in epoch 664/1000 \n",
      "... loss: 0.00266875047236681\n",
      "\n",
      "batch: 1/1 in epoch 665/1000 \n",
      "... loss: 0.0026645297184586525\n",
      "\n",
      "batch: 1/1 in epoch 666/1000 \n",
      "... loss: 0.0026604277081787586\n",
      "\n",
      "batch: 1/1 in epoch 667/1000 \n",
      "... loss: 0.0026562665589153767\n",
      "\n",
      "batch: 1/1 in epoch 668/1000 \n",
      "... loss: 0.0026520458050072193\n",
      "\n",
      "batch: 1/1 in epoch 669/1000 \n",
      "... loss: 0.0026478846557438374\n",
      "\n",
      "batch: 1/1 in epoch 670/1000 \n",
      "... loss: 0.002643842250108719\n",
      "\n",
      "batch: 1/1 in epoch 671/1000 \n",
      "... loss: 0.002639681100845337\n",
      "\n",
      "batch: 1/1 in epoch 672/1000 \n",
      "... loss: 0.002635579090565443\n",
      "\n",
      "batch: 1/1 in epoch 673/1000 \n",
      "... loss: 0.0026314177084714174\n",
      "\n",
      "batch: 1/1 in epoch 674/1000 \n",
      "... loss: 0.0026273750700056553\n",
      "\n",
      "batch: 1/1 in epoch 675/1000 \n",
      "... loss: 0.002623273292556405\n",
      "\n",
      "batch: 1/1 in epoch 676/1000 \n",
      "... loss: 0.002619171282276511\n",
      "\n",
      "batch: 1/1 in epoch 677/1000 \n",
      "... loss: 0.0026151882484555244\n",
      "\n",
      "batch: 1/1 in epoch 678/1000 \n",
      "... loss: 0.002611145842820406\n",
      "\n",
      "batch: 1/1 in epoch 679/1000 \n",
      "... loss: 0.002607043832540512\n",
      "\n",
      "batch: 1/1 in epoch 680/1000 \n",
      "... loss: 0.0026030605658888817\n",
      "\n",
      "batch: 1/1 in epoch 681/1000 \n",
      "... loss: 0.0025990772992372513\n",
      "\n",
      "batch: 1/1 in epoch 682/1000 \n",
      "... loss: 0.0025951536372303963\n",
      "\n",
      "batch: 1/1 in epoch 683/1000 \n",
      "... loss: 0.002591111231595278\n",
      "\n",
      "batch: 1/1 in epoch 684/1000 \n",
      "... loss: 0.002587068360298872\n",
      "\n",
      "batch: 1/1 in epoch 685/1000 \n",
      "... loss: 0.002583144698292017\n",
      "\n",
      "batch: 1/1 in epoch 686/1000 \n",
      "... loss: 0.002579221036285162\n",
      "\n",
      "batch: 1/1 in epoch 687/1000 \n",
      "... loss: 0.002575297374278307\n",
      "\n",
      "batch: 1/1 in epoch 688/1000 \n",
      "... loss: 0.0025713732466101646\n",
      "\n",
      "batch: 1/1 in epoch 689/1000 \n",
      "... loss: 0.0025674495846033096\n",
      "\n",
      "batch: 1/1 in epoch 690/1000 \n",
      "... loss: 0.002563525689765811\n",
      "\n",
      "batch: 1/1 in epoch 691/1000 \n",
      "... loss: 0.0025596613995730877\n",
      "\n",
      "batch: 1/1 in epoch 692/1000 \n",
      "... loss: 0.0025557968765497208\n",
      "\n",
      "batch: 1/1 in epoch 693/1000 \n",
      "... loss: 0.0025519919581711292\n",
      "\n",
      "batch: 1/1 in epoch 694/1000 \n",
      "... loss: 0.002548127667978406\n",
      "\n",
      "batch: 1/1 in epoch 695/1000 \n",
      "... loss: 0.0025442037731409073\n",
      "\n",
      "batch: 1/1 in epoch 696/1000 \n",
      "... loss: 0.002540457993745804\n",
      "\n",
      "batch: 1/1 in epoch 697/1000 \n",
      "... loss: 0.002536593470722437\n",
      "\n",
      "batch: 1/1 in epoch 698/1000 \n",
      "... loss: 0.0025327885523438454\n",
      "\n",
      "batch: 1/1 in epoch 699/1000 \n",
      "... loss: 0.0025290430057793856\n",
      "\n",
      "batch: 1/1 in epoch 700/1000 \n",
      "... loss: 0.0025251784827560186\n",
      "\n",
      "batch: 1/1 in epoch 701/1000 \n",
      "... loss: 0.002521432936191559\n",
      "\n",
      "batch: 1/1 in epoch 702/1000 \n",
      "... loss: 0.0025176871567964554\n",
      "\n",
      "batch: 1/1 in epoch 703/1000 \n",
      "... loss: 0.002513941377401352\n",
      "\n",
      "batch: 1/1 in epoch 704/1000 \n",
      "... loss: 0.002510195830836892\n",
      "\n",
      "batch: 1/1 in epoch 705/1000 \n",
      "... loss: 0.0025064502842724323\n",
      "\n",
      "batch: 1/1 in epoch 706/1000 \n",
      "... loss: 0.0025027638766914606\n",
      "\n",
      "batch: 1/1 in epoch 707/1000 \n",
      "... loss: 0.002499018330127001\n",
      "\n",
      "batch: 1/1 in epoch 708/1000 \n",
      "... loss: 0.002495331922546029\n",
      "\n",
      "batch: 1/1 in epoch 709/1000 \n",
      "... loss: 0.0024916455149650574\n",
      "\n",
      "batch: 1/1 in epoch 710/1000 \n",
      "... loss: 0.0024879593402147293\n",
      "\n",
      "batch: 1/1 in epoch 711/1000 \n",
      "... loss: 0.0024842731654644012\n",
      "\n",
      "batch: 1/1 in epoch 712/1000 \n",
      "... loss: 0.0024807057343423367\n",
      "\n",
      "batch: 1/1 in epoch 713/1000 \n",
      "... loss: 0.002477019326761365\n",
      "\n",
      "batch: 1/1 in epoch 714/1000 \n",
      "... loss: 0.0024734518956393003\n",
      "\n",
      "batch: 1/1 in epoch 715/1000 \n",
      "... loss: 0.002469825092703104\n",
      "\n",
      "batch: 1/1 in epoch 716/1000 \n",
      "... loss: 0.002466198056936264\n",
      "\n",
      "batch: 1/1 in epoch 717/1000 \n",
      "... loss: 0.0024625116493552923\n",
      "\n",
      "batch: 1/1 in epoch 718/1000 \n",
      "... loss: 0.002458884846419096\n",
      "\n",
      "batch: 1/1 in epoch 719/1000 \n",
      "... loss: 0.0024553765542805195\n",
      "\n",
      "batch: 1/1 in epoch 720/1000 \n",
      "... loss: 0.002451809123158455\n",
      "\n",
      "batch: 1/1 in epoch 721/1000 \n",
      "... loss: 0.0024482416920363903\n",
      "\n",
      "batch: 1/1 in epoch 722/1000 \n",
      "... loss: 0.0024446742609143257\n",
      "\n",
      "batch: 1/1 in epoch 723/1000 \n",
      "... loss: 0.002441165968775749\n",
      "\n",
      "batch: 1/1 in epoch 724/1000 \n",
      "... loss: 0.0024375985376536846\n",
      "\n",
      "batch: 1/1 in epoch 725/1000 \n",
      "... loss: 0.002434090245515108\n",
      "\n",
      "batch: 1/1 in epoch 726/1000 \n",
      "... loss: 0.0024305821862071753\n",
      "\n",
      "batch: 1/1 in epoch 727/1000 \n",
      "... loss: 0.002427133498713374\n",
      "\n",
      "batch: 1/1 in epoch 728/1000 \n",
      "... loss: 0.0024236254394054413\n",
      "\n",
      "batch: 1/1 in epoch 729/1000 \n",
      "... loss: 0.0024201171472668648\n",
      "\n",
      "batch: 1/1 in epoch 730/1000 \n",
      "... loss: 0.0024166684597730637\n",
      "\n",
      "batch: 1/1 in epoch 731/1000 \n",
      "... loss: 0.002413160167634487\n",
      "\n",
      "batch: 1/1 in epoch 732/1000 \n",
      "... loss: 0.002409711480140686\n",
      "\n",
      "batch: 1/1 in epoch 733/1000 \n",
      "... loss: 0.0024063221644610167\n",
      "\n",
      "batch: 1/1 in epoch 734/1000 \n",
      "... loss: 0.002402814105153084\n",
      "\n",
      "batch: 1/1 in epoch 735/1000 \n",
      "... loss: 0.002399484161287546\n",
      "\n",
      "batch: 1/1 in epoch 736/1000 \n",
      "... loss: 0.0023959758691489697\n",
      "\n",
      "batch: 1/1 in epoch 737/1000 \n",
      "... loss: 0.0023927055299282074\n",
      "\n",
      "batch: 1/1 in epoch 738/1000 \n",
      "... loss: 0.002389197237789631\n",
      "\n",
      "batch: 1/1 in epoch 739/1000 \n",
      "... loss: 0.002385926665738225\n",
      "\n",
      "batch: 1/1 in epoch 740/1000 \n",
      "... loss: 0.002382418606430292\n",
      "\n",
      "batch: 1/1 in epoch 741/1000 \n",
      "... loss: 0.0023791480343788862\n",
      "\n",
      "batch: 1/1 in epoch 742/1000 \n",
      "... loss: 0.0023756991140544415\n",
      "\n",
      "batch: 1/1 in epoch 743/1000 \n",
      "... loss: 0.002372428774833679\n",
      "\n",
      "batch: 1/1 in epoch 744/1000 \n",
      "... loss: 0.002369039226323366\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 745/1000 \n",
      "... loss: 0.0023657092824578285\n",
      "\n",
      "batch: 1/1 in epoch 746/1000 \n",
      "... loss: 0.0023624387104064226\n",
      "\n",
      "batch: 1/1 in epoch 747/1000 \n",
      "... loss: 0.0023590493947267532\n",
      "\n",
      "batch: 1/1 in epoch 748/1000 \n",
      "... loss: 0.002355719218030572\n",
      "\n",
      "batch: 1/1 in epoch 749/1000 \n",
      "... loss: 0.0023525082506239414\n",
      "\n",
      "batch: 1/1 in epoch 750/1000 \n",
      "... loss: 0.0023492970503866673\n",
      "\n",
      "batch: 1/1 in epoch 751/1000 \n",
      "... loss: 0.0023459075018763542\n",
      "\n",
      "batch: 1/1 in epoch 752/1000 \n",
      "... loss: 0.002342637162655592\n",
      "\n",
      "batch: 1/1 in epoch 753/1000 \n",
      "... loss: 0.0023393663577735424\n",
      "\n",
      "batch: 1/1 in epoch 754/1000 \n",
      "... loss: 0.00233609601855278\n",
      "\n",
      "batch: 1/1 in epoch 755/1000 \n",
      "... loss: 0.002332884818315506\n",
      "\n",
      "batch: 1/1 in epoch 756/1000 \n",
      "... loss: 0.002329673618078232\n",
      "\n",
      "batch: 1/1 in epoch 757/1000 \n",
      "... loss: 0.0023264624178409576\n",
      "\n",
      "batch: 1/1 in epoch 758/1000 \n",
      "... loss: 0.0023232512176036835\n",
      "\n",
      "batch: 1/1 in epoch 759/1000 \n",
      "... loss: 0.0023200400173664093\n",
      "\n",
      "batch: 1/1 in epoch 760/1000 \n",
      "... loss: 0.002316828817129135\n",
      "\n",
      "batch: 1/1 in epoch 761/1000 \n",
      "... loss: 0.0023136772215366364\n",
      "\n",
      "batch: 1/1 in epoch 762/1000 \n",
      "... loss: 0.0023105251602828503\n",
      "\n",
      "batch: 1/1 in epoch 763/1000 \n",
      "... loss: 0.0023073735646903515\n",
      "\n",
      "batch: 1/1 in epoch 764/1000 \n",
      "... loss: 0.0023041623644530773\n",
      "\n",
      "batch: 1/1 in epoch 765/1000 \n",
      "... loss: 0.002301010536029935\n",
      "\n",
      "batch: 1/1 in epoch 766/1000 \n",
      "... loss: 0.0022978587076067924\n",
      "\n",
      "batch: 1/1 in epoch 767/1000 \n",
      "... loss: 0.0022946475073695183\n",
      "\n",
      "batch: 1/1 in epoch 768/1000 \n",
      "... loss: 0.0022916740272194147\n",
      "\n",
      "batch: 1/1 in epoch 769/1000 \n",
      "... loss: 0.0022884628269821405\n",
      "\n",
      "batch: 1/1 in epoch 770/1000 \n",
      "... loss: 0.0022853706032037735\n",
      "\n",
      "batch: 1/1 in epoch 771/1000 \n",
      "... loss: 0.002282158937305212\n",
      "\n",
      "batch: 1/1 in epoch 772/1000 \n",
      "... loss: 0.002279185689985752\n",
      "\n",
      "batch: 1/1 in epoch 773/1000 \n",
      "... loss: 0.0022760932333767414\n",
      "\n",
      "batch: 1/1 in epoch 774/1000 \n",
      "... loss: 0.0022728820331394672\n",
      "\n",
      "batch: 1/1 in epoch 775/1000 \n",
      "... loss: 0.0022699679248034954\n",
      "\n",
      "batch: 1/1 in epoch 776/1000 \n",
      "... loss: 0.002266816096380353\n",
      "\n",
      "batch: 1/1 in epoch 777/1000 \n",
      "... loss: 0.002263783011585474\n",
      "\n",
      "batch: 1/1 in epoch 778/1000 \n",
      "... loss: 0.0022607501596212387\n",
      "\n",
      "batch: 1/1 in epoch 779/1000 \n",
      "... loss: 0.0022577170748263597\n",
      "\n",
      "batch: 1/1 in epoch 780/1000 \n",
      "... loss: 0.002254683990031481\n",
      "\n",
      "batch: 1/1 in epoch 781/1000 \n",
      "... loss: 0.0022516511380672455\n",
      "\n",
      "batch: 1/1 in epoch 782/1000 \n",
      "... loss: 0.00224861828610301\n",
      "\n",
      "batch: 1/1 in epoch 783/1000 \n",
      "... loss: 0.0022455852013081312\n",
      "\n",
      "batch: 1/1 in epoch 784/1000 \n",
      "... loss: 0.0022426117211580276\n",
      "\n",
      "batch: 1/1 in epoch 785/1000 \n",
      "... loss: 0.0022396380081772804\n",
      "\n",
      "batch: 1/1 in epoch 786/1000 \n",
      "... loss: 0.002236664295196533\n",
      "\n",
      "batch: 1/1 in epoch 787/1000 \n",
      "... loss: 0.0022336910478770733\n",
      "\n",
      "batch: 1/1 in epoch 788/1000 \n",
      "... loss: 0.0022306577302515507\n",
      "\n",
      "batch: 1/1 in epoch 789/1000 \n",
      "... loss: 0.002227743621915579\n",
      "\n",
      "batch: 1/1 in epoch 790/1000 \n",
      "... loss: 0.0022247701417654753\n",
      "\n",
      "batch: 1/1 in epoch 791/1000 \n",
      "... loss: 0.00222185580059886\n",
      "\n",
      "batch: 1/1 in epoch 792/1000 \n",
      "... loss: 0.002218941692262888\n",
      "\n",
      "batch: 1/1 in epoch 793/1000 \n",
      "... loss: 0.0022159682121127844\n",
      "\n",
      "batch: 1/1 in epoch 794/1000 \n",
      "... loss: 0.0022131134755909443\n",
      "\n",
      "batch: 1/1 in epoch 795/1000 \n",
      "... loss: 0.0022100803907960653\n",
      "\n",
      "batch: 1/1 in epoch 796/1000 \n",
      "... loss: 0.0022072256542742252\n",
      "\n",
      "batch: 1/1 in epoch 797/1000 \n",
      "... loss: 0.0022043115459382534\n",
      "\n",
      "batch: 1/1 in epoch 798/1000 \n",
      "... loss: 0.0022014565765857697\n",
      "\n",
      "batch: 1/1 in epoch 799/1000 \n",
      "... loss: 0.002198602072894573\n",
      "\n",
      "batch: 1/1 in epoch 800/1000 \n",
      "... loss: 0.0021957471035420895\n",
      "\n",
      "batch: 1/1 in epoch 801/1000 \n",
      "... loss: 0.002192892599850893\n",
      "\n",
      "batch: 1/1 in epoch 802/1000 \n",
      "... loss: 0.0021899782586842775\n",
      "\n",
      "batch: 1/1 in epoch 803/1000 \n",
      "... loss: 0.0021871235221624374\n",
      "\n",
      "batch: 1/1 in epoch 804/1000 \n",
      "... loss: 0.002184328157454729\n",
      "\n",
      "batch: 1/1 in epoch 805/1000 \n",
      "... loss: 0.002181473420932889\n",
      "\n",
      "batch: 1/1 in epoch 806/1000 \n",
      "... loss: 0.002178618684411049\n",
      "\n",
      "batch: 1/1 in epoch 807/1000 \n",
      "... loss: 0.002175763715058565\n",
      "\n",
      "batch: 1/1 in epoch 808/1000 \n",
      "... loss: 0.002172908978536725\n",
      "\n",
      "batch: 1/1 in epoch 809/1000 \n",
      "... loss: 0.0021701138466596603\n",
      "\n",
      "batch: 1/1 in epoch 810/1000 \n",
      "... loss: 0.0021672588773071766\n",
      "\n",
      "batch: 1/1 in epoch 811/1000 \n",
      "... loss: 0.0021645231172442436\n",
      "\n",
      "batch: 1/1 in epoch 812/1000 \n",
      "... loss: 0.0021617277525365353\n",
      "\n",
      "batch: 1/1 in epoch 813/1000 \n",
      "... loss: 0.0021589321549981833\n",
      "\n",
      "batch: 1/1 in epoch 814/1000 \n",
      "... loss: 0.0021561963949352503\n",
      "\n",
      "batch: 1/1 in epoch 815/1000 \n",
      "... loss: 0.0021533414255827665\n",
      "\n",
      "batch: 1/1 in epoch 816/1000 \n",
      "... loss: 0.00215060543268919\n",
      "\n",
      "batch: 1/1 in epoch 817/1000 \n",
      "... loss: 0.0021479290444403887\n",
      "\n",
      "batch: 1/1 in epoch 818/1000 \n",
      "... loss: 0.0021451336797326803\n",
      "\n",
      "batch: 1/1 in epoch 819/1000 \n",
      "... loss: 0.0021423976868391037\n",
      "\n",
      "batch: 1/1 in epoch 820/1000 \n",
      "... loss: 0.0021397212985903025\n",
      "\n",
      "batch: 1/1 in epoch 821/1000 \n",
      "... loss: 0.0021369257010519505\n",
      "\n",
      "batch: 1/1 in epoch 822/1000 \n",
      "... loss: 0.0021342493128031492\n",
      "\n",
      "batch: 1/1 in epoch 823/1000 \n",
      "... loss: 0.0021315133199095726\n",
      "\n",
      "batch: 1/1 in epoch 824/1000 \n",
      "... loss: 0.0021287179552018642\n",
      "\n",
      "batch: 1/1 in epoch 825/1000 \n",
      "... loss: 0.0021261009387671947\n",
      "\n",
      "batch: 1/1 in epoch 826/1000 \n",
      "... loss: 0.0021233055740594864\n",
      "\n",
      "batch: 1/1 in epoch 827/1000 \n",
      "... loss: 0.002120688557624817\n",
      "\n",
      "batch: 1/1 in epoch 828/1000 \n",
      "... loss: 0.0021179523319005966\n",
      "\n",
      "batch: 1/1 in epoch 829/1000 \n",
      "... loss: 0.002115335315465927\n",
      "\n",
      "batch: 1/1 in epoch 830/1000 \n",
      "... loss: 0.0021126586943864822\n",
      "\n",
      "batch: 1/1 in epoch 831/1000 \n",
      "... loss: 0.0021100416779518127\n",
      "\n",
      "batch: 1/1 in epoch 832/1000 \n",
      "... loss: 0.0021073054522275925\n",
      "\n",
      "batch: 1/1 in epoch 833/1000 \n",
      "... loss: 0.002104688435792923\n",
      "\n",
      "batch: 1/1 in epoch 834/1000 \n",
      "... loss: 0.002102131024003029\n",
      "\n",
      "batch: 1/1 in epoch 835/1000 \n",
      "... loss: 0.0020993947982788086\n",
      "\n",
      "batch: 1/1 in epoch 836/1000 \n",
      "... loss: 0.0020968373864889145\n",
      "\n",
      "batch: 1/1 in epoch 837/1000 \n",
      "... loss: 0.0020942201372236013\n",
      "\n",
      "batch: 1/1 in epoch 838/1000 \n",
      "... loss: 0.0020915435161441565\n",
      "\n",
      "batch: 1/1 in epoch 839/1000 \n",
      "... loss: 0.0020889858715236187\n",
      "\n",
      "batch: 1/1 in epoch 840/1000 \n",
      "... loss: 0.002086368855088949\n",
      "\n",
      "batch: 1/1 in epoch 841/1000 \n",
      "... loss: 0.0020836922340095043\n",
      "\n",
      "batch: 1/1 in epoch 842/1000 \n",
      "... loss: 0.0020811939612030983\n",
      "\n",
      "batch: 1/1 in epoch 843/1000 \n",
      "... loss: 0.002078576944768429\n",
      "\n",
      "batch: 1/1 in epoch 844/1000 \n",
      "... loss: 0.0020760190673172474\n",
      "\n",
      "batch: 1/1 in epoch 845/1000 \n",
      "... loss: 0.0020733424462378025\n",
      "\n",
      "batch: 1/1 in epoch 846/1000 \n",
      "... loss: 0.0020708441734313965\n",
      "\n",
      "batch: 1/1 in epoch 847/1000 \n",
      "... loss: 0.0020683459006249905\n",
      "\n",
      "batch: 1/1 in epoch 848/1000 \n",
      "... loss: 0.0020657884888350964\n",
      "\n",
      "batch: 1/1 in epoch 849/1000 \n",
      "... loss: 0.002063230611383915\n",
      "\n",
      "batch: 1/1 in epoch 850/1000 \n",
      "... loss: 0.0020606727339327335\n",
      "\n",
      "batch: 1/1 in epoch 851/1000 \n",
      "... loss: 0.0020581744611263275\n",
      "\n",
      "batch: 1/1 in epoch 852/1000 \n",
      "... loss: 0.0020556170493364334\n",
      "\n",
      "batch: 1/1 in epoch 853/1000 \n",
      "... loss: 0.0020529995672404766\n",
      "\n",
      "batch: 1/1 in epoch 854/1000 \n",
      "... loss: 0.0020505012944340706\n",
      "\n",
      "batch: 1/1 in epoch 855/1000 \n",
      "... loss: 0.0020480030216276646\n",
      "\n",
      "batch: 1/1 in epoch 856/1000 \n",
      "... loss: 0.0020455047488212585\n",
      "\n",
      "batch: 1/1 in epoch 857/1000 \n",
      "... loss: 0.002043066080659628\n",
      "\n",
      "batch: 1/1 in epoch 858/1000 \n",
      "... loss: 0.002040567807853222\n",
      "\n",
      "batch: 1/1 in epoch 859/1000 \n",
      "... loss: 0.002038069535046816\n",
      "\n",
      "batch: 1/1 in epoch 860/1000 \n",
      "... loss: 0.00203557126224041\n",
      "\n",
      "batch: 1/1 in epoch 861/1000 \n",
      "... loss: 0.0020331323612481356\n",
      "\n",
      "batch: 1/1 in epoch 862/1000 \n",
      "... loss: 0.0020306934602558613\n",
      "\n",
      "batch: 1/1 in epoch 863/1000 \n",
      "... loss: 0.0020281951874494553\n",
      "\n",
      "batch: 1/1 in epoch 864/1000 \n",
      "... loss: 0.0020256969146430492\n",
      "\n",
      "batch: 1/1 in epoch 865/1000 \n",
      "... loss: 0.002023258013650775\n",
      "\n",
      "batch: 1/1 in epoch 866/1000 \n",
      "... loss: 0.002020878717303276\n",
      "\n",
      "batch: 1/1 in epoch 867/1000 \n",
      "... loss: 0.00201838044449687\n",
      "\n",
      "batch: 1/1 in epoch 868/1000 \n",
      "... loss: 0.0020158819388598204\n",
      "\n",
      "batch: 1/1 in epoch 869/1000 \n",
      "... loss: 0.002013562247157097\n",
      "\n",
      "batch: 1/1 in epoch 870/1000 \n",
      "... loss: 0.0020111827179789543\n",
      "\n",
      "batch: 1/1 in epoch 871/1000 \n",
      "... loss: 0.0020086844451725483\n",
      "\n",
      "batch: 1/1 in epoch 872/1000 \n",
      "... loss: 0.0020062453113496304\n",
      "\n",
      "batch: 1/1 in epoch 873/1000 \n",
      "... loss: 0.0020038066431879997\n",
      "\n",
      "batch: 1/1 in epoch 874/1000 \n",
      "... loss: 0.0020015460904687643\n",
      "\n",
      "batch: 1/1 in epoch 875/1000 \n",
      "... loss: 0.0019990475848317146\n",
      "\n",
      "batch: 1/1 in epoch 876/1000 \n",
      "... loss: 0.0019966682884842157\n",
      "\n",
      "batch: 1/1 in epoch 877/1000 \n",
      "... loss: 0.001994288759306073\n",
      "\n",
      "batch: 1/1 in epoch 878/1000 \n",
      "... loss: 0.0019919094629585743\n",
      "\n",
      "batch: 1/1 in epoch 879/1000 \n",
      "... loss: 0.0019895299337804317\n",
      "\n",
      "batch: 1/1 in epoch 880/1000 \n",
      "... loss: 0.0019872100092470646\n",
      "\n",
      "batch: 1/1 in epoch 881/1000 \n",
      "... loss: 0.0019847708754241467\n",
      "\n",
      "batch: 1/1 in epoch 882/1000 \n",
      "... loss: 0.001982510555535555\n",
      "\n",
      "batch: 1/1 in epoch 883/1000 \n",
      "... loss: 0.0019801310263574123\n",
      "\n",
      "batch: 1/1 in epoch 884/1000 \n",
      "... loss: 0.001977811101824045\n",
      "\n",
      "batch: 1/1 in epoch 885/1000 \n",
      "... loss: 0.0019754315726459026\n",
      "\n",
      "batch: 1/1 in epoch 886/1000 \n",
      "... loss: 0.00197305204346776\n",
      "\n",
      "batch: 1/1 in epoch 887/1000 \n",
      "... loss: 0.0019707917235791683\n",
      "\n",
      "batch: 1/1 in epoch 888/1000 \n",
      "... loss: 0.0019684121944010258\n",
      "\n",
      "batch: 1/1 in epoch 889/1000 \n",
      "... loss: 0.0019661516416817904\n",
      "\n",
      "batch: 1/1 in epoch 890/1000 \n",
      "... loss: 0.0019638314843177795\n",
      "\n",
      "batch: 1/1 in epoch 891/1000 \n",
      "... loss: 0.0019615115597844124\n",
      "\n",
      "batch: 1/1 in epoch 892/1000 \n",
      "... loss: 0.0019591916352510452\n",
      "\n",
      "batch: 1/1 in epoch 893/1000 \n",
      "... loss: 0.00195693108253181\n",
      "\n",
      "batch: 1/1 in epoch 894/1000 \n",
      "... loss: 0.001954610925167799\n",
      "\n",
      "batch: 1/1 in epoch 895/1000 \n",
      "... loss: 0.0019522910006344318\n",
      "\n",
      "batch: 1/1 in epoch 896/1000 \n",
      "... loss: 0.0019500898197293282\n",
      "\n",
      "batch: 1/1 in epoch 897/1000 \n",
      "... loss: 0.0019477697787806392\n",
      "\n",
      "batch: 1/1 in epoch 898/1000 \n",
      "... loss: 0.001945509109646082\n",
      "\n",
      "batch: 1/1 in epoch 899/1000 \n",
      "... loss: 0.0019431891851127148\n",
      "\n",
      "batch: 1/1 in epoch 900/1000 \n",
      "... loss: 0.001940988004207611\n",
      "\n",
      "batch: 1/1 in epoch 901/1000 \n",
      "... loss: 0.0019387274514883757\n",
      "\n",
      "batch: 1/1 in epoch 902/1000 \n",
      "... loss: 0.0019365263869985938\n",
      "\n",
      "batch: 1/1 in epoch 903/1000 \n",
      "... loss: 0.001934206229634583\n",
      "\n",
      "batch: 1/1 in epoch 904/1000 \n",
      "... loss: 0.0019319456769153476\n",
      "\n",
      "batch: 1/1 in epoch 905/1000 \n",
      "... loss: 0.0019298039842396975\n",
      "\n",
      "batch: 1/1 in epoch 906/1000 \n",
      "... loss: 0.001927543431520462\n",
      "\n",
      "batch: 1/1 in epoch 907/1000 \n",
      "... loss: 0.0019252232741564512\n",
      "\n",
      "batch: 1/1 in epoch 908/1000 \n",
      "... loss: 0.0019230220932513475\n",
      "\n",
      "batch: 1/1 in epoch 909/1000 \n",
      "... loss: 0.0019208805169910192\n",
      "\n",
      "batch: 1/1 in epoch 910/1000 \n",
      "... loss: 0.0019186793360859156\n",
      "\n",
      "batch: 1/1 in epoch 911/1000 \n",
      "... loss: 0.0019164782715961337\n",
      "\n",
      "batch: 1/1 in epoch 912/1000 \n",
      "... loss: 0.0019142176024615765\n",
      "\n",
      "batch: 1/1 in epoch 913/1000 \n",
      "... loss: 0.0019120759097859263\n",
      "\n",
      "batch: 1/1 in epoch 914/1000 \n",
      "... loss: 0.001909815240651369\n",
      "\n",
      "batch: 1/1 in epoch 915/1000 \n",
      "... loss: 0.0019076736643910408\n",
      "\n",
      "batch: 1/1 in epoch 916/1000 \n",
      "... loss: 0.0019054724834859371\n",
      "\n",
      "batch: 1/1 in epoch 917/1000 \n",
      "... loss: 0.0019033306743949652\n",
      "\n",
      "batch: 1/1 in epoch 918/1000 \n",
      "... loss: 0.0019011890981346369\n",
      "\n",
      "batch: 1/1 in epoch 919/1000 \n",
      "... loss: 0.001899047289043665\n",
      "\n",
      "batch: 1/1 in epoch 920/1000 \n",
      "... loss: 0.0018968461081385612\n",
      "\n",
      "batch: 1/1 in epoch 921/1000 \n",
      "... loss: 0.0018946449272334576\n",
      "\n",
      "batch: 1/1 in epoch 922/1000 \n",
      "... loss: 0.0018925033509731293\n",
      "\n",
      "batch: 1/1 in epoch 923/1000 \n",
      "... loss: 0.0018903615418821573\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 924/1000 \n",
      "... loss: 0.0018882198492065072\n",
      "\n",
      "batch: 1/1 in epoch 925/1000 \n",
      "... loss: 0.001886078156530857\n",
      "\n",
      "batch: 1/1 in epoch 926/1000 \n",
      "... loss: 0.0018839363474398851\n",
      "\n",
      "batch: 1/1 in epoch 927/1000 \n",
      "... loss: 0.0018818541429936886\n",
      "\n",
      "batch: 1/1 in epoch 928/1000 \n",
      "... loss: 0.0018797124503180385\n",
      "\n",
      "batch: 1/1 in epoch 929/1000 \n",
      "... loss: 0.00187763012945652\n",
      "\n",
      "batch: 1/1 in epoch 930/1000 \n",
      "... loss: 0.0018754885531961918\n",
      "\n",
      "batch: 1/1 in epoch 931/1000 \n",
      "... loss: 0.0018734061159193516\n",
      "\n",
      "batch: 1/1 in epoch 932/1000 \n",
      "... loss: 0.0018712644232437015\n",
      "\n",
      "batch: 1/1 in epoch 933/1000 \n",
      "... loss: 0.001869182102382183\n",
      "\n",
      "batch: 1/1 in epoch 934/1000 \n",
      "... loss: 0.001867040409706533\n",
      "\n",
      "batch: 1/1 in epoch 935/1000 \n",
      "... loss: 0.0018649580888450146\n",
      "\n",
      "batch: 1/1 in epoch 936/1000 \n",
      "... loss: 0.0018629948608577251\n",
      "\n",
      "batch: 1/1 in epoch 937/1000 \n",
      "... loss: 0.0018608530517667532\n",
      "\n",
      "batch: 1/1 in epoch 938/1000 \n",
      "... loss: 0.0018587112426757812\n",
      "\n",
      "batch: 1/1 in epoch 939/1000 \n",
      "... loss: 0.0018566884100437164\n",
      "\n",
      "batch: 1/1 in epoch 940/1000 \n",
      "... loss: 0.0018545467173680663\n",
      "\n",
      "batch: 1/1 in epoch 941/1000 \n",
      "... loss: 0.0018526429776102304\n",
      "\n",
      "batch: 1/1 in epoch 942/1000 \n",
      "... loss: 0.0018505011685192585\n",
      "\n",
      "batch: 1/1 in epoch 943/1000 \n",
      "... loss: 0.0018484187312424183\n",
      "\n",
      "batch: 1/1 in epoch 944/1000 \n",
      "... loss: 0.0018463958986103535\n",
      "\n",
      "batch: 1/1 in epoch 945/1000 \n",
      "... loss: 0.001844432670623064\n",
      "\n",
      "batch: 1/1 in epoch 946/1000 \n",
      "... loss: 0.001842290861532092\n",
      "\n",
      "batch: 1/1 in epoch 947/1000 \n",
      "... loss: 0.0018402680289000273\n",
      "\n",
      "batch: 1/1 in epoch 948/1000 \n",
      "... loss: 0.001838185708038509\n",
      "\n",
      "batch: 1/1 in epoch 949/1000 \n",
      "... loss: 0.0018362223636358976\n",
      "\n",
      "batch: 1/1 in epoch 950/1000 \n",
      "... loss: 0.0018341995310038328\n",
      "\n",
      "batch: 1/1 in epoch 951/1000 \n",
      "... loss: 0.0018321170937269926\n",
      "\n",
      "batch: 1/1 in epoch 952/1000 \n",
      "... loss: 0.0018301538657397032\n",
      "\n",
      "batch: 1/1 in epoch 953/1000 \n",
      "... loss: 0.0018281309166923165\n",
      "\n",
      "batch: 1/1 in epoch 954/1000 \n",
      "... loss: 0.0018261675722897053\n",
      "\n",
      "batch: 1/1 in epoch 955/1000 \n",
      "... loss: 0.0018241447396576405\n",
      "\n",
      "batch: 1/1 in epoch 956/1000 \n",
      "... loss: 0.0018221219070255756\n",
      "\n",
      "batch: 1/1 in epoch 957/1000 \n",
      "... loss: 0.0018201584462076426\n",
      "\n",
      "batch: 1/1 in epoch 958/1000 \n",
      "... loss: 0.0018181356135755777\n",
      "\n",
      "batch: 1/1 in epoch 959/1000 \n",
      "... loss: 0.0018161721527576447\n",
      "\n",
      "batch: 1/1 in epoch 960/1000 \n",
      "... loss: 0.0018142088083550334\n",
      "\n",
      "batch: 1/1 in epoch 961/1000 \n",
      "... loss: 0.0018122454639524221\n",
      "\n",
      "batch: 1/1 in epoch 962/1000 \n",
      "... loss: 0.001810282003134489\n",
      "\n",
      "batch: 1/1 in epoch 963/1000 \n",
      "... loss: 0.0018083186587318778\n",
      "\n",
      "batch: 1/1 in epoch 964/1000 \n",
      "... loss: 0.0018063553143292665\n",
      "\n",
      "batch: 1/1 in epoch 965/1000 \n",
      "... loss: 0.0018043918535113335\n",
      "\n",
      "batch: 1/1 in epoch 966/1000 \n",
      "... loss: 0.0018024283926934004\n",
      "\n",
      "batch: 1/1 in epoch 967/1000 \n",
      "... loss: 0.0018005245365202427\n",
      "\n",
      "batch: 1/1 in epoch 968/1000 \n",
      "... loss: 0.001798501587472856\n",
      "\n",
      "batch: 1/1 in epoch 969/1000 \n",
      "... loss: 0.0017965976148843765\n",
      "\n",
      "batch: 1/1 in epoch 970/1000 \n",
      "... loss: 0.0017945747822523117\n",
      "\n",
      "batch: 1/1 in epoch 971/1000 \n",
      "... loss: 0.0017926708096638322\n",
      "\n",
      "batch: 1/1 in epoch 972/1000 \n",
      "... loss: 0.001790707348845899\n",
      "\n",
      "batch: 1/1 in epoch 973/1000 \n",
      "... loss: 0.001788862980902195\n",
      "\n",
      "batch: 1/1 in epoch 974/1000 \n",
      "... loss: 0.001786899520084262\n",
      "\n",
      "batch: 1/1 in epoch 975/1000 \n",
      "... loss: 0.0017849360592663288\n",
      "\n",
      "batch: 1/1 in epoch 976/1000 \n",
      "... loss: 0.0017830915749073029\n",
      "\n",
      "batch: 1/1 in epoch 977/1000 \n",
      "... loss: 0.0017811877187341452\n",
      "\n",
      "batch: 1/1 in epoch 978/1000 \n",
      "... loss: 0.0017792836297303438\n",
      "\n",
      "batch: 1/1 in epoch 979/1000 \n",
      "... loss: 0.0017773797735571861\n",
      "\n",
      "batch: 1/1 in epoch 980/1000 \n",
      "... loss: 0.0017754756845533848\n",
      "\n",
      "batch: 1/1 in epoch 981/1000 \n",
      "... loss: 0.001773571828380227\n",
      "\n",
      "batch: 1/1 in epoch 982/1000 \n",
      "... loss: 0.0017716678557917476\n",
      "\n",
      "batch: 1/1 in epoch 983/1000 \n",
      "... loss: 0.001769763883203268\n",
      "\n",
      "batch: 1/1 in epoch 984/1000 \n",
      "... loss: 0.001767919398844242\n",
      "\n",
      "batch: 1/1 in epoch 985/1000 \n",
      "... loss: 0.0017660154262557626\n",
      "\n",
      "batch: 1/1 in epoch 986/1000 \n",
      "... loss: 0.0017641709418967366\n",
      "\n",
      "batch: 1/1 in epoch 987/1000 \n",
      "... loss: 0.001762266969308257\n",
      "\n",
      "batch: 1/1 in epoch 988/1000 \n",
      "... loss: 0.0017604224849492311\n",
      "\n",
      "batch: 1/1 in epoch 989/1000 \n",
      "... loss: 0.0017585183959454298\n",
      "\n",
      "batch: 1/1 in epoch 990/1000 \n",
      "... loss: 0.0017567335162311792\n",
      "\n",
      "batch: 1/1 in epoch 991/1000 \n",
      "... loss: 0.0017548294272273779\n",
      "\n",
      "batch: 1/1 in epoch 992/1000 \n",
      "... loss: 0.001752984942868352\n",
      "\n",
      "batch: 1/1 in epoch 993/1000 \n",
      "... loss: 0.001751140458509326\n",
      "\n",
      "batch: 1/1 in epoch 994/1000 \n",
      "... loss: 0.0017492363695055246\n",
      "\n",
      "batch: 1/1 in epoch 995/1000 \n",
      "... loss: 0.001747451489791274\n",
      "\n",
      "batch: 1/1 in epoch 996/1000 \n",
      "... loss: 0.0017456067726016045\n",
      "\n",
      "batch: 1/1 in epoch 997/1000 \n",
      "... loss: 0.001743821892887354\n",
      "\n",
      "batch: 1/1 in epoch 998/1000 \n",
      "... loss: 0.0017419772921130061\n",
      "\n",
      "batch: 1/1 in epoch 999/1000 \n",
      "... loss: 0.0017401922959834337\n",
      "\n",
      "batch: 1/1 in epoch 1000/1000 \n",
      "... loss: 0.0017382882069796324\n",
      "\n",
      "\n",
      "[[0, 1.3776636123657227], [1, 1.2420530319213867], [2, 1.0579910278320312], [3, 0.8742104172706604], [4, 0.7135658264160156], [5, 0.582996129989624], [6, 0.4809767007827759], [7, 0.4026193618774414], [8, 0.3425494432449341], [9, 0.29613444209098816], [10, 0.2597839832305908], [11, 0.23085461556911469], [12, 0.20744377374649048], [13, 0.1881902515888214], [14, 0.17211714386940002], [15, 0.15851622819900513], [16, 0.14686760306358337], [17, 0.13678394258022308], [18, 0.1279723048210144], [19, 0.12020787596702576], [20, 0.11331532895565033], [21, 0.10715645551681519], [22, 0.10162036865949631], [23, 0.09661777317523956], [24, 0.09207554161548615], [25, 0.08793331682682037], [26, 0.08414061367511749], [27, 0.0806553065776825], [28, 0.07744182646274567], [29, 0.07446970045566559], [30, 0.07171282917261124], [31, 0.06914886832237244], [32, 0.06675848364830017], [33, 0.06452459841966629], [34, 0.06243255361914635], [35, 0.06046926975250244], [36, 0.05862332507967949], [37, 0.056884560734033585], [38, 0.05524395778775215], [39, 0.05369347333908081], [40, 0.05222600698471069], [41, 0.05083507299423218], [42, 0.04951487481594086], [43, 0.048260290175676346], [44, 0.047066397964954376], [45, 0.04592909291386604], [46, 0.04484429210424423], [47, 0.0438084602355957], [48, 0.04281872510910034], [49, 0.041871801018714905], [50, 0.0409649983048439], [51, 0.04009585082530975], [52, 0.03926216810941696], [53, 0.03846180438995361], [54, 0.037692710757255554], [55, 0.03695324435830116], [56, 0.0362415686249733], [57, 0.035556480288505554], [58, 0.03489607572555542], [59, 0.034259483218193054], [60, 0.03364507853984833], [61, 0.03305209428071976], [62, 0.0324791818857193], [63, 0.03192534297704697], [64, 0.031389735639095306], [65, 0.03087141364812851], [66, 0.030369646847248077], [67, 0.029883652925491333], [68, 0.0294126458466053], [69, 0.028956007212400436], [70, 0.028513005003333092], [71, 0.028083136305212975], [72, 0.027665723115205765], [73, 0.027260370552539825], [74, 0.02686646208167076], [75, 0.026483483612537384], [76, 0.026111219078302383], [77, 0.025748923420906067], [78, 0.025396432727575302], [79, 0.025053292512893677], [80, 0.02471904642879963], [81, 0.02439347468316555], [82, 0.024076290428638458], [83, 0.02376692183315754], [84, 0.023465316742658615], [85, 0.02317119389772415], [86, 0.022884149104356766], [87, 0.022604014724493027], [88, 0.022330446168780327], [89, 0.02206333354115486], [90, 0.0218025054782629], [91, 0.021547500044107437], [92, 0.021298326551914215], [93, 0.021054863929748535], [94, 0.02081659995019436], [95, 0.020583707839250565], [96, 0.020355960354208946], [97, 0.02013283222913742], [98, 0.019914623349905014], [99, 0.01970098167657852], [100, 0.019491679966449738], [101, 0.019286837428808212], [102, 0.01908610202372074], [103, 0.018889421597123146], [104, 0.018696680665016174], [105, 0.018507765606045723], [106, 0.018322616815567017], [107, 0.0181410051882267], [108, 0.01796281524002552], [109, 0.017788104712963104], [110, 0.01761670410633087], [111, 0.017448436468839645], [112, 0.0172833614051342], [113, 0.017121247947216034], [114, 0.016962215304374695], [115, 0.016805969178676605], [116, 0.01665257290005684], [117, 0.016501788049936295], [118, 0.01635373942553997], [119, 0.01620824821293354], [120, 0.016065258532762527], [121, 0.015924770385026932], [122, 0.015786610543727875], [123, 0.015650834888219833], [124, 0.015517331659793854], [125, 0.01538598258048296], [126, 0.015256786718964577], [127, 0.015129806473851204], [128, 0.01500486396253109], [129, 0.014881845563650131], [130, 0.014760807156562805], [131, 0.014641692861914635], [132, 0.014524385333061218], [133, 0.014409061521291733], [134, 0.014295371249318123], [135, 0.014183547347784042], [136, 0.014073297381401062], [137, 0.013964798301458359], [138, 0.01385793462395668], [139, 0.013752587139606476], [140, 0.013648875057697296], [141, 0.013546681962907314], [142, 0.013445889577269554], [143, 0.013346615247428417], [144, 0.013248860836029053], [145, 0.013152332976460457], [146, 0.013057323172688484], [147, 0.01296360045671463], [148, 0.01287110522389412], [149, 0.01278001256287098], [150, 0.012690089643001556], [151, 0.012601394206285477], [152, 0.012513985857367516], [153, 0.012427687644958496], [154, 0.012342561036348343], [155, 0.012258604168891907], [156, 0.012175758369266987], [157, 0.012093907222151756], [158, 0.012013226747512817], [159, 0.011933600530028343], [160, 0.011855028569698334], [161, 0.011777333915233612], [162, 0.01170063391327858], [163, 0.011624989099800587], [164, 0.011550339870154858], [165, 0.011476568877696991], [166, 0.011403735727071762], [167, 0.011331722140312195], [168, 0.011260705068707466], [169, 0.011190509423613548], [170, 0.011121073737740517], [171, 0.011052576825022697], [172, 0.01098489947617054], [173, 0.010918045416474342], [174, 0.010852009989321232], [175, 0.01078661996871233], [176, 0.01072211004793644], [177, 0.010658244602382183], [178, 0.010595260187983513], [179, 0.010532919317483902], [180, 0.010471401736140251], [181, 0.010410410352051258], [182, 0.010350299999117851], [183, 0.01029065903276205], [184, 0.01023172214627266], [185, 0.010173607617616653], [186, 0.01011602021753788], [187, 0.010059019550681114], [188, 0.010002784430980682], [189, 0.009947016835212708], [190, 0.009892072528600693], [191, 0.009837479330599308], [192, 0.009783592075109482], [193, 0.009730173274874687], [194, 0.009677400812506676], [195, 0.009625334292650223], [196, 0.009573619812726974], [197, 0.009522492997348309], [198, 0.00947195291519165], [199, 0.009421765804290771], [200, 0.009372225031256676], [201, 0.009323213249444962], [202, 0.009274671785533428], [203, 0.009226659312844276], [204, 0.009179058484733105], [205, 0.00913192704319954], [206, 0.009085385128855705], [207, 0.009039253927767277], [208, 0.008993592113256454], [209, 0.008948284201323986], [210, 0.008903564885258675], [211, 0.008859196677803993], [212, 0.008815182372927666], [213, 0.008771639317274094], [214, 0.00872868299484253], [215, 0.008686021901667118], [216, 0.008643712848424911], [217, 0.00860181637108326], [218, 0.008560331538319588], [219, 0.008519317954778671], [220, 0.00847865641117096], [221, 0.008438289165496826], [222, 0.008398334495723248], [223, 0.008358791470527649], [224, 0.008319542743265629], [225, 0.008280705660581589], [226, 0.008242163807153702], [227, 0.008204033598303795], [228, 0.008166197687387466], [229, 0.008128715679049492], [230, 0.008091645315289497], [231, 0.008054869249463081], [232, 0.008018387481570244], [233, 0.007982200011610985], [234, 0.00794642511755228], [235, 0.007910944521427155], [236, 0.007875639945268631], [237, 0.007840808480978012], [238, 0.007806151639670134], [239, 0.007771849632263184], [240, 0.0077379010617733], [241, 0.007704246789216995], [242, 0.0076707093976438046], [243, 0.007637585513293743], [244, 0.007604696787893772], [245, 0.007572102826088667], [246, 0.007539744488894939], [247, 0.007507799193263054], [248, 0.00747597124427557], [249, 0.007444438058882952], [250, 0.007413200102746487], [251, 0.007382138166576624], [252, 0.007351430132985115], [253, 0.007320958189666271], [254, 0.007290663197636604], [255, 0.0072606028988957405], [256, 0.007230779156088829], [257, 0.007201428059488535], [258, 0.007172076031565666], [259, 0.007143018767237663], [260, 0.007114078849554062], [261, 0.007085552904754877], [262, 0.007057144306600094], [263, 0.007029030472040176], [264, 0.007001094054430723], [265, 0.0069732749834656715], [266, 0.006945750676095486], [267, 0.0069185225293040276], [268, 0.006891411263495684], [269, 0.006864476948976517], [270, 0.006837897002696991], [271, 0.006811435334384441], [272, 0.006785149686038494], [273, 0.006758982315659523], [274, 0.0067332289181649685], [275, 0.006707474589347839], [276, 0.006681956350803375], [277, 0.006656615063548088], [278, 0.006631509866565466], [279, 0.00660652294754982], [280, 0.006581890396773815], [281, 0.006557316519320011], [282, 0.006532919593155384], [283, 0.006508699618279934], [284, 0.006484656594693661], [285, 0.006460731849074364], [286, 0.00643710233271122], [287, 0.006413531489670277], [288, 0.006390138063579798], [289, 0.006366981193423271], [290, 0.006344000808894634], [291, 0.006321079563349485], [292, 0.006298394408077002], [293, 0.006275886669754982], [294, 0.006253437604755163], [295, 0.0062312837690114975], [296, 0.006209189537912607], [297, 0.006187272258102894], [298, 0.006165413185954094], [299, 0.006143850274384022], [300, 0.00612234603613615], [301, 0.006101078353822231], [302, 0.006079810205847025], [303, 0.006058778613805771], [304, 0.006037924438714981], [305, 0.00601718807592988], [306, 0.005996569991111755], [307, 0.005976010579615831], [308, 0.005955747328698635], [309, 0.005935483146458864], [310, 0.005915396846830845], [311, 0.005895428359508514], [312, 0.005875636823475361], [313, 0.005855964031070471], [314, 0.005836468189954758], [315, 0.005817031487822533], [316, 0.005797713063657284], [317, 0.005778512451797724], [318, 0.005759489722549915], [319, 0.00574052520096302], [320, 0.005721738561987877], [321, 0.005703129805624485], [322, 0.005684460513293743], [323, 0.005665969103574753], [324, 0.005647714249789715], [325, 0.005629459396004677], [326, 0.005611381493508816], [327, 0.005593481939285994], [328, 0.005575581453740597], [329, 0.0055577997118234634], [330, 0.005540076643228531], [331, 0.005522590130567551], [332, 0.005505162291228771], [333, 0.0054878536611795425], [334, 0.005470544099807739], [335, 0.005453471094369888], [336, 0.005436516832560301], [337, 0.005419562570750713], [338, 0.005402844399213791], [339, 0.00538606708869338], [340, 0.005369408056139946], [341, 0.005353044718503952], [342, 0.005336503963917494], [343, 0.005320259369909763], [344, 0.005304073449224234], [345, 0.005287887062877417], [346, 0.005271937698125839], [347, 0.005255929194390774], [348, 0.005240216851234436], [349, 0.005224444437772036], [350, 0.005208790767937899], [351, 0.00519319623708725], [352, 0.005177779123187065], [353, 0.005162420682609081], [354, 0.005147181451320648], [355, 0.005132000893354416], [356, 0.005116760730743408], [357, 0.005101816728711128], [358, 0.005086932331323624], [359, 0.0050720470026135445], [360, 0.005057280883193016], [361, 0.005042573437094688], [362, 0.0050279246643185616], [363, 0.005013513378798962], [364, 0.004999102093279362], [365, 0.004984749015420675], [366, 0.00497051514685154], [367, 0.004956280812621117], [368, 0.00494216475635767], [369, 0.004928108304738998], [370, 0.004914228804409504], [371, 0.004900231491774321], [372, 0.004886529874056578], [373, 0.004872709512710571], [374, 0.0048591261729598045], [375, 0.004845602437853813], [376, 0.0048320782370865345], [377, 0.004818612709641457], [378, 0.0048052663914859295], [379, 0.004791978746652603], [380, 0.004778750240802765], [381, 0.00476564047858119], [382, 0.0047526489943265915], [383, 0.004739538766443729], [384, 0.004726725164800882], [385, 0.00471385195851326], [386, 0.004701037425547838], [387, 0.004688282497227192], [388, 0.004675646312534809], [389, 0.004663068801164627], [390, 0.004650550428777933], [391, 0.0046380916610360146], [392, 0.004625632427632809], [393, 0.004613351076841354], [394, 0.0046010697260499], [395, 0.004588966257870197], [396, 0.004576862324029207], [397, 0.004564698785543442], [398, 0.004552713595330715], [399, 0.004540668800473213], [400, 0.004528861492872238], [401, 0.0045169941149652], [402, 0.004505245480686426], [403, 0.00449355598539114], [404, 0.004481866955757141], [405, 0.004470354877412319], [406, 0.004458664916455746], [407, 0.0044472720474004745], [408, 0.004435878247022629], [409, 0.004424485377967358], [410, 0.004413209855556488], [411, 0.004401934798806906], [412, 0.004390719346702099], [413, 0.004379621706902981], [414, 0.004368583671748638], [415, 0.004357605241239071], [416, 0.004346566274762154], [417, 0.0043357061222195625], [418, 0.004324786365032196], [419, 0.004314044490456581], [420, 0.004303183406591415], [421, 0.004292501136660576], [422, 0.004281936213374138], [423, 0.004271253477782011], [424, 0.004260748624801636], [425, 0.004250243306159973], [426, 0.0042397379875183105], [427, 0.004229350946843624], [428, 0.004219023510813713], [429, 0.00420875521376729], [430, 0.004198427777737379], [431, 0.004188396502286196], [432, 0.004178068600594997], [433, 0.0041680969297885895], [434, 0.004157946910709143], [435, 0.0041479747742414474], [436, 0.00413806177675724], [437, 0.004128089640289545], [438, 0.004118176642805338], [439, 0.00410850066691637], [440, 0.004098647274076939], [441, 0.004088970832526684], [442, 0.004079295322299004], [443, 0.004069619346410036], [444, 0.004060002509504557], [445, 0.004050444811582565], [446, 0.004040946718305349], [447, 0.004031448625028133], [448, 0.004022068344056606], [449, 0.004012688994407654], [450, 0.0040034279227256775], [451, 0.003993988037109375], [452, 0.0039848461747169495], [453, 0.003975643776357174], [454, 0.003966441843658686], [455, 0.0039572990499436855], [456, 0.003948274999856949], [457, 0.003939132206141949], [458, 0.003930225968360901], [459, 0.003921201918274164], [460, 0.003912236541509628], [461, 0.0039034495130181313], [462, 0.003894602879881859], [463, 0.0038856971077620983], [464, 0.0038770283572375774], [465, 0.0038682410959154367], [466, 0.003859572345390916], [467, 0.0038509629666805267], [468, 0.003842353355139494], [469, 0.003833743743598461], [470, 0.0038251937367022038], [471, 0.0038168213795870543], [472, 0.003808271139860153], [473, 0.0037997798062860966], [474, 0.0037914076820015907], [475, 0.0037830350920557976], [476, 0.003774721873924136], [477, 0.0037665273994207382], [478, 0.003758273320272565], [479, 0.003750019473955035], [480, 0.00374182453379035], [481, 0.0037336298264563084], [482, 0.003725613234564662], [483, 0.003717477899044752], [484, 0.003709461074322462], [485, 0.003701444249600172], [486, 0.00369348656386137], [487, 0.003685528878122568], [488, 0.003677571192383766], [489, 0.0036697322502732277], [490, 0.003661893308162689], [491, 0.0036540543660521507], [492, 0.003646333934739232], [493, 0.003638553898781538], [494, 0.0036309524439275265], [495, 0.003623231779783964], [496, 0.0036155704874545336], [497, 0.0036079687997698784], [498, 0.003600485622882843], [499, 0.0035929428413510323], [500, 0.0035852815490216017], [501, 0.0035778575111180544], [502, 0.0035703741014003754], [503, 0.003562950063496828], [504, 0.0035555853974074125], [505, 0.00354810175485909], [506, 0.003540914971381426], [507, 0.0035334909334778786], [508, 0.0035263041500002146], [509, 0.003518998622894287], [510, 0.0035117524676024914], [511, 0.003504624590277672], [512, 0.003497437806800008], [513, 0.003490310162305832], [514, 0.003483182517811656], [515, 0.003476114245131612], [516, 0.003469045739620924], [517, 0.0034620368387550116], [518, 0.0034551466815173626], [519, 0.003448018804192543], [520, 0.003441247157752514], [521, 0.003434238024055958], [522, 0.003427347633987665], [523, 0.0034205163829028606], [524, 0.0034136257600039244], [525, 0.0034068538807332516], [526, 0.0034000822342932224], [527, 0.003393310122191906], [528, 0.003386597614735365], [529, 0.003379885107278824], [530, 0.003373172599822283], [531, 0.0033665786031633615], [532, 0.0033599254675209522], [533, 0.0033533908426761627], [534, 0.0033467968460172415], [535, 0.003340262221172452], [536, 0.0033337275963276625], [537, 0.0033272523432970047], [538, 0.0033207174856215715], [539, 0.0033142422325909138], [540, 0.003307826118543744], [541, 0.003301469376310706], [542, 0.0032951720058918], [543, 0.003288756124675274], [544, 0.003282399382442236], [545, 0.003276101779192686], [546, 0.0032698637805879116], [547, 0.0032635661773383617], [548, 0.0032574469223618507], [549, 0.003251090180128813], [550, 0.00324503006413579], [551, 0.00323873246088624], [552, 0.003232672344893217], [553, 0.003226612228900194], [554, 0.0032205521129071712], [555, 0.0032144919969141483], [556, 0.0032084318809211254], [557, 0.0032023717649281025], [558, 0.003196311416104436], [559, 0.0031903106719255447], [560, 0.0031843690667301416], [561, 0.003178487066179514], [562, 0.0031724858563393354], [563, 0.003166662994772196], [564, 0.0031607216224074364], [565, 0.003154898528009653], [566, 0.003149075899273157], [567, 0.003143252804875374], [568, 0.003137429943308234], [569, 0.003131725825369358], [570, 0.00312596233561635], [571, 0.0031202579848468304], [572, 0.0031144944950938225], [573, 0.003108908887952566], [574, 0.0031032045371830463], [575, 0.0030975001864135265], [576, 0.003091855440288782], [577, 0.0030863292049616575], [578, 0.003080743597820401], [579, 0.003075098618865013], [580, 0.0030695723835378885], [581, 0.003064046148210764], [582, 0.0030585199128836393], [583, 0.003053052816540003], [584, 0.00304758595302701], [585, 0.003042119089514017], [586, 0.0030367709696292877], [587, 0.003031303873285651], [588, 0.00302589638158679], [589, 0.0030204886570572853], [590, 0.003015140537172556], [591, 0.0030098515562713146], [592, 0.0030045032035559416], [593, 0.0029992142226547003], [594, 0.0029939846135675907], [595, 0.0029886956326663494], [596, 0.0029834662564098835], [597, 0.002978177275508642], [598, 0.0029730070382356644], [599, 0.0029678368009626865], [600, 0.0029625478200614452], [601, 0.002957496326416731], [602, 0.0029522664844989777], [603, 0.0029472149908542633], [604, 0.002942163497209549], [605, 0.002936993259936571], [606, 0.0029319417662918568], [607, 0.0029269494116306305], [608, 0.002921897917985916], [609, 0.002916846191510558], [610, 0.0029119134414941072], [611, 0.0029069213196635246], [612, 0.0029019289650022984], [613, 0.002896936610341072], [614, 0.002891944255679846], [615, 0.0028871302492916584], [616, 0.002882137894630432], [617, 0.0028772642835974693], [618, 0.002872450277209282], [619, 0.0028675172943621874], [620, 0.0028627626597881317], [621, 0.0028578294441103935], [622, 0.002853074576705694], [623, 0.0028482009656727314], [624, 0.002843565074726939], [625, 0.0028388104401528835], [626, 0.002833995968103409], [627, 0.002829359844326973], [628, 0.0028246049769222736], [629, 0.0028198501095175743], [630, 0.0028152139857411385], [631, 0.0028105778619647026], [632, 0.0028058229945600033], [633, 0.0028011868707835674], [634, 0.002796669490635395], [635, 0.002792092738673091], [636, 0.002787515986710787], [637, 0.0027828796301037073], [638, 0.0027782435063272715], [639, 0.0027737258933484554], [640, 0.0027692681178450584], [641, 0.0027646911330521107], [642, 0.002760114148259163], [643, 0.0027557751163840294], [644, 0.0027511981315910816], [645, 0.002746859099715948], [646, 0.0027422821149230003], [647, 0.002737942850217223], [648, 0.0027333658654242754], [649, 0.00272908597253263], [650, 0.002724687336012721], [651, 0.0027202884666621685], [652, 0.0027159489691257477], [653, 0.002711490960791707], [654, 0.002707210835069418], [655, 0.0027029309421777725], [656, 0.002698651049286127], [657, 0.0026943711563944817], [658, 0.0026900912635028362], [659, 0.002685811137780547], [660, 0.0026815906167030334], [661, 0.0026773104909807444], [662, 0.0026730303652584553], [663, 0.00266875047236681], [664, 0.0026645297184586525], [665, 0.0026604277081787586], [666, 0.0026562665589153767], [667, 0.0026520458050072193], [668, 0.0026478846557438374], [669, 0.002643842250108719], [670, 0.002639681100845337], [671, 0.002635579090565443], [672, 0.0026314177084714174], [673, 0.0026273750700056553], [674, 0.002623273292556405], [675, 0.002619171282276511], [676, 0.0026151882484555244], [677, 0.002611145842820406], [678, 0.002607043832540512], [679, 0.0026030605658888817], [680, 0.0025990772992372513], [681, 0.0025951536372303963], [682, 0.002591111231595278], [683, 0.002587068360298872], [684, 0.002583144698292017], [685, 0.002579221036285162], [686, 0.002575297374278307], [687, 0.0025713732466101646], [688, 0.0025674495846033096], [689, 0.002563525689765811], [690, 0.0025596613995730877], [691, 0.0025557968765497208], [692, 0.0025519919581711292], [693, 0.002548127667978406], [694, 0.0025442037731409073], [695, 0.002540457993745804], [696, 0.002536593470722437], [697, 0.0025327885523438454], [698, 0.0025290430057793856], [699, 0.0025251784827560186], [700, 0.002521432936191559], [701, 0.0025176871567964554], [702, 0.002513941377401352], [703, 0.002510195830836892], [704, 0.0025064502842724323], [705, 0.0025027638766914606], [706, 0.002499018330127001], [707, 0.002495331922546029], [708, 0.0024916455149650574], [709, 0.0024879593402147293], [710, 0.0024842731654644012], [711, 0.0024807057343423367], [712, 0.002477019326761365], [713, 0.0024734518956393003], [714, 0.002469825092703104], [715, 0.002466198056936264], [716, 0.0024625116493552923], [717, 0.002458884846419096], [718, 0.0024553765542805195], [719, 0.002451809123158455], [720, 0.0024482416920363903], [721, 0.0024446742609143257], [722, 0.002441165968775749], [723, 0.0024375985376536846], [724, 0.002434090245515108], [725, 0.0024305821862071753], [726, 0.002427133498713374], [727, 0.0024236254394054413], [728, 0.0024201171472668648], [729, 0.0024166684597730637], [730, 0.002413160167634487], [731, 0.002409711480140686], [732, 0.0024063221644610167], [733, 0.002402814105153084], [734, 0.002399484161287546], [735, 0.0023959758691489697], [736, 0.0023927055299282074], [737, 0.002389197237789631], [738, 0.002385926665738225], [739, 0.002382418606430292], [740, 0.0023791480343788862], [741, 0.0023756991140544415], [742, 0.002372428774833679], [743, 0.002369039226323366], [744, 0.0023657092824578285], [745, 0.0023624387104064226], [746, 0.0023590493947267532], [747, 0.002355719218030572], [748, 0.0023525082506239414], [749, 0.0023492970503866673], [750, 0.0023459075018763542], [751, 0.002342637162655592], [752, 0.0023393663577735424], [753, 0.00233609601855278], [754, 0.002332884818315506], [755, 0.002329673618078232], [756, 0.0023264624178409576], [757, 0.0023232512176036835], [758, 0.0023200400173664093], [759, 0.002316828817129135], [760, 0.0023136772215366364], [761, 0.0023105251602828503], [762, 0.0023073735646903515], [763, 0.0023041623644530773], [764, 0.002301010536029935], [765, 0.0022978587076067924], [766, 0.0022946475073695183], [767, 0.0022916740272194147], [768, 0.0022884628269821405], [769, 0.0022853706032037735], [770, 0.002282158937305212], [771, 0.002279185689985752], [772, 0.0022760932333767414], [773, 0.0022728820331394672], [774, 0.0022699679248034954], [775, 0.002266816096380353], [776, 0.002263783011585474], [777, 0.0022607501596212387], [778, 0.0022577170748263597], [779, 0.002254683990031481], [780, 0.0022516511380672455], [781, 0.00224861828610301], [782, 0.0022455852013081312], [783, 0.0022426117211580276], [784, 0.0022396380081772804], [785, 0.002236664295196533], [786, 0.0022336910478770733], [787, 0.0022306577302515507], [788, 0.002227743621915579], [789, 0.0022247701417654753], [790, 0.00222185580059886], [791, 0.002218941692262888], [792, 0.0022159682121127844], [793, 0.0022131134755909443], [794, 0.0022100803907960653], [795, 0.0022072256542742252], [796, 0.0022043115459382534], [797, 0.0022014565765857697], [798, 0.002198602072894573], [799, 0.0021957471035420895], [800, 0.002192892599850893], [801, 0.0021899782586842775], [802, 0.0021871235221624374], [803, 0.002184328157454729], [804, 0.002181473420932889], [805, 0.002178618684411049], [806, 0.002175763715058565], [807, 0.002172908978536725], [808, 0.0021701138466596603], [809, 0.0021672588773071766], [810, 0.0021645231172442436], [811, 0.0021617277525365353], [812, 0.0021589321549981833], [813, 0.0021561963949352503], [814, 0.0021533414255827665], [815, 0.00215060543268919], [816, 0.0021479290444403887], [817, 0.0021451336797326803], [818, 0.0021423976868391037], [819, 0.0021397212985903025], [820, 0.0021369257010519505], [821, 0.0021342493128031492], [822, 0.0021315133199095726], [823, 0.0021287179552018642], [824, 0.0021261009387671947], [825, 0.0021233055740594864], [826, 0.002120688557624817], [827, 0.0021179523319005966], [828, 0.002115335315465927], [829, 0.0021126586943864822], [830, 0.0021100416779518127], [831, 0.0021073054522275925], [832, 0.002104688435792923], [833, 0.002102131024003029], [834, 0.0020993947982788086], [835, 0.0020968373864889145], [836, 0.0020942201372236013], [837, 0.0020915435161441565], [838, 0.0020889858715236187], [839, 0.002086368855088949], [840, 0.0020836922340095043], [841, 0.0020811939612030983], [842, 0.002078576944768429], [843, 0.0020760190673172474], [844, 0.0020733424462378025], [845, 0.0020708441734313965], [846, 0.0020683459006249905], [847, 0.0020657884888350964], [848, 0.002063230611383915], [849, 0.0020606727339327335], [850, 0.0020581744611263275], [851, 0.0020556170493364334], [852, 0.0020529995672404766], [853, 0.0020505012944340706], [854, 0.0020480030216276646], [855, 0.0020455047488212585], [856, 0.002043066080659628], [857, 0.002040567807853222], [858, 0.002038069535046816], [859, 0.00203557126224041], [860, 0.0020331323612481356], [861, 0.0020306934602558613], [862, 0.0020281951874494553], [863, 0.0020256969146430492], [864, 0.002023258013650775], [865, 0.002020878717303276], [866, 0.00201838044449687], [867, 0.0020158819388598204], [868, 0.002013562247157097], [869, 0.0020111827179789543], [870, 0.0020086844451725483], [871, 0.0020062453113496304], [872, 0.0020038066431879997], [873, 0.0020015460904687643], [874, 0.0019990475848317146], [875, 0.0019966682884842157], [876, 0.001994288759306073], [877, 0.0019919094629585743], [878, 0.0019895299337804317], [879, 0.0019872100092470646], [880, 0.0019847708754241467], [881, 0.001982510555535555], [882, 0.0019801310263574123], [883, 0.001977811101824045], [884, 0.0019754315726459026], [885, 0.00197305204346776], [886, 0.0019707917235791683], [887, 0.0019684121944010258], [888, 0.0019661516416817904], [889, 0.0019638314843177795], [890, 0.0019615115597844124], [891, 0.0019591916352510452], [892, 0.00195693108253181], [893, 0.001954610925167799], [894, 0.0019522910006344318], [895, 0.0019500898197293282], [896, 0.0019477697787806392], [897, 0.001945509109646082], [898, 0.0019431891851127148], [899, 0.001940988004207611], [900, 0.0019387274514883757], [901, 0.0019365263869985938], [902, 0.001934206229634583], [903, 0.0019319456769153476], [904, 0.0019298039842396975], [905, 0.001927543431520462], [906, 0.0019252232741564512], [907, 0.0019230220932513475], [908, 0.0019208805169910192], [909, 0.0019186793360859156], [910, 0.0019164782715961337], [911, 0.0019142176024615765], [912, 0.0019120759097859263], [913, 0.001909815240651369], [914, 0.0019076736643910408], [915, 0.0019054724834859371], [916, 0.0019033306743949652], [917, 0.0019011890981346369], [918, 0.001899047289043665], [919, 0.0018968461081385612], [920, 0.0018946449272334576], [921, 0.0018925033509731293], [922, 0.0018903615418821573], [923, 0.0018882198492065072], [924, 0.001886078156530857], [925, 0.0018839363474398851], [926, 0.0018818541429936886], [927, 0.0018797124503180385], [928, 0.00187763012945652], [929, 0.0018754885531961918], [930, 0.0018734061159193516], [931, 0.0018712644232437015], [932, 0.001869182102382183], [933, 0.001867040409706533], [934, 0.0018649580888450146], [935, 0.0018629948608577251], [936, 0.0018608530517667532], [937, 0.0018587112426757812], [938, 0.0018566884100437164], [939, 0.0018545467173680663], [940, 0.0018526429776102304], [941, 0.0018505011685192585], [942, 0.0018484187312424183], [943, 0.0018463958986103535], [944, 0.001844432670623064], [945, 0.001842290861532092], [946, 0.0018402680289000273], [947, 0.001838185708038509], [948, 0.0018362223636358976], [949, 0.0018341995310038328], [950, 0.0018321170937269926], [951, 0.0018301538657397032], [952, 0.0018281309166923165], [953, 0.0018261675722897053], [954, 0.0018241447396576405], [955, 0.0018221219070255756], [956, 0.0018201584462076426], [957, 0.0018181356135755777], [958, 0.0018161721527576447], [959, 0.0018142088083550334], [960, 0.0018122454639524221], [961, 0.001810282003134489], [962, 0.0018083186587318778], [963, 0.0018063553143292665], [964, 0.0018043918535113335], [965, 0.0018024283926934004], [966, 0.0018005245365202427], [967, 0.001798501587472856], [968, 0.0017965976148843765], [969, 0.0017945747822523117], [970, 0.0017926708096638322], [971, 0.001790707348845899], [972, 0.001788862980902195], [973, 0.001786899520084262], [974, 0.0017849360592663288], [975, 0.0017830915749073029], [976, 0.0017811877187341452], [977, 0.0017792836297303438], [978, 0.0017773797735571861], [979, 0.0017754756845533848], [980, 0.001773571828380227], [981, 0.0017716678557917476], [982, 0.001769763883203268], [983, 0.001767919398844242], [984, 0.0017660154262557626], [985, 0.0017641709418967366], [986, 0.001762266969308257], [987, 0.0017604224849492311], [988, 0.0017585183959454298], [989, 0.0017567335162311792], [990, 0.0017548294272273779], [991, 0.001752984942868352], [992, 0.001751140458509326], [993, 0.0017492363695055246], [994, 0.001747451489791274], [995, 0.0017456067726016045], [996, 0.001743821892887354], [997, 0.0017419772921130061], [998, 0.0017401922959834337], [999, 0.0017382882069796324]]\n",
      "batch: 1/2\n",
      "... correct: 1\n",
      "\n",
      "average test loss: 0.0017364437226206064, relative correct: 1.0\n",
      "\n",
      "confusion:\n",
      "[[1, 1], [1, 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# debug set\n",
    "net_full = Lin_Net(8, 4, 64, 64, act_function)\n",
    "plot = train(train_loader_debug, net_full, 1000, criterion, 100, \"debug\", cuda)\n",
    "plt.plot([item[0] for item in plot], [item[1] for item in plot])\n",
    "test(test_loader_debug, net_full, criterion, 100, \"debug\", cuda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyDataset object at 0x7ffa820a2c50>\n"
     ]
    }
   ],
   "source": [
    "# create nets\n",
    "print(\"creating nets\")\n",
    "print(\"-------- net_lin_emotion_full\")\n",
    "net_full = Lin_Net(8, 4, 64, 64, act_function)\n",
    "train(train_loader_emotion_full, net_full, 100, criterion, 5000, \"../logs/net_lin_emotion_full\", 0.1)\n",
    "test(test_loader_emotion_full, net_full, criterion, 1000, \"../logs/net_lin_emotion_full\")\n",
    "print(\"-------- net_lin_emotion_nolex\")\n",
    "net_half = Lin_Net(4, 4, 64, 64, act_function)\n",
    "train(train_loader_emotion_nolex, net_half, 100, criterion, 5000, \"../logs/net_lin_emotion_nolex\", 0.1)\n",
    "test(test_loader_emotion_nolex, net_half, criterion, 1000, \"../logs/net_lin_emotion_nolex\")\n",
    "print(\"-------- net_lin_emotion_lex\")\n",
    "net_half = Lin_Net(4, 4, 64, 64, act_function)\n",
    "train(train_loader_emotion_lex, net_half, 100, criterion, 5000, \"../logs/net_lin_emotion_lex\", 0.1)\n",
    "test(test_loader_emotion_lex, net_half, criterion, 1000, \"../logs/net_lin_emotion_lex\")\n",
    "print(\"-------- net_lin_emotion_full\")\n",
    "net_full = Lin_Net(8, 4, 64, 64, act_function)\n",
    "train(train_loader_tweet_full, net_full, 100, criterion, 5000, \"../logs/net_tweet_full\", 0.1)\n",
    "test(test_loader_tweet_full, net_full, criterion, 1000, \"../logs/net_lin_tweet_full\")\n",
    "print(\"-------- net_lin_tweet_nolex\")\n",
    "net_half = Lin_Net(4, 4, 64, 64, act_function)\n",
    "train(train_loader_tweet_nolex, net_half, 100, criterion, 5000, \"../logs/net_tweet_nolex\", 0.1)\n",
    "test(test_loader_tweet_nolex, net_half, criterion, 1000, \"../logs/net_lin_tweet_nolex\")\n",
    "print(\"-------- net_lin_tweet_lex\")\n",
    "net_half = Lin_Net(4, 4, 64, 64, act_function)\n",
    "train(train_loader_tweet_lex, net_half, 100, criterion, 5000, \"../logs/net_tweet_lex\", 0.1)\n",
    "test(test_loader_tweet_lex, net_half, criterion, 1000, \"../logs/net_lin_tweet_lex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
