{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "import gensim.corpora\n",
    "import gensim as gs\n",
    "import pandas as pd\n",
    "from gensim.models import FastText\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "stemmer = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_punct(text):\n",
    "    replacement = [(\".\", \" . \"), (\",\", \" , \"), (\"!\", \" ! \"), (\"?\", \" ? \")]\n",
    "    for k, v in replacement: \n",
    "        text = text.replace(k, v)\n",
    "    return text\n",
    "    \n",
    "def get_emotion_words(stems, list_of_lexica):\n",
    "    emotion_words = np.zeros(4)\n",
    "    for index, lexicon in enumerate(list_of_lexica): \n",
    "        for stem in stems:\n",
    "            if stem in lexicon:\n",
    "                emotion_words[index] = emotion_words[index] + 1\n",
    "    return emotion_words\n",
    "\n",
    "def get_cons_punct_count(pos):\n",
    "    cons_punct_count = 0\n",
    "    for index, item in enumerate(pos[:-1]):\n",
    "        if item == 97 and item == pos[index+1]:\n",
    "            cons_punct_count += 1\n",
    "    return cons_punct_count\n",
    "\n",
    "def extract_features(list_of_lexica, input_message, seq_len): \n",
    "    doc = nlp(split_punct(input_message))\n",
    "    doc = nlp(\" \".join([token.text for token in doc if not token.is_stop and token.pos != 103]))\n",
    "    if len(doc) != 0:\n",
    "        pos = [token.pos for token in doc]\n",
    "        stems = [stemmer.stem(token.text) for token in doc if token.pos != 97]\n",
    "        emotion_words = get_emotion_words(stems, list_of_lexica)\n",
    "        feature_vec = [\n",
    "            (len(doc)/seq_len), (sum([token.text.isupper() for token in doc])/len(doc)), \n",
    "            (len(doc.ents)/len(doc)),get_cons_punct_count(pos), \n",
    "            emotion_words[0]/len(doc), emotion_words[1]/len(doc), emotion_words[2]/len(doc), emotion_words[3]/len(doc)]\n",
    "        return feature_vec, pos, stems\n",
    "    return [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2345679012345679, 0.0, 0.05263157894736842, 0, 0.0, 0.0, 0.0, 0.0]\n",
      "[91, 97, 92, 92, 97, 100, 94, 100, 84, 92, 97, 100, 94, 100, 96, 92, 97, 91, 84]\n",
      "['ok', 'son', 'bath', 'gon', 'na', 'find', 'quick', 'quot', 'gon', 'na', 'miss', \"ya'll\", 'weekend', 'gettin', 'sad']\n",
      "\n",
      " [2]\n"
     ]
    }
   ],
   "source": [
    "lexica_names = [\"clean_happiness\", \"clean_sadness\", \"clean_anger\", \"clean_fear\"]\n",
    "list_of_lexica = [pd.read_csv(\"../../lexica/\" + dataset_name + \".csv\") for dataset_name in lexica_names]\n",
    "seq_len = {\"norm_tweet\": 81, \"norm_emotion\": 32}\n",
    "dataset_name = \"norm_tweet\"\n",
    "feature_set_name = \"full\"\n",
    "\n",
    "sent = \"ok , son bath , gon na find quick quotes . Gon na miss ya'll weekend . gettin sad\"\n",
    "fvec = extract_features(list_of_lexica, sent, seq_len[dataset_name])\n",
    "for a in fvec: print(a)\n",
    "\n",
    "\n",
    "rf = clf = load(\"../models/random_forests/\" + dataset_name + \"_\" + feature_set_name + \"_random_forests.joblib\") \n",
    "print(\"\\n\",rf.predict([fvec[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
