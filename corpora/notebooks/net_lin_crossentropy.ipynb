{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin_Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, act_function):\n",
    "        super(Lin_Net, self).__init__()\n",
    "        self.act_function = act_function\n",
    "        \n",
    "        self.lin1 = nn.Linear(input_dim, hidden_dim_1)\n",
    "        self.lin2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.lin3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.lin4 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act_function(self.lin1(x))\n",
    "        x = self.act_function(self.lin2(x))\n",
    "        x = self.act_function(self.lin3(x))\n",
    "        x = self.lin4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(D.Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = torch.from_numpy(x_tensor)\n",
    "        self.y = torch.from_numpy(y_tensor)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(dataset, features, batch_size, debug=False):\n",
    "    datasets = []\n",
    "    for file in dataset:\n",
    "        datasets.append(pd.read_csv(\"../\" + file))\n",
    "    dataset = pd.concat(datasets, axis=0, ignore_index=True)\n",
    "    \n",
    "    target = dataset[\"affect\"]\n",
    "    dataset_full = dataset[[\"word_count\", \"upper_word_count\", \"ent_word_count\", \"h_count\", \"s_count\", \"a_count\", \"f_count\", \"cons_punct_count\"]]\n",
    "    dataset_nolex = dataset[[\"word_count\", \"upper_word_count\", \"ent_word_count\", \"cons_punct_count\"]]\n",
    "    dataset_lex = dataset[[\"h_count\", \"s_count\", \"a_count\", \"f_count\"]]\n",
    "    \n",
    "    # make train and test sets\n",
    "    if features == \"full\": \n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_full, target, test_size=0.2)\n",
    "    elif features == \"nolex\":\n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_nolex, target, test_size=0.2)\n",
    "    elif features == \"lex\": \n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_lex, target, test_size=0.2)\n",
    "\n",
    "    # make data loaders\n",
    "    train_data = MyDataset(train_x.to_numpy(), train_y.to_numpy())\n",
    "    test_data = MyDataset(test_x.to_numpy(), test_y.to_numpy())\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    \n",
    "    if debug: \n",
    "        dataset_full = dataset_full.iloc[:10]\n",
    "        target = target[:10]\n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_full, target, test_size=0.8)\n",
    "        train_data = MyDataset(train_x.to_numpy(), train_y.to_numpy())\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "        test_loader = DataLoader(dataset=train_data, batch_size=1)\n",
    "    return train_loader, test_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(summary, file):\n",
    "    log = open(file, \"a\")\n",
    "    log.write(summary)\n",
    "    log.close()\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, epochs, criterion, print_every, save_name, cuda, lr):\n",
    "    open(save_name + \"_train\", \"w\").close()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.5)\n",
    "    error_curve = []\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        for index, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.float(), targets.long()\n",
    "            if cuda: \n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "                net = net.cuda()\n",
    "            pred = net(inputs)\n",
    "            loss = criterion(pred.float(), targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if ((index) % print_every == 0):\n",
    "                log(\"batch: {}/{} in epoch {}/{} \\n... loss: {}\\n\".\n",
    "                    format((index+1), len(train_loader), (epoch+1), epochs, loss.item()), \n",
    "                    save_name + \"_train\")\n",
    "        # save network after every epoch\n",
    "        torch.save(net.state_dict(), save_name + \".pt\")  \n",
    "        # after every epoch save the error\n",
    "        error_curve.append([epoch, loss.item()])\n",
    "    log(\"\\n\" + str(error_curve), save_name + \"_train\")\n",
    "    plot = plt.plot([item[0] for item in error_curve], [item[1] for item in error_curve])\n",
    "    plt.savefig(save_name+\"_train_error.png\")\n",
    "\n",
    "def test(test_loader, net, criterion, print_every, save_name, cuda):\n",
    "    open(save_name + \"_test\", \"w\").close()\n",
    "    confusion = []\n",
    "    net.eval()\n",
    "    loss_sum, correct, correct2 = 0, 0, 0\n",
    "    for index, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.float(), targets.long()\n",
    "        if cuda: \n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            net = net.cuda()\n",
    "        pred = net(inputs)\n",
    "        pred_class = torch.max(pred.data, 1)[1]\n",
    "        loss_sum += criterion(pred, targets).item()\n",
    "        confusion.append([targets.item(), pred_class.item()])\n",
    "        if pred_class.item() == targets.item(): \n",
    "            correct += 1\n",
    "        if ((index) % print_every == 0):\n",
    "            log(\"batch: {}/{}\\n... correct: {}\\n\".\n",
    "                format((index+1), len(test_loader), correct), \n",
    "                save_name + \"_test\")\n",
    "           \n",
    "    # give end report\n",
    "    log(\"average test loss: {}, relative correct: {}\\n\\nconfusion:\\n{}\".\n",
    "        format((loss_sum / len(test_loader)), (correct / len(test_loader)),str(confusion)), \n",
    "        save_name + \"_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating variables\n"
     ]
    }
   ],
   "source": [
    "# create variables \n",
    "print(\"creating variables\")\n",
    "emotion_dataset = [\"emotion_classification_1_clean.csv\", \"emotion_classification_2_clean.csv\", \"emotion_classification_3_clean.csv\", \"emotion_classification_4_clean.csv\", \"emotion_classification_5_clean.csv\", \"emotion_classification_6_clean.csv\", \"emotion_classification_7_clean.csv\", \"emotion_classification_8_clean.csv\"]\n",
    "tweet_dataset = [\"crowdflower_clean.csv\", \"emoint_clean.csv\", \"tec_clean.csv\"]\n",
    "act_function = torch.sigmoid\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "cuda = torch.cuda.is_available()\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 1/1000 \n",
      "... loss: 1.410484790802002\n",
      "\n",
      "batch: 1/1 in epoch 2/1000 \n",
      "... loss: 1.03560209274292\n",
      "\n",
      "batch: 1/1 in epoch 3/1000 \n",
      "... loss: 0.8322607278823853\n",
      "\n",
      "batch: 1/1 in epoch 4/1000 \n",
      "... loss: 0.7617442607879639\n",
      "\n",
      "batch: 1/1 in epoch 5/1000 \n",
      "... loss: 0.7353168725967407\n",
      "\n",
      "batch: 1/1 in epoch 6/1000 \n",
      "... loss: 0.7236469984054565\n",
      "\n",
      "batch: 1/1 in epoch 7/1000 \n",
      "... loss: 0.7176548838615417\n",
      "\n",
      "batch: 1/1 in epoch 8/1000 \n",
      "... loss: 0.7140815258026123\n",
      "\n",
      "batch: 1/1 in epoch 9/1000 \n",
      "... loss: 0.7117377519607544\n",
      "\n",
      "batch: 1/1 in epoch 10/1000 \n",
      "... loss: 0.7100479602813721\n",
      "\n",
      "batch: 1/1 in epoch 11/1000 \n",
      "... loss: 0.7087364792823792\n",
      "\n",
      "batch: 1/1 in epoch 12/1000 \n",
      "... loss: 0.7076705694198608\n",
      "\n",
      "batch: 1/1 in epoch 13/1000 \n",
      "... loss: 0.7067698240280151\n",
      "\n",
      "batch: 1/1 in epoch 14/1000 \n",
      "... loss: 0.7059892416000366\n",
      "\n",
      "batch: 1/1 in epoch 15/1000 \n",
      "... loss: 0.7053015232086182\n",
      "\n",
      "batch: 1/1 in epoch 16/1000 \n",
      "... loss: 0.7046875953674316\n",
      "\n",
      "batch: 1/1 in epoch 17/1000 \n",
      "... loss: 0.7041341662406921\n",
      "\n",
      "batch: 1/1 in epoch 18/1000 \n",
      "... loss: 0.703632116317749\n",
      "\n",
      "batch: 1/1 in epoch 19/1000 \n",
      "... loss: 0.7031737565994263\n",
      "\n",
      "batch: 1/1 in epoch 20/1000 \n",
      "... loss: 0.7027531862258911\n",
      "\n",
      "batch: 1/1 in epoch 21/1000 \n",
      "... loss: 0.7023659944534302\n",
      "\n",
      "batch: 1/1 in epoch 22/1000 \n",
      "... loss: 0.7020078897476196\n",
      "\n",
      "batch: 1/1 in epoch 23/1000 \n",
      "... loss: 0.7016754746437073\n",
      "\n",
      "batch: 1/1 in epoch 24/1000 \n",
      "... loss: 0.7013661861419678\n",
      "\n",
      "batch: 1/1 in epoch 25/1000 \n",
      "... loss: 0.7010774612426758\n",
      "\n",
      "batch: 1/1 in epoch 26/1000 \n",
      "... loss: 0.7008074522018433\n",
      "\n",
      "batch: 1/1 in epoch 27/1000 \n",
      "... loss: 0.7005541324615479\n",
      "\n",
      "batch: 1/1 in epoch 28/1000 \n",
      "... loss: 0.7003159523010254\n",
      "\n",
      "batch: 1/1 in epoch 29/1000 \n",
      "... loss: 0.7000917196273804\n",
      "\n",
      "batch: 1/1 in epoch 30/1000 \n",
      "... loss: 0.6998800039291382\n",
      "\n",
      "batch: 1/1 in epoch 31/1000 \n",
      "... loss: 0.6996797323226929\n",
      "\n",
      "batch: 1/1 in epoch 32/1000 \n",
      "... loss: 0.6994901895523071\n",
      "\n",
      "batch: 1/1 in epoch 33/1000 \n",
      "... loss: 0.6993104219436646\n",
      "\n",
      "batch: 1/1 in epoch 34/1000 \n",
      "... loss: 0.6991391777992249\n",
      "\n",
      "batch: 1/1 in epoch 35/1000 \n",
      "... loss: 0.6989766359329224\n",
      "\n",
      "batch: 1/1 in epoch 36/1000 \n",
      "... loss: 0.6988216042518616\n",
      "\n",
      "batch: 1/1 in epoch 37/1000 \n",
      "... loss: 0.6986737251281738\n",
      "\n",
      "batch: 1/1 in epoch 38/1000 \n",
      "... loss: 0.6985323429107666\n",
      "\n",
      "batch: 1/1 in epoch 39/1000 \n",
      "... loss: 0.698397159576416\n",
      "\n",
      "batch: 1/1 in epoch 40/1000 \n",
      "... loss: 0.6982676982879639\n",
      "\n",
      "batch: 1/1 in epoch 41/1000 \n",
      "... loss: 0.6981435418128967\n",
      "\n",
      "batch: 1/1 in epoch 42/1000 \n",
      "... loss: 0.6980244517326355\n",
      "\n",
      "batch: 1/1 in epoch 43/1000 \n",
      "... loss: 0.6979100108146667\n",
      "\n",
      "batch: 1/1 in epoch 44/1000 \n",
      "... loss: 0.6978000402450562\n",
      "\n",
      "batch: 1/1 in epoch 45/1000 \n",
      "... loss: 0.6976940631866455\n",
      "\n",
      "batch: 1/1 in epoch 46/1000 \n",
      "... loss: 0.6975919604301453\n",
      "\n",
      "batch: 1/1 in epoch 47/1000 \n",
      "... loss: 0.6974937915802002\n",
      "\n",
      "batch: 1/1 in epoch 48/1000 \n",
      "... loss: 0.6973987817764282\n",
      "\n",
      "batch: 1/1 in epoch 49/1000 \n",
      "... loss: 0.6973072290420532\n",
      "\n",
      "batch: 1/1 in epoch 50/1000 \n",
      "... loss: 0.6972185373306274\n",
      "\n",
      "batch: 1/1 in epoch 51/1000 \n",
      "... loss: 0.6971327066421509\n",
      "\n",
      "batch: 1/1 in epoch 52/1000 \n",
      "... loss: 0.6970498561859131\n",
      "\n",
      "batch: 1/1 in epoch 53/1000 \n",
      "... loss: 0.6969695687294006\n",
      "\n",
      "batch: 1/1 in epoch 54/1000 \n",
      "... loss: 0.6968917846679688\n",
      "\n",
      "batch: 1/1 in epoch 55/1000 \n",
      "... loss: 0.6968163251876831\n",
      "\n",
      "batch: 1/1 in epoch 56/1000 \n",
      "... loss: 0.6967430114746094\n",
      "\n",
      "batch: 1/1 in epoch 57/1000 \n",
      "... loss: 0.6966718435287476\n",
      "\n",
      "batch: 1/1 in epoch 58/1000 \n",
      "... loss: 0.6966027021408081\n",
      "\n",
      "batch: 1/1 in epoch 59/1000 \n",
      "... loss: 0.696535587310791\n",
      "\n",
      "batch: 1/1 in epoch 60/1000 \n",
      "... loss: 0.6964703798294067\n",
      "\n",
      "batch: 1/1 in epoch 61/1000 \n",
      "... loss: 0.6964067220687866\n",
      "\n",
      "batch: 1/1 in epoch 62/1000 \n",
      "... loss: 0.6963446736335754\n",
      "\n",
      "batch: 1/1 in epoch 63/1000 \n",
      "... loss: 0.6962844729423523\n",
      "\n",
      "batch: 1/1 in epoch 64/1000 \n",
      "... loss: 0.6962257027626038\n",
      "\n",
      "batch: 1/1 in epoch 65/1000 \n",
      "... loss: 0.6961683630943298\n",
      "\n",
      "batch: 1/1 in epoch 66/1000 \n",
      "... loss: 0.6961123943328857\n",
      "\n",
      "batch: 1/1 in epoch 67/1000 \n",
      "... loss: 0.6960578560829163\n",
      "\n",
      "batch: 1/1 in epoch 68/1000 \n",
      "... loss: 0.6960045099258423\n",
      "\n",
      "batch: 1/1 in epoch 69/1000 \n",
      "... loss: 0.6959525346755981\n",
      "\n",
      "batch: 1/1 in epoch 70/1000 \n",
      "... loss: 0.6959017515182495\n",
      "\n",
      "batch: 1/1 in epoch 71/1000 \n",
      "... loss: 0.6958518028259277\n",
      "\n",
      "batch: 1/1 in epoch 72/1000 \n",
      "... loss: 0.695803165435791\n",
      "\n",
      "batch: 1/1 in epoch 73/1000 \n",
      "... loss: 0.6957554817199707\n",
      "\n",
      "batch: 1/1 in epoch 74/1000 \n",
      "... loss: 0.6957089900970459\n",
      "\n",
      "batch: 1/1 in epoch 75/1000 \n",
      "... loss: 0.6956632137298584\n",
      "\n",
      "batch: 1/1 in epoch 76/1000 \n",
      "... loss: 0.6956186294555664\n",
      "\n",
      "batch: 1/1 in epoch 77/1000 \n",
      "... loss: 0.6955748796463013\n",
      "\n",
      "batch: 1/1 in epoch 78/1000 \n",
      "... loss: 0.695531964302063\n",
      "\n",
      "batch: 1/1 in epoch 79/1000 \n",
      "... loss: 0.6954897046089172\n",
      "\n",
      "batch: 1/1 in epoch 80/1000 \n",
      "... loss: 0.6954485177993774\n",
      "\n",
      "batch: 1/1 in epoch 81/1000 \n",
      "... loss: 0.6954078674316406\n",
      "\n",
      "batch: 1/1 in epoch 82/1000 \n",
      "... loss: 0.6953680515289307\n",
      "\n",
      "batch: 1/1 in epoch 83/1000 \n",
      "... loss: 0.695328950881958\n",
      "\n",
      "batch: 1/1 in epoch 84/1000 \n",
      "... loss: 0.6952906847000122\n",
      "\n",
      "batch: 1/1 in epoch 85/1000 \n",
      "... loss: 0.6952527761459351\n",
      "\n",
      "batch: 1/1 in epoch 86/1000 \n",
      "... loss: 0.6952157616615295\n",
      "\n",
      "batch: 1/1 in epoch 87/1000 \n",
      "... loss: 0.6951793432235718\n",
      "\n",
      "batch: 1/1 in epoch 88/1000 \n",
      "... loss: 0.695143461227417\n",
      "\n",
      "batch: 1/1 in epoch 89/1000 \n",
      "... loss: 0.6951082944869995\n",
      "\n",
      "batch: 1/1 in epoch 90/1000 \n",
      "... loss: 0.6950736045837402\n",
      "\n",
      "batch: 1/1 in epoch 91/1000 \n",
      "... loss: 0.6950393915176392\n",
      "\n",
      "batch: 1/1 in epoch 92/1000 \n",
      "... loss: 0.6950058341026306\n",
      "\n",
      "batch: 1/1 in epoch 93/1000 \n",
      "... loss: 0.694972813129425\n",
      "\n",
      "batch: 1/1 in epoch 94/1000 \n",
      "... loss: 0.6949401497840881\n",
      "\n",
      "batch: 1/1 in epoch 95/1000 \n",
      "... loss: 0.6949079632759094\n",
      "\n",
      "batch: 1/1 in epoch 96/1000 \n",
      "... loss: 0.6948763132095337\n",
      "\n",
      "batch: 1/1 in epoch 97/1000 \n",
      "... loss: 0.6948451995849609\n",
      "\n",
      "batch: 1/1 in epoch 98/1000 \n",
      "... loss: 0.6948143243789673\n",
      "\n",
      "batch: 1/1 in epoch 99/1000 \n",
      "... loss: 0.6947838664054871\n",
      "\n",
      "batch: 1/1 in epoch 100/1000 \n",
      "... loss: 0.694753885269165\n",
      "\n",
      "batch: 1/1 in epoch 101/1000 \n",
      "... loss: 0.694724440574646\n",
      "\n",
      "batch: 1/1 in epoch 102/1000 \n",
      "... loss: 0.6946953535079956\n",
      "\n",
      "batch: 1/1 in epoch 103/1000 \n",
      "... loss: 0.6946665048599243\n",
      "\n",
      "batch: 1/1 in epoch 104/1000 \n",
      "... loss: 0.6946380734443665\n",
      "\n",
      "batch: 1/1 in epoch 105/1000 \n",
      "... loss: 0.6946101188659668\n",
      "\n",
      "batch: 1/1 in epoch 106/1000 \n",
      "... loss: 0.6945821046829224\n",
      "\n",
      "batch: 1/1 in epoch 107/1000 \n",
      "... loss: 0.6945549249649048\n",
      "\n",
      "batch: 1/1 in epoch 108/1000 \n",
      "... loss: 0.6945277452468872\n",
      "\n",
      "batch: 1/1 in epoch 109/1000 \n",
      "... loss: 0.6945011615753174\n",
      "\n",
      "batch: 1/1 in epoch 110/1000 \n",
      "... loss: 0.6944746971130371\n",
      "\n",
      "batch: 1/1 in epoch 111/1000 \n",
      "... loss: 0.6944483518600464\n",
      "\n",
      "batch: 1/1 in epoch 112/1000 \n",
      "... loss: 0.6944226026535034\n",
      "\n",
      "batch: 1/1 in epoch 113/1000 \n",
      "... loss: 0.6943968534469604\n",
      "\n",
      "batch: 1/1 in epoch 114/1000 \n",
      "... loss: 0.6943714618682861\n",
      "\n",
      "batch: 1/1 in epoch 115/1000 \n",
      "... loss: 0.6943464279174805\n",
      "\n",
      "batch: 1/1 in epoch 116/1000 \n",
      "... loss: 0.6943216323852539\n",
      "\n",
      "batch: 1/1 in epoch 117/1000 \n",
      "... loss: 0.6942970752716064\n",
      "\n",
      "batch: 1/1 in epoch 118/1000 \n",
      "... loss: 0.6942728757858276\n",
      "\n",
      "batch: 1/1 in epoch 119/1000 \n",
      "... loss: 0.694248616695404\n",
      "\n",
      "batch: 1/1 in epoch 120/1000 \n",
      "... loss: 0.6942247152328491\n",
      "\n",
      "batch: 1/1 in epoch 121/1000 \n",
      "... loss: 0.6942011117935181\n",
      "\n",
      "batch: 1/1 in epoch 122/1000 \n",
      "... loss: 0.6941777467727661\n",
      "\n",
      "batch: 1/1 in epoch 123/1000 \n",
      "... loss: 0.6941544413566589\n",
      "\n",
      "batch: 1/1 in epoch 124/1000 \n",
      "... loss: 0.6941314935684204\n",
      "\n",
      "batch: 1/1 in epoch 125/1000 \n",
      "... loss: 0.6941087245941162\n",
      "\n",
      "batch: 1/1 in epoch 126/1000 \n",
      "... loss: 0.6940860748291016\n",
      "\n",
      "batch: 1/1 in epoch 127/1000 \n",
      "... loss: 0.6940636038780212\n",
      "\n",
      "batch: 1/1 in epoch 128/1000 \n",
      "... loss: 0.6940412521362305\n",
      "\n",
      "batch: 1/1 in epoch 129/1000 \n",
      "... loss: 0.6940193176269531\n",
      "\n",
      "batch: 1/1 in epoch 130/1000 \n",
      "... loss: 0.693997323513031\n",
      "\n",
      "batch: 1/1 in epoch 131/1000 \n",
      "... loss: 0.6939756870269775\n",
      "\n",
      "batch: 1/1 in epoch 132/1000 \n",
      "... loss: 0.6939539909362793\n",
      "\n",
      "batch: 1/1 in epoch 133/1000 \n",
      "... loss: 0.6939326524734497\n",
      "\n",
      "batch: 1/1 in epoch 134/1000 \n",
      "... loss: 0.6939113736152649\n",
      "\n",
      "batch: 1/1 in epoch 135/1000 \n",
      "... loss: 0.6938902139663696\n",
      "\n",
      "batch: 1/1 in epoch 136/1000 \n",
      "... loss: 0.6938692331314087\n",
      "\n",
      "batch: 1/1 in epoch 137/1000 \n",
      "... loss: 0.6938484907150269\n",
      "\n",
      "batch: 1/1 in epoch 138/1000 \n",
      "... loss: 0.6938276886940002\n",
      "\n",
      "batch: 1/1 in epoch 139/1000 \n",
      "... loss: 0.6938072443008423\n",
      "\n",
      "batch: 1/1 in epoch 140/1000 \n",
      "... loss: 0.6937869787216187\n",
      "\n",
      "batch: 1/1 in epoch 141/1000 \n",
      "... loss: 0.6937664747238159\n",
      "\n",
      "batch: 1/1 in epoch 142/1000 \n",
      "... loss: 0.6937463283538818\n",
      "\n",
      "batch: 1/1 in epoch 143/1000 \n",
      "... loss: 0.6937262415885925\n",
      "\n",
      "batch: 1/1 in epoch 144/1000 \n",
      "... loss: 0.693706214427948\n",
      "\n",
      "batch: 1/1 in epoch 145/1000 \n",
      "... loss: 0.6936863660812378\n",
      "\n",
      "batch: 1/1 in epoch 146/1000 \n",
      "... loss: 0.6936668157577515\n",
      "\n",
      "batch: 1/1 in epoch 147/1000 \n",
      "... loss: 0.6936470866203308\n",
      "\n",
      "batch: 1/1 in epoch 148/1000 \n",
      "... loss: 0.6936275959014893\n",
      "\n",
      "batch: 1/1 in epoch 149/1000 \n",
      "... loss: 0.6936083436012268\n",
      "\n",
      "batch: 1/1 in epoch 150/1000 \n",
      "... loss: 0.6935889720916748\n",
      "\n",
      "batch: 1/1 in epoch 151/1000 \n",
      "... loss: 0.6935696601867676\n",
      "\n",
      "batch: 1/1 in epoch 152/1000 \n",
      "... loss: 0.6935505867004395\n",
      "\n",
      "batch: 1/1 in epoch 153/1000 \n",
      "... loss: 0.6935315132141113\n",
      "\n",
      "batch: 1/1 in epoch 154/1000 \n",
      "... loss: 0.6935124397277832\n",
      "\n",
      "batch: 1/1 in epoch 155/1000 \n",
      "... loss: 0.693493664264679\n",
      "\n",
      "batch: 1/1 in epoch 156/1000 \n",
      "... loss: 0.6934749484062195\n",
      "\n",
      "batch: 1/1 in epoch 157/1000 \n",
      "... loss: 0.6934561133384705\n",
      "\n",
      "batch: 1/1 in epoch 158/1000 \n",
      "... loss: 0.6934375762939453\n",
      "\n",
      "batch: 1/1 in epoch 159/1000 \n",
      "... loss: 0.6934190988540649\n",
      "\n",
      "batch: 1/1 in epoch 160/1000 \n",
      "... loss: 0.693400502204895\n",
      "\n",
      "batch: 1/1 in epoch 161/1000 \n",
      "... loss: 0.6933820247650146\n",
      "\n",
      "batch: 1/1 in epoch 162/1000 \n",
      "... loss: 0.6933636665344238\n",
      "\n",
      "batch: 1/1 in epoch 163/1000 \n",
      "... loss: 0.6933454275131226\n",
      "\n",
      "batch: 1/1 in epoch 164/1000 \n",
      "... loss: 0.6933271884918213\n",
      "\n",
      "batch: 1/1 in epoch 165/1000 \n",
      "... loss: 0.69330894947052\n",
      "\n",
      "batch: 1/1 in epoch 166/1000 \n",
      "... loss: 0.6932908296585083\n",
      "\n",
      "batch: 1/1 in epoch 167/1000 \n",
      "... loss: 0.6932728290557861\n",
      "\n",
      "batch: 1/1 in epoch 168/1000 \n",
      "... loss: 0.6932549476623535\n",
      "\n",
      "batch: 1/1 in epoch 169/1000 \n",
      "... loss: 0.6932368874549866\n",
      "\n",
      "batch: 1/1 in epoch 170/1000 \n",
      "... loss: 0.6932189464569092\n",
      "\n",
      "batch: 1/1 in epoch 171/1000 \n",
      "... loss: 0.6932010650634766\n",
      "\n",
      "batch: 1/1 in epoch 172/1000 \n",
      "... loss: 0.6931833028793335\n",
      "\n",
      "batch: 1/1 in epoch 173/1000 \n",
      "... loss: 0.6931654214859009\n",
      "\n",
      "batch: 1/1 in epoch 174/1000 \n",
      "... loss: 0.6931477785110474\n",
      "\n",
      "batch: 1/1 in epoch 175/1000 \n",
      "... loss: 0.6931299567222595\n",
      "\n",
      "batch: 1/1 in epoch 176/1000 \n",
      "... loss: 0.6931123733520508\n",
      "\n",
      "batch: 1/1 in epoch 177/1000 \n",
      "... loss: 0.6930948495864868\n",
      "\n",
      "batch: 1/1 in epoch 178/1000 \n",
      "... loss: 0.6930772066116333\n",
      "\n",
      "batch: 1/1 in epoch 179/1000 \n",
      "... loss: 0.6930596828460693\n",
      "\n",
      "batch: 1/1 in epoch 180/1000 \n",
      "... loss: 0.6930419206619263\n",
      "\n",
      "batch: 1/1 in epoch 181/1000 \n",
      "... loss: 0.6930246353149414\n",
      "\n",
      "batch: 1/1 in epoch 182/1000 \n",
      "... loss: 0.6930071711540222\n",
      "\n",
      "batch: 1/1 in epoch 183/1000 \n",
      "... loss: 0.6929897665977478\n",
      "\n",
      "batch: 1/1 in epoch 184/1000 \n",
      "... loss: 0.6929723024368286\n",
      "\n",
      "batch: 1/1 in epoch 185/1000 \n",
      "... loss: 0.6929547786712646\n",
      "\n",
      "batch: 1/1 in epoch 186/1000 \n",
      "... loss: 0.6929373741149902\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 187/1000 \n",
      "... loss: 0.6929201483726501\n",
      "\n",
      "batch: 1/1 in epoch 188/1000 \n",
      "... loss: 0.6929028034210205\n",
      "\n",
      "batch: 1/1 in epoch 189/1000 \n",
      "... loss: 0.6928853392601013\n",
      "\n",
      "batch: 1/1 in epoch 190/1000 \n",
      "... loss: 0.6928681135177612\n",
      "\n",
      "batch: 1/1 in epoch 191/1000 \n",
      "... loss: 0.6928508281707764\n",
      "\n",
      "batch: 1/1 in epoch 192/1000 \n",
      "... loss: 0.692833662033081\n",
      "\n",
      "batch: 1/1 in epoch 193/1000 \n",
      "... loss: 0.6928162574768066\n",
      "\n",
      "batch: 1/1 in epoch 194/1000 \n",
      "... loss: 0.6927989721298218\n",
      "\n",
      "batch: 1/1 in epoch 195/1000 \n",
      "... loss: 0.692781925201416\n",
      "\n",
      "batch: 1/1 in epoch 196/1000 \n",
      "... loss: 0.6927645206451416\n",
      "\n",
      "batch: 1/1 in epoch 197/1000 \n",
      "... loss: 0.6927474141120911\n",
      "\n",
      "batch: 1/1 in epoch 198/1000 \n",
      "... loss: 0.6927300691604614\n",
      "\n",
      "batch: 1/1 in epoch 199/1000 \n",
      "... loss: 0.6927129030227661\n",
      "\n",
      "batch: 1/1 in epoch 200/1000 \n",
      "... loss: 0.6926956176757812\n",
      "\n",
      "batch: 1/1 in epoch 201/1000 \n",
      "... loss: 0.6926782131195068\n",
      "\n",
      "batch: 1/1 in epoch 202/1000 \n",
      "... loss: 0.6926609873771667\n",
      "\n",
      "batch: 1/1 in epoch 203/1000 \n",
      "... loss: 0.6926437616348267\n",
      "\n",
      "batch: 1/1 in epoch 204/1000 \n",
      "... loss: 0.6926265954971313\n",
      "\n",
      "batch: 1/1 in epoch 205/1000 \n",
      "... loss: 0.6926091909408569\n",
      "\n",
      "batch: 1/1 in epoch 206/1000 \n",
      "... loss: 0.6925921440124512\n",
      "\n",
      "batch: 1/1 in epoch 207/1000 \n",
      "... loss: 0.6925747990608215\n",
      "\n",
      "batch: 1/1 in epoch 208/1000 \n",
      "... loss: 0.6925573945045471\n",
      "\n",
      "batch: 1/1 in epoch 209/1000 \n",
      "... loss: 0.6925402283668518\n",
      "\n",
      "batch: 1/1 in epoch 210/1000 \n",
      "... loss: 0.6925228834152222\n",
      "\n",
      "batch: 1/1 in epoch 211/1000 \n",
      "... loss: 0.6925054788589478\n",
      "\n",
      "batch: 1/1 in epoch 212/1000 \n",
      "... loss: 0.6924881935119629\n",
      "\n",
      "batch: 1/1 in epoch 213/1000 \n",
      "... loss: 0.6924707889556885\n",
      "\n",
      "batch: 1/1 in epoch 214/1000 \n",
      "... loss: 0.6924534440040588\n",
      "\n",
      "batch: 1/1 in epoch 215/1000 \n",
      "... loss: 0.692436158657074\n",
      "\n",
      "batch: 1/1 in epoch 216/1000 \n",
      "... loss: 0.6924186944961548\n",
      "\n",
      "batch: 1/1 in epoch 217/1000 \n",
      "... loss: 0.6924012899398804\n",
      "\n",
      "batch: 1/1 in epoch 218/1000 \n",
      "... loss: 0.692383885383606\n",
      "\n",
      "batch: 1/1 in epoch 219/1000 \n",
      "... loss: 0.692366361618042\n",
      "\n",
      "batch: 1/1 in epoch 220/1000 \n",
      "... loss: 0.6923487782478333\n",
      "\n",
      "batch: 1/1 in epoch 221/1000 \n",
      "... loss: 0.6923313140869141\n",
      "\n",
      "batch: 1/1 in epoch 222/1000 \n",
      "... loss: 0.6923136711120605\n",
      "\n",
      "batch: 1/1 in epoch 223/1000 \n",
      "... loss: 0.6922961473464966\n",
      "\n",
      "batch: 1/1 in epoch 224/1000 \n",
      "... loss: 0.6922785639762878\n",
      "\n",
      "batch: 1/1 in epoch 225/1000 \n",
      "... loss: 0.6922610998153687\n",
      "\n",
      "batch: 1/1 in epoch 226/1000 \n",
      "... loss: 0.6922433376312256\n",
      "\n",
      "batch: 1/1 in epoch 227/1000 \n",
      "... loss: 0.6922255754470825\n",
      "\n",
      "batch: 1/1 in epoch 228/1000 \n",
      "... loss: 0.692207932472229\n",
      "\n",
      "batch: 1/1 in epoch 229/1000 \n",
      "... loss: 0.6921900510787964\n",
      "\n",
      "batch: 1/1 in epoch 230/1000 \n",
      "... loss: 0.6921723484992981\n",
      "\n",
      "batch: 1/1 in epoch 231/1000 \n",
      "... loss: 0.6921545267105103\n",
      "\n",
      "batch: 1/1 in epoch 232/1000 \n",
      "... loss: 0.6921365261077881\n",
      "\n",
      "batch: 1/1 in epoch 233/1000 \n",
      "... loss: 0.692118763923645\n",
      "\n",
      "batch: 1/1 in epoch 234/1000 \n",
      "... loss: 0.6921006441116333\n",
      "\n",
      "batch: 1/1 in epoch 235/1000 \n",
      "... loss: 0.6920828819274902\n",
      "\n",
      "batch: 1/1 in epoch 236/1000 \n",
      "... loss: 0.692064642906189\n",
      "\n",
      "batch: 1/1 in epoch 237/1000 \n",
      "... loss: 0.6920466423034668\n",
      "\n",
      "batch: 1/1 in epoch 238/1000 \n",
      "... loss: 0.6920284032821655\n",
      "\n",
      "batch: 1/1 in epoch 239/1000 \n",
      "... loss: 0.6920104026794434\n",
      "\n",
      "batch: 1/1 in epoch 240/1000 \n",
      "... loss: 0.6919921040534973\n",
      "\n",
      "batch: 1/1 in epoch 241/1000 \n",
      "... loss: 0.6919739842414856\n",
      "\n",
      "batch: 1/1 in epoch 242/1000 \n",
      "... loss: 0.6919554471969604\n",
      "\n",
      "batch: 1/1 in epoch 243/1000 \n",
      "... loss: 0.6919372081756592\n",
      "\n",
      "batch: 1/1 in epoch 244/1000 \n",
      "... loss: 0.6919187903404236\n",
      "\n",
      "batch: 1/1 in epoch 245/1000 \n",
      "... loss: 0.6919001936912537\n",
      "\n",
      "batch: 1/1 in epoch 246/1000 \n",
      "... loss: 0.6918818354606628\n",
      "\n",
      "batch: 1/1 in epoch 247/1000 \n",
      "... loss: 0.6918632984161377\n",
      "\n",
      "batch: 1/1 in epoch 248/1000 \n",
      "... loss: 0.6918445825576782\n",
      "\n",
      "batch: 1/1 in epoch 249/1000 \n",
      "... loss: 0.691825807094574\n",
      "\n",
      "batch: 1/1 in epoch 250/1000 \n",
      "... loss: 0.6918070316314697\n",
      "\n",
      "batch: 1/1 in epoch 251/1000 \n",
      "... loss: 0.6917882561683655\n",
      "\n",
      "batch: 1/1 in epoch 252/1000 \n",
      "... loss: 0.691769540309906\n",
      "\n",
      "batch: 1/1 in epoch 253/1000 \n",
      "... loss: 0.6917506456375122\n",
      "\n",
      "batch: 1/1 in epoch 254/1000 \n",
      "... loss: 0.6917315721511841\n",
      "\n",
      "batch: 1/1 in epoch 255/1000 \n",
      "... loss: 0.691712498664856\n",
      "\n",
      "batch: 1/1 in epoch 256/1000 \n",
      "... loss: 0.6916934251785278\n",
      "\n",
      "batch: 1/1 in epoch 257/1000 \n",
      "... loss: 0.6916742324829102\n",
      "\n",
      "batch: 1/1 in epoch 258/1000 \n",
      "... loss: 0.6916549801826477\n",
      "\n",
      "batch: 1/1 in epoch 259/1000 \n",
      "... loss: 0.6916356086730957\n",
      "\n",
      "batch: 1/1 in epoch 260/1000 \n",
      "... loss: 0.6916163563728333\n",
      "\n",
      "batch: 1/1 in epoch 261/1000 \n",
      "... loss: 0.6915969252586365\n",
      "\n",
      "batch: 1/1 in epoch 262/1000 \n",
      "... loss: 0.6915773749351501\n",
      "\n",
      "batch: 1/1 in epoch 263/1000 \n",
      "... loss: 0.6915578246116638\n",
      "\n",
      "batch: 1/1 in epoch 264/1000 \n",
      "... loss: 0.6915380954742432\n",
      "\n",
      "batch: 1/1 in epoch 265/1000 \n",
      "... loss: 0.6915183663368225\n",
      "\n",
      "batch: 1/1 in epoch 266/1000 \n",
      "... loss: 0.6914985775947571\n",
      "\n",
      "batch: 1/1 in epoch 267/1000 \n",
      "... loss: 0.6914786100387573\n",
      "\n",
      "batch: 1/1 in epoch 268/1000 \n",
      "... loss: 0.6914587020874023\n",
      "\n",
      "batch: 1/1 in epoch 269/1000 \n",
      "... loss: 0.6914385557174683\n",
      "\n",
      "batch: 1/1 in epoch 270/1000 \n",
      "... loss: 0.6914185285568237\n",
      "\n",
      "batch: 1/1 in epoch 271/1000 \n",
      "... loss: 0.6913983821868896\n",
      "\n",
      "batch: 1/1 in epoch 272/1000 \n",
      "... loss: 0.691378116607666\n",
      "\n",
      "batch: 1/1 in epoch 273/1000 \n",
      "... loss: 0.6913575530052185\n",
      "\n",
      "batch: 1/1 in epoch 274/1000 \n",
      "... loss: 0.6913372278213501\n",
      "\n",
      "batch: 1/1 in epoch 275/1000 \n",
      "... loss: 0.6913167238235474\n",
      "\n",
      "batch: 1/1 in epoch 276/1000 \n",
      "... loss: 0.6912961006164551\n",
      "\n",
      "batch: 1/1 in epoch 277/1000 \n",
      "... loss: 0.6912752985954285\n",
      "\n",
      "batch: 1/1 in epoch 278/1000 \n",
      "... loss: 0.6912546157836914\n",
      "\n",
      "batch: 1/1 in epoch 279/1000 \n",
      "... loss: 0.6912335157394409\n",
      "\n",
      "batch: 1/1 in epoch 280/1000 \n",
      "... loss: 0.6912126541137695\n",
      "\n",
      "batch: 1/1 in epoch 281/1000 \n",
      "... loss: 0.691191554069519\n",
      "\n",
      "batch: 1/1 in epoch 282/1000 \n",
      "... loss: 0.6911704540252686\n",
      "\n",
      "batch: 1/1 in epoch 283/1000 \n",
      "... loss: 0.691149115562439\n",
      "\n",
      "batch: 1/1 in epoch 284/1000 \n",
      "... loss: 0.6911277174949646\n",
      "\n",
      "batch: 1/1 in epoch 285/1000 \n",
      "... loss: 0.6911063194274902\n",
      "\n",
      "batch: 1/1 in epoch 286/1000 \n",
      "... loss: 0.691084623336792\n",
      "\n",
      "batch: 1/1 in epoch 287/1000 \n",
      "... loss: 0.6910630464553833\n",
      "\n",
      "batch: 1/1 in epoch 288/1000 \n",
      "... loss: 0.6910412311553955\n",
      "\n",
      "batch: 1/1 in epoch 289/1000 \n",
      "... loss: 0.6910192966461182\n",
      "\n",
      "batch: 1/1 in epoch 290/1000 \n",
      "... loss: 0.6909974217414856\n",
      "\n",
      "batch: 1/1 in epoch 291/1000 \n",
      "... loss: 0.6909753084182739\n",
      "\n",
      "batch: 1/1 in epoch 292/1000 \n",
      "... loss: 0.6909530162811279\n",
      "\n",
      "batch: 1/1 in epoch 293/1000 \n",
      "... loss: 0.6909307837486267\n",
      "\n",
      "batch: 1/1 in epoch 294/1000 \n",
      "... loss: 0.6909084320068359\n",
      "\n",
      "batch: 1/1 in epoch 295/1000 \n",
      "... loss: 0.6908859610557556\n",
      "\n",
      "batch: 1/1 in epoch 296/1000 \n",
      "... loss: 0.6908633708953857\n",
      "\n",
      "batch: 1/1 in epoch 297/1000 \n",
      "... loss: 0.6908406019210815\n",
      "\n",
      "batch: 1/1 in epoch 298/1000 \n",
      "... loss: 0.6908175945281982\n",
      "\n",
      "batch: 1/1 in epoch 299/1000 \n",
      "... loss: 0.690794825553894\n",
      "\n",
      "batch: 1/1 in epoch 300/1000 \n",
      "... loss: 0.6907715797424316\n",
      "\n",
      "batch: 1/1 in epoch 301/1000 \n",
      "... loss: 0.6907483339309692\n",
      "\n",
      "batch: 1/1 in epoch 302/1000 \n",
      "... loss: 0.6907252073287964\n",
      "\n",
      "batch: 1/1 in epoch 303/1000 \n",
      "... loss: 0.6907016038894653\n",
      "\n",
      "batch: 1/1 in epoch 304/1000 \n",
      "... loss: 0.6906780004501343\n",
      "\n",
      "batch: 1/1 in epoch 305/1000 \n",
      "... loss: 0.6906542778015137\n",
      "\n",
      "batch: 1/1 in epoch 306/1000 \n",
      "... loss: 0.6906304359436035\n",
      "\n",
      "batch: 1/1 in epoch 307/1000 \n",
      "... loss: 0.6906067132949829\n",
      "\n",
      "batch: 1/1 in epoch 308/1000 \n",
      "... loss: 0.6905825734138489\n",
      "\n",
      "batch: 1/1 in epoch 309/1000 \n",
      "... loss: 0.6905583143234253\n",
      "\n",
      "batch: 1/1 in epoch 310/1000 \n",
      "... loss: 0.6905339956283569\n",
      "\n",
      "batch: 1/1 in epoch 311/1000 \n",
      "... loss: 0.6905093193054199\n",
      "\n",
      "batch: 1/1 in epoch 312/1000 \n",
      "... loss: 0.6904848217964172\n",
      "\n",
      "batch: 1/1 in epoch 313/1000 \n",
      "... loss: 0.6904600858688354\n",
      "\n",
      "batch: 1/1 in epoch 314/1000 \n",
      "... loss: 0.6904351115226746\n",
      "\n",
      "batch: 1/1 in epoch 315/1000 \n",
      "... loss: 0.6904101371765137\n",
      "\n",
      "batch: 1/1 in epoch 316/1000 \n",
      "... loss: 0.690385103225708\n",
      "\n",
      "batch: 1/1 in epoch 317/1000 \n",
      "... loss: 0.6903597116470337\n",
      "\n",
      "batch: 1/1 in epoch 318/1000 \n",
      "... loss: 0.6903342008590698\n",
      "\n",
      "batch: 1/1 in epoch 319/1000 \n",
      "... loss: 0.6903086304664612\n",
      "\n",
      "batch: 1/1 in epoch 320/1000 \n",
      "... loss: 0.6902828216552734\n",
      "\n",
      "batch: 1/1 in epoch 321/1000 \n",
      "... loss: 0.6902570128440857\n",
      "\n",
      "batch: 1/1 in epoch 322/1000 \n",
      "... loss: 0.6902308464050293\n",
      "\n",
      "batch: 1/1 in epoch 323/1000 \n",
      "... loss: 0.6902046799659729\n",
      "\n",
      "batch: 1/1 in epoch 324/1000 \n",
      "... loss: 0.690178394317627\n",
      "\n",
      "batch: 1/1 in epoch 325/1000 \n",
      "... loss: 0.6901518106460571\n",
      "\n",
      "batch: 1/1 in epoch 326/1000 \n",
      "... loss: 0.6901252269744873\n",
      "\n",
      "batch: 1/1 in epoch 327/1000 \n",
      "... loss: 0.6900984048843384\n",
      "\n",
      "batch: 1/1 in epoch 328/1000 \n",
      "... loss: 0.6900713443756104\n",
      "\n",
      "batch: 1/1 in epoch 329/1000 \n",
      "... loss: 0.6900444626808167\n",
      "\n",
      "batch: 1/1 in epoch 330/1000 \n",
      "... loss: 0.6900169253349304\n",
      "\n",
      "batch: 1/1 in epoch 331/1000 \n",
      "... loss: 0.6899895668029785\n",
      "\n",
      "batch: 1/1 in epoch 332/1000 \n",
      "... loss: 0.6899617910385132\n",
      "\n",
      "batch: 1/1 in epoch 333/1000 \n",
      "... loss: 0.6899341344833374\n",
      "\n",
      "batch: 1/1 in epoch 334/1000 \n",
      "... loss: 0.6899058818817139\n",
      "\n",
      "batch: 1/1 in epoch 335/1000 \n",
      "... loss: 0.6898778676986694\n",
      "\n",
      "batch: 1/1 in epoch 336/1000 \n",
      "... loss: 0.6898496150970459\n",
      "\n",
      "batch: 1/1 in epoch 337/1000 \n",
      "... loss: 0.6898208856582642\n",
      "\n",
      "batch: 1/1 in epoch 338/1000 \n",
      "... loss: 0.6897923946380615\n",
      "\n",
      "batch: 1/1 in epoch 339/1000 \n",
      "... loss: 0.689763605594635\n",
      "\n",
      "batch: 1/1 in epoch 340/1000 \n",
      "... loss: 0.6897343993186951\n",
      "\n",
      "batch: 1/1 in epoch 341/1000 \n",
      "... loss: 0.6897053122520447\n",
      "\n",
      "batch: 1/1 in epoch 342/1000 \n",
      "... loss: 0.6896758079528809\n",
      "\n",
      "batch: 1/1 in epoch 343/1000 \n",
      "... loss: 0.6896462440490723\n",
      "\n",
      "batch: 1/1 in epoch 344/1000 \n",
      "... loss: 0.6896162033081055\n",
      "\n",
      "batch: 1/1 in epoch 345/1000 \n",
      "... loss: 0.6895862817764282\n",
      "\n",
      "batch: 1/1 in epoch 346/1000 \n",
      "... loss: 0.6895562410354614\n",
      "\n",
      "batch: 1/1 in epoch 347/1000 \n",
      "... loss: 0.6895257234573364\n",
      "\n",
      "batch: 1/1 in epoch 348/1000 \n",
      "... loss: 0.6894952058792114\n",
      "\n",
      "batch: 1/1 in epoch 349/1000 \n",
      "... loss: 0.6894644498825073\n",
      "\n",
      "batch: 1/1 in epoch 350/1000 \n",
      "... loss: 0.6894333362579346\n",
      "\n",
      "batch: 1/1 in epoch 351/1000 \n",
      "... loss: 0.6894022226333618\n",
      "\n",
      "batch: 1/1 in epoch 352/1000 \n",
      "... loss: 0.68937087059021\n",
      "\n",
      "batch: 1/1 in epoch 353/1000 \n",
      "... loss: 0.6893391609191895\n",
      "\n",
      "batch: 1/1 in epoch 354/1000 \n",
      "... loss: 0.689307451248169\n",
      "\n",
      "batch: 1/1 in epoch 355/1000 \n",
      "... loss: 0.6892753839492798\n",
      "\n",
      "batch: 1/1 in epoch 356/1000 \n",
      "... loss: 0.689242959022522\n",
      "\n",
      "batch: 1/1 in epoch 357/1000 \n",
      "... loss: 0.6892105937004089\n",
      "\n",
      "batch: 1/1 in epoch 358/1000 \n",
      "... loss: 0.6891778707504272\n",
      "\n",
      "batch: 1/1 in epoch 359/1000 \n",
      "... loss: 0.6891449689865112\n",
      "\n",
      "batch: 1/1 in epoch 360/1000 \n",
      "... loss: 0.6891119480133057\n",
      "\n",
      "batch: 1/1 in epoch 361/1000 \n",
      "... loss: 0.6890785694122314\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 362/1000 \n",
      "... loss: 0.6890448927879333\n",
      "\n",
      "batch: 1/1 in epoch 363/1000 \n",
      "... loss: 0.6890111565589905\n",
      "\n",
      "batch: 1/1 in epoch 364/1000 \n",
      "... loss: 0.6889770030975342\n",
      "\n",
      "batch: 1/1 in epoch 365/1000 \n",
      "... loss: 0.6889427304267883\n",
      "\n",
      "batch: 1/1 in epoch 366/1000 \n",
      "... loss: 0.6889081597328186\n",
      "\n",
      "batch: 1/1 in epoch 367/1000 \n",
      "... loss: 0.6888733506202698\n",
      "\n",
      "batch: 1/1 in epoch 368/1000 \n",
      "... loss: 0.6888382434844971\n",
      "\n",
      "batch: 1/1 in epoch 369/1000 \n",
      "... loss: 0.6888031959533691\n",
      "\n",
      "batch: 1/1 in epoch 370/1000 \n",
      "... loss: 0.6887674331665039\n",
      "\n",
      "batch: 1/1 in epoch 371/1000 \n",
      "... loss: 0.6887317299842834\n",
      "\n",
      "batch: 1/1 in epoch 372/1000 \n",
      "... loss: 0.6886956691741943\n",
      "\n",
      "batch: 1/1 in epoch 373/1000 \n",
      "... loss: 0.6886594295501709\n",
      "\n",
      "batch: 1/1 in epoch 374/1000 \n",
      "... loss: 0.6886228322982788\n",
      "\n",
      "batch: 1/1 in epoch 375/1000 \n",
      "... loss: 0.6885861754417419\n",
      "\n",
      "batch: 1/1 in epoch 376/1000 \n",
      "... loss: 0.6885488629341125\n",
      "\n",
      "batch: 1/1 in epoch 377/1000 \n",
      "... loss: 0.6885115504264832\n",
      "\n",
      "batch: 1/1 in epoch 378/1000 \n",
      "... loss: 0.6884739995002747\n",
      "\n",
      "batch: 1/1 in epoch 379/1000 \n",
      "... loss: 0.6884362697601318\n",
      "\n",
      "batch: 1/1 in epoch 380/1000 \n",
      "... loss: 0.6883978843688965\n",
      "\n",
      "batch: 1/1 in epoch 381/1000 \n",
      "... loss: 0.6883594989776611\n",
      "\n",
      "batch: 1/1 in epoch 382/1000 \n",
      "... loss: 0.6883204579353333\n",
      "\n",
      "batch: 1/1 in epoch 383/1000 \n",
      "... loss: 0.6882815957069397\n",
      "\n",
      "batch: 1/1 in epoch 384/1000 \n",
      "... loss: 0.6882421970367432\n",
      "\n",
      "batch: 1/1 in epoch 385/1000 \n",
      "... loss: 0.6882027387619019\n",
      "\n",
      "batch: 1/1 in epoch 386/1000 \n",
      "... loss: 0.6881625652313232\n",
      "\n",
      "batch: 1/1 in epoch 387/1000 \n",
      "... loss: 0.6881224513053894\n",
      "\n",
      "batch: 1/1 in epoch 388/1000 \n",
      "... loss: 0.6880819797515869\n",
      "\n",
      "batch: 1/1 in epoch 389/1000 \n",
      "... loss: 0.6880409717559814\n",
      "\n",
      "batch: 1/1 in epoch 390/1000 \n",
      "... loss: 0.687999963760376\n",
      "\n",
      "batch: 1/1 in epoch 391/1000 \n",
      "... loss: 0.6879583597183228\n",
      "\n",
      "batch: 1/1 in epoch 392/1000 \n",
      "... loss: 0.6879165172576904\n",
      "\n",
      "batch: 1/1 in epoch 393/1000 \n",
      "... loss: 0.6878747344017029\n",
      "\n",
      "batch: 1/1 in epoch 394/1000 \n",
      "... loss: 0.6878322958946228\n",
      "\n",
      "batch: 1/1 in epoch 395/1000 \n",
      "... loss: 0.6877893805503845\n",
      "\n",
      "batch: 1/1 in epoch 396/1000 \n",
      "... loss: 0.6877462863922119\n",
      "\n",
      "batch: 1/1 in epoch 397/1000 \n",
      "... loss: 0.687703013420105\n",
      "\n",
      "batch: 1/1 in epoch 398/1000 \n",
      "... loss: 0.6876592040061951\n",
      "\n",
      "batch: 1/1 in epoch 399/1000 \n",
      "... loss: 0.6876150369644165\n",
      "\n",
      "batch: 1/1 in epoch 400/1000 \n",
      "... loss: 0.6875705718994141\n",
      "\n",
      "batch: 1/1 in epoch 401/1000 \n",
      "... loss: 0.6875259876251221\n",
      "\n",
      "batch: 1/1 in epoch 402/1000 \n",
      "... loss: 0.6874806880950928\n",
      "\n",
      "batch: 1/1 in epoch 403/1000 \n",
      "... loss: 0.6874352097511292\n",
      "\n",
      "batch: 1/1 in epoch 404/1000 \n",
      "... loss: 0.6873893141746521\n",
      "\n",
      "batch: 1/1 in epoch 405/1000 \n",
      "... loss: 0.6873432397842407\n",
      "\n",
      "batch: 1/1 in epoch 406/1000 \n",
      "... loss: 0.6872965693473816\n",
      "\n",
      "batch: 1/1 in epoch 407/1000 \n",
      "... loss: 0.6872495412826538\n",
      "\n",
      "batch: 1/1 in epoch 408/1000 \n",
      "... loss: 0.6872022151947021\n",
      "\n",
      "batch: 1/1 in epoch 409/1000 \n",
      "... loss: 0.6871546506881714\n",
      "\n",
      "batch: 1/1 in epoch 410/1000 \n",
      "... loss: 0.6871062517166138\n",
      "\n",
      "batch: 1/1 in epoch 411/1000 \n",
      "... loss: 0.6870578527450562\n",
      "\n",
      "batch: 1/1 in epoch 412/1000 \n",
      "... loss: 0.6870089173316956\n",
      "\n",
      "batch: 1/1 in epoch 413/1000 \n",
      "... loss: 0.6869596242904663\n",
      "\n",
      "batch: 1/1 in epoch 414/1000 \n",
      "... loss: 0.6869099140167236\n",
      "\n",
      "batch: 1/1 in epoch 415/1000 \n",
      "... loss: 0.686859667301178\n",
      "\n",
      "batch: 1/1 in epoch 416/1000 \n",
      "... loss: 0.6868091821670532\n",
      "\n",
      "batch: 1/1 in epoch 417/1000 \n",
      "... loss: 0.686758279800415\n",
      "\n",
      "batch: 1/1 in epoch 418/1000 \n",
      "... loss: 0.6867068409919739\n",
      "\n",
      "batch: 1/1 in epoch 419/1000 \n",
      "... loss: 0.6866551041603088\n",
      "\n",
      "batch: 1/1 in epoch 420/1000 \n",
      "... loss: 0.6866028308868408\n",
      "\n",
      "batch: 1/1 in epoch 421/1000 \n",
      "... loss: 0.6865502595901489\n",
      "\n",
      "batch: 1/1 in epoch 422/1000 \n",
      "... loss: 0.6864970922470093\n",
      "\n",
      "batch: 1/1 in epoch 423/1000 \n",
      "... loss: 0.6864435076713562\n",
      "\n",
      "batch: 1/1 in epoch 424/1000 \n",
      "... loss: 0.6863895654678345\n",
      "\n",
      "batch: 1/1 in epoch 425/1000 \n",
      "... loss: 0.6863349676132202\n",
      "\n",
      "batch: 1/1 in epoch 426/1000 \n",
      "... loss: 0.6862800717353821\n",
      "\n",
      "batch: 1/1 in epoch 427/1000 \n",
      "... loss: 0.6862246990203857\n",
      "\n",
      "batch: 1/1 in epoch 428/1000 \n",
      "... loss: 0.686168909072876\n",
      "\n",
      "batch: 1/1 in epoch 429/1000 \n",
      "... loss: 0.6861124038696289\n",
      "\n",
      "batch: 1/1 in epoch 430/1000 \n",
      "... loss: 0.686055600643158\n",
      "\n",
      "batch: 1/1 in epoch 431/1000 \n",
      "... loss: 0.6859982013702393\n",
      "\n",
      "batch: 1/1 in epoch 432/1000 \n",
      "... loss: 0.6859406232833862\n",
      "\n",
      "batch: 1/1 in epoch 433/1000 \n",
      "... loss: 0.6858822107315063\n",
      "\n",
      "batch: 1/1 in epoch 434/1000 \n",
      "... loss: 0.6858234405517578\n",
      "\n",
      "batch: 1/1 in epoch 435/1000 \n",
      "... loss: 0.6857640743255615\n",
      "\n",
      "batch: 1/1 in epoch 436/1000 \n",
      "... loss: 0.6857041716575623\n",
      "\n",
      "batch: 1/1 in epoch 437/1000 \n",
      "... loss: 0.6856437921524048\n",
      "\n",
      "batch: 1/1 in epoch 438/1000 \n",
      "... loss: 0.6855829954147339\n",
      "\n",
      "batch: 1/1 in epoch 439/1000 \n",
      "... loss: 0.6855214834213257\n",
      "\n",
      "batch: 1/1 in epoch 440/1000 \n",
      "... loss: 0.6854592561721802\n",
      "\n",
      "batch: 1/1 in epoch 441/1000 \n",
      "... loss: 0.6853969097137451\n",
      "\n",
      "batch: 1/1 in epoch 442/1000 \n",
      "... loss: 0.685333788394928\n",
      "\n",
      "batch: 1/1 in epoch 443/1000 \n",
      "... loss: 0.6852701902389526\n",
      "\n",
      "batch: 1/1 in epoch 444/1000 \n",
      "... loss: 0.6852059960365295\n",
      "\n",
      "batch: 1/1 in epoch 445/1000 \n",
      "... loss: 0.6851411461830139\n",
      "\n",
      "batch: 1/1 in epoch 446/1000 \n",
      "... loss: 0.6850758790969849\n",
      "\n",
      "batch: 1/1 in epoch 447/1000 \n",
      "... loss: 0.6850097179412842\n",
      "\n",
      "batch: 1/1 in epoch 448/1000 \n",
      "... loss: 0.6849431991577148\n",
      "\n",
      "batch: 1/1 in epoch 449/1000 \n",
      "... loss: 0.6848761439323425\n",
      "\n",
      "batch: 1/1 in epoch 450/1000 \n",
      "... loss: 0.6848081946372986\n",
      "\n",
      "batch: 1/1 in epoch 451/1000 \n",
      "... loss: 0.6847398281097412\n",
      "\n",
      "batch: 1/1 in epoch 452/1000 \n",
      "... loss: 0.6846706867218018\n",
      "\n",
      "batch: 1/1 in epoch 453/1000 \n",
      "... loss: 0.6846011877059937\n",
      "\n",
      "batch: 1/1 in epoch 454/1000 \n",
      "... loss: 0.6845308542251587\n",
      "\n",
      "batch: 1/1 in epoch 455/1000 \n",
      "... loss: 0.684459924697876\n",
      "\n",
      "batch: 1/1 in epoch 456/1000 \n",
      "... loss: 0.6843882203102112\n",
      "\n",
      "batch: 1/1 in epoch 457/1000 \n",
      "... loss: 0.6843159794807434\n",
      "\n",
      "batch: 1/1 in epoch 458/1000 \n",
      "... loss: 0.6842430830001831\n",
      "\n",
      "batch: 1/1 in epoch 459/1000 \n",
      "... loss: 0.6841692924499512\n",
      "\n",
      "batch: 1/1 in epoch 460/1000 \n",
      "... loss: 0.6840948462486267\n",
      "\n",
      "batch: 1/1 in epoch 461/1000 \n",
      "... loss: 0.6840200424194336\n",
      "\n",
      "batch: 1/1 in epoch 462/1000 \n",
      "... loss: 0.6839443445205688\n",
      "\n",
      "batch: 1/1 in epoch 463/1000 \n",
      "... loss: 0.6838676929473877\n",
      "\n",
      "batch: 1/1 in epoch 464/1000 \n",
      "... loss: 0.6837905645370483\n",
      "\n",
      "batch: 1/1 in epoch 465/1000 \n",
      "... loss: 0.6837127208709717\n",
      "\n",
      "batch: 1/1 in epoch 466/1000 \n",
      "... loss: 0.6836341023445129\n",
      "\n",
      "batch: 1/1 in epoch 467/1000 \n",
      "... loss: 0.6835546493530273\n",
      "\n",
      "batch: 1/1 in epoch 468/1000 \n",
      "... loss: 0.6834746599197388\n",
      "\n",
      "batch: 1/1 in epoch 469/1000 \n",
      "... loss: 0.6833937168121338\n",
      "\n",
      "batch: 1/1 in epoch 470/1000 \n",
      "... loss: 0.6833118200302124\n",
      "\n",
      "batch: 1/1 in epoch 471/1000 \n",
      "... loss: 0.6832294464111328\n",
      "\n",
      "batch: 1/1 in epoch 472/1000 \n",
      "... loss: 0.6831459999084473\n",
      "\n",
      "batch: 1/1 in epoch 473/1000 \n",
      "... loss: 0.683061957359314\n",
      "\n",
      "batch: 1/1 in epoch 474/1000 \n",
      "... loss: 0.6829769611358643\n",
      "\n",
      "batch: 1/1 in epoch 475/1000 \n",
      "... loss: 0.6828913688659668\n",
      "\n",
      "batch: 1/1 in epoch 476/1000 \n",
      "... loss: 0.6828047037124634\n",
      "\n",
      "batch: 1/1 in epoch 477/1000 \n",
      "... loss: 0.6827171444892883\n",
      "\n",
      "batch: 1/1 in epoch 478/1000 \n",
      "... loss: 0.6826289892196655\n",
      "\n",
      "batch: 1/1 in epoch 479/1000 \n",
      "... loss: 0.6825398206710815\n",
      "\n",
      "batch: 1/1 in epoch 480/1000 \n",
      "... loss: 0.6824498772621155\n",
      "\n",
      "batch: 1/1 in epoch 481/1000 \n",
      "... loss: 0.6823588609695435\n",
      "\n",
      "batch: 1/1 in epoch 482/1000 \n",
      "... loss: 0.6822668313980103\n",
      "\n",
      "batch: 1/1 in epoch 483/1000 \n",
      "... loss: 0.6821742057800293\n",
      "\n",
      "batch: 1/1 in epoch 484/1000 \n",
      "... loss: 0.6820803880691528\n",
      "\n",
      "batch: 1/1 in epoch 485/1000 \n",
      "... loss: 0.6819857954978943\n",
      "\n",
      "batch: 1/1 in epoch 486/1000 \n",
      "... loss: 0.6818901896476746\n",
      "\n",
      "batch: 1/1 in epoch 487/1000 \n",
      "... loss: 0.6817936897277832\n",
      "\n",
      "batch: 1/1 in epoch 488/1000 \n",
      "... loss: 0.6816960573196411\n",
      "\n",
      "batch: 1/1 in epoch 489/1000 \n",
      "... loss: 0.6815975308418274\n",
      "\n",
      "batch: 1/1 in epoch 490/1000 \n",
      "... loss: 0.6814979314804077\n",
      "\n",
      "batch: 1/1 in epoch 491/1000 \n",
      "... loss: 0.6813972592353821\n",
      "\n",
      "batch: 1/1 in epoch 492/1000 \n",
      "... loss: 0.6812956929206848\n",
      "\n",
      "batch: 1/1 in epoch 493/1000 \n",
      "... loss: 0.6811932325363159\n",
      "\n",
      "batch: 1/1 in epoch 494/1000 \n",
      "... loss: 0.681089460849762\n",
      "\n",
      "batch: 1/1 in epoch 495/1000 \n",
      "... loss: 0.6809844970703125\n",
      "\n",
      "batch: 1/1 in epoch 496/1000 \n",
      "... loss: 0.6808786392211914\n",
      "\n",
      "batch: 1/1 in epoch 497/1000 \n",
      "... loss: 0.6807717084884644\n",
      "\n",
      "batch: 1/1 in epoch 498/1000 \n",
      "... loss: 0.680663526058197\n",
      "\n",
      "batch: 1/1 in epoch 499/1000 \n",
      "... loss: 0.6805543899536133\n",
      "\n",
      "batch: 1/1 in epoch 500/1000 \n",
      "... loss: 0.6804440021514893\n",
      "\n",
      "batch: 1/1 in epoch 501/1000 \n",
      "... loss: 0.6803326606750488\n",
      "\n",
      "batch: 1/1 in epoch 502/1000 \n",
      "... loss: 0.6802197694778442\n",
      "\n",
      "batch: 1/1 in epoch 503/1000 \n",
      "... loss: 0.6801059246063232\n",
      "\n",
      "batch: 1/1 in epoch 504/1000 \n",
      "... loss: 0.6799910068511963\n",
      "\n",
      "batch: 1/1 in epoch 505/1000 \n",
      "... loss: 0.6798745393753052\n",
      "\n",
      "batch: 1/1 in epoch 506/1000 \n",
      "... loss: 0.6797569394111633\n",
      "\n",
      "batch: 1/1 in epoch 507/1000 \n",
      "... loss: 0.679638147354126\n",
      "\n",
      "batch: 1/1 in epoch 508/1000 \n",
      "... loss: 0.6795179843902588\n",
      "\n",
      "batch: 1/1 in epoch 509/1000 \n",
      "... loss: 0.6793967485427856\n",
      "\n",
      "batch: 1/1 in epoch 510/1000 \n",
      "... loss: 0.6792738437652588\n",
      "\n",
      "batch: 1/1 in epoch 511/1000 \n",
      "... loss: 0.679149866104126\n",
      "\n",
      "batch: 1/1 in epoch 512/1000 \n",
      "... loss: 0.6790244579315186\n",
      "\n",
      "batch: 1/1 in epoch 513/1000 \n",
      "... loss: 0.6788976192474365\n",
      "\n",
      "batch: 1/1 in epoch 514/1000 \n",
      "... loss: 0.6787695288658142\n",
      "\n",
      "batch: 1/1 in epoch 515/1000 \n",
      "... loss: 0.6786400079727173\n",
      "\n",
      "batch: 1/1 in epoch 516/1000 \n",
      "... loss: 0.6785091161727905\n",
      "\n",
      "batch: 1/1 in epoch 517/1000 \n",
      "... loss: 0.6783764958381653\n",
      "\n",
      "batch: 1/1 in epoch 518/1000 \n",
      "... loss: 0.6782426834106445\n",
      "\n",
      "batch: 1/1 in epoch 519/1000 \n",
      "... loss: 0.6781074404716492\n",
      "\n",
      "batch: 1/1 in epoch 520/1000 \n",
      "... loss: 0.6779706478118896\n",
      "\n",
      "batch: 1/1 in epoch 521/1000 \n",
      "... loss: 0.6778320670127869\n",
      "\n",
      "batch: 1/1 in epoch 522/1000 \n",
      "... loss: 0.6776924133300781\n",
      "\n",
      "batch: 1/1 in epoch 523/1000 \n",
      "... loss: 0.6775504350662231\n",
      "\n",
      "batch: 1/1 in epoch 524/1000 \n",
      "... loss: 0.6774075031280518\n",
      "\n",
      "batch: 1/1 in epoch 525/1000 \n",
      "... loss: 0.6772630214691162\n",
      "\n",
      "batch: 1/1 in epoch 526/1000 \n",
      "... loss: 0.6771166324615479\n",
      "\n",
      "batch: 1/1 in epoch 527/1000 \n",
      "... loss: 0.6769685745239258\n",
      "\n",
      "batch: 1/1 in epoch 528/1000 \n",
      "... loss: 0.67681884765625\n",
      "\n",
      "batch: 1/1 in epoch 529/1000 \n",
      "... loss: 0.6766674518585205\n",
      "\n",
      "batch: 1/1 in epoch 530/1000 \n",
      "... loss: 0.6765143275260925\n",
      "\n",
      "batch: 1/1 in epoch 531/1000 \n",
      "... loss: 0.6763595342636108\n",
      "\n",
      "batch: 1/1 in epoch 532/1000 \n",
      "... loss: 0.6762027740478516\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 533/1000 \n",
      "... loss: 0.6760441064834595\n",
      "\n",
      "batch: 1/1 in epoch 534/1000 \n",
      "... loss: 0.6758838295936584\n",
      "\n",
      "batch: 1/1 in epoch 535/1000 \n",
      "... loss: 0.6757216453552246\n",
      "\n",
      "batch: 1/1 in epoch 536/1000 \n",
      "... loss: 0.6755577325820923\n",
      "\n",
      "batch: 1/1 in epoch 537/1000 \n",
      "... loss: 0.675391435623169\n",
      "\n",
      "batch: 1/1 in epoch 538/1000 \n",
      "... loss: 0.6752234697341919\n",
      "\n",
      "batch: 1/1 in epoch 539/1000 \n",
      "... loss: 0.6750534772872925\n",
      "\n",
      "batch: 1/1 in epoch 540/1000 \n",
      "... loss: 0.674881637096405\n",
      "\n",
      "batch: 1/1 in epoch 541/1000 \n",
      "... loss: 0.6747076511383057\n",
      "\n",
      "batch: 1/1 in epoch 542/1000 \n",
      "... loss: 0.6745316386222839\n",
      "\n",
      "batch: 1/1 in epoch 543/1000 \n",
      "... loss: 0.6743534803390503\n",
      "\n",
      "batch: 1/1 in epoch 544/1000 \n",
      "... loss: 0.6741733551025391\n",
      "\n",
      "batch: 1/1 in epoch 545/1000 \n",
      "... loss: 0.6739909648895264\n",
      "\n",
      "batch: 1/1 in epoch 546/1000 \n",
      "... loss: 0.6738060712814331\n",
      "\n",
      "batch: 1/1 in epoch 547/1000 \n",
      "... loss: 0.6736193895339966\n",
      "\n",
      "batch: 1/1 in epoch 548/1000 \n",
      "... loss: 0.6734300255775452\n",
      "\n",
      "batch: 1/1 in epoch 549/1000 \n",
      "... loss: 0.6732383966445923\n",
      "\n",
      "batch: 1/1 in epoch 550/1000 \n",
      "... loss: 0.6730450987815857\n",
      "\n",
      "batch: 1/1 in epoch 551/1000 \n",
      "... loss: 0.6728488206863403\n",
      "\n",
      "batch: 1/1 in epoch 552/1000 \n",
      "... loss: 0.6726502776145935\n",
      "\n",
      "batch: 1/1 in epoch 553/1000 \n",
      "... loss: 0.6724493503570557\n",
      "\n",
      "batch: 1/1 in epoch 554/1000 \n",
      "... loss: 0.672245979309082\n",
      "\n",
      "batch: 1/1 in epoch 555/1000 \n",
      "... loss: 0.6720401048660278\n",
      "\n",
      "batch: 1/1 in epoch 556/1000 \n",
      "... loss: 0.671831488609314\n",
      "\n",
      "batch: 1/1 in epoch 557/1000 \n",
      "... loss: 0.6716203689575195\n",
      "\n",
      "batch: 1/1 in epoch 558/1000 \n",
      "... loss: 0.671406626701355\n",
      "\n",
      "batch: 1/1 in epoch 559/1000 \n",
      "... loss: 0.6711902618408203\n",
      "\n",
      "batch: 1/1 in epoch 560/1000 \n",
      "... loss: 0.6709710359573364\n",
      "\n",
      "batch: 1/1 in epoch 561/1000 \n",
      "... loss: 0.6707491874694824\n",
      "\n",
      "batch: 1/1 in epoch 562/1000 \n",
      "... loss: 0.6705245971679688\n",
      "\n",
      "batch: 1/1 in epoch 563/1000 \n",
      "... loss: 0.6702969074249268\n",
      "\n",
      "batch: 1/1 in epoch 564/1000 \n",
      "... loss: 0.6700664162635803\n",
      "\n",
      "batch: 1/1 in epoch 565/1000 \n",
      "... loss: 0.6698331832885742\n",
      "\n",
      "batch: 1/1 in epoch 566/1000 \n",
      "... loss: 0.6695966720581055\n",
      "\n",
      "batch: 1/1 in epoch 567/1000 \n",
      "... loss: 0.6693572998046875\n",
      "\n",
      "batch: 1/1 in epoch 568/1000 \n",
      "... loss: 0.6691147089004517\n",
      "\n",
      "batch: 1/1 in epoch 569/1000 \n",
      "... loss: 0.668869137763977\n",
      "\n",
      "batch: 1/1 in epoch 570/1000 \n",
      "... loss: 0.6686203479766846\n",
      "\n",
      "batch: 1/1 in epoch 571/1000 \n",
      "... loss: 0.6683681011199951\n",
      "\n",
      "batch: 1/1 in epoch 572/1000 \n",
      "... loss: 0.6681127548217773\n",
      "\n",
      "batch: 1/1 in epoch 573/1000 \n",
      "... loss: 0.6678538918495178\n",
      "\n",
      "batch: 1/1 in epoch 574/1000 \n",
      "... loss: 0.66759192943573\n",
      "\n",
      "batch: 1/1 in epoch 575/1000 \n",
      "... loss: 0.6673263311386108\n",
      "\n",
      "batch: 1/1 in epoch 576/1000 \n",
      "... loss: 0.6670573949813843\n",
      "\n",
      "batch: 1/1 in epoch 577/1000 \n",
      "... loss: 0.6667845249176025\n",
      "\n",
      "batch: 1/1 in epoch 578/1000 \n",
      "... loss: 0.6665081977844238\n",
      "\n",
      "batch: 1/1 in epoch 579/1000 \n",
      "... loss: 0.6662283539772034\n",
      "\n",
      "batch: 1/1 in epoch 580/1000 \n",
      "... loss: 0.6659445762634277\n",
      "\n",
      "batch: 1/1 in epoch 581/1000 \n",
      "... loss: 0.6656569838523865\n",
      "\n",
      "batch: 1/1 in epoch 582/1000 \n",
      "... loss: 0.6653655171394348\n",
      "\n",
      "batch: 1/1 in epoch 583/1000 \n",
      "... loss: 0.6650701761245728\n",
      "\n",
      "batch: 1/1 in epoch 584/1000 \n",
      "... loss: 0.6647707223892212\n",
      "\n",
      "batch: 1/1 in epoch 585/1000 \n",
      "... loss: 0.6644673347473145\n",
      "\n",
      "batch: 1/1 in epoch 586/1000 \n",
      "... loss: 0.6641594767570496\n",
      "\n",
      "batch: 1/1 in epoch 587/1000 \n",
      "... loss: 0.6638475060462952\n",
      "\n",
      "batch: 1/1 in epoch 588/1000 \n",
      "... loss: 0.6635313034057617\n",
      "\n",
      "batch: 1/1 in epoch 589/1000 \n",
      "... loss: 0.6632107496261597\n",
      "\n",
      "batch: 1/1 in epoch 590/1000 \n",
      "... loss: 0.6628857851028442\n",
      "\n",
      "batch: 1/1 in epoch 591/1000 \n",
      "... loss: 0.6625562906265259\n",
      "\n",
      "batch: 1/1 in epoch 592/1000 \n",
      "... loss: 0.6622223854064941\n",
      "\n",
      "batch: 1/1 in epoch 593/1000 \n",
      "... loss: 0.6618834733963013\n",
      "\n",
      "batch: 1/1 in epoch 594/1000 \n",
      "... loss: 0.6615397930145264\n",
      "\n",
      "batch: 1/1 in epoch 595/1000 \n",
      "... loss: 0.6611914038658142\n",
      "\n",
      "batch: 1/1 in epoch 596/1000 \n",
      "... loss: 0.6608381271362305\n",
      "\n",
      "batch: 1/1 in epoch 597/1000 \n",
      "... loss: 0.6604797840118408\n",
      "\n",
      "batch: 1/1 in epoch 598/1000 \n",
      "... loss: 0.6601161956787109\n",
      "\n",
      "batch: 1/1 in epoch 599/1000 \n",
      "... loss: 0.6597476005554199\n",
      "\n",
      "batch: 1/1 in epoch 600/1000 \n",
      "... loss: 0.6593737602233887\n",
      "\n",
      "batch: 1/1 in epoch 601/1000 \n",
      "... loss: 0.6589943170547485\n",
      "\n",
      "batch: 1/1 in epoch 602/1000 \n",
      "... loss: 0.6586093902587891\n",
      "\n",
      "batch: 1/1 in epoch 603/1000 \n",
      "... loss: 0.6582192182540894\n",
      "\n",
      "batch: 1/1 in epoch 604/1000 \n",
      "... loss: 0.6578231453895569\n",
      "\n",
      "batch: 1/1 in epoch 605/1000 \n",
      "... loss: 0.6574212312698364\n",
      "\n",
      "batch: 1/1 in epoch 606/1000 \n",
      "... loss: 0.6570136547088623\n",
      "\n",
      "batch: 1/1 in epoch 607/1000 \n",
      "... loss: 0.6565998792648315\n",
      "\n",
      "batch: 1/1 in epoch 608/1000 \n",
      "... loss: 0.6561801433563232\n",
      "\n",
      "batch: 1/1 in epoch 609/1000 \n",
      "... loss: 0.6557542085647583\n",
      "\n",
      "batch: 1/1 in epoch 610/1000 \n",
      "... loss: 0.6553219556808472\n",
      "\n",
      "batch: 1/1 in epoch 611/1000 \n",
      "... loss: 0.654883086681366\n",
      "\n",
      "batch: 1/1 in epoch 612/1000 \n",
      "... loss: 0.6544381380081177\n",
      "\n",
      "batch: 1/1 in epoch 613/1000 \n",
      "... loss: 0.653985857963562\n",
      "\n",
      "batch: 1/1 in epoch 614/1000 \n",
      "... loss: 0.6535270810127258\n",
      "\n",
      "batch: 1/1 in epoch 615/1000 \n",
      "... loss: 0.6530616879463196\n",
      "\n",
      "batch: 1/1 in epoch 616/1000 \n",
      "... loss: 0.6525888442993164\n",
      "\n",
      "batch: 1/1 in epoch 617/1000 \n",
      "... loss: 0.6521089673042297\n",
      "\n",
      "batch: 1/1 in epoch 618/1000 \n",
      "... loss: 0.6516218185424805\n",
      "\n",
      "batch: 1/1 in epoch 619/1000 \n",
      "... loss: 0.6511274576187134\n",
      "\n",
      "batch: 1/1 in epoch 620/1000 \n",
      "... loss: 0.6506251096725464\n",
      "\n",
      "batch: 1/1 in epoch 621/1000 \n",
      "... loss: 0.6501152515411377\n",
      "\n",
      "batch: 1/1 in epoch 622/1000 \n",
      "... loss: 0.6495975852012634\n",
      "\n",
      "batch: 1/1 in epoch 623/1000 \n",
      "... loss: 0.6490716934204102\n",
      "\n",
      "batch: 1/1 in epoch 624/1000 \n",
      "... loss: 0.6485379338264465\n",
      "\n",
      "batch: 1/1 in epoch 625/1000 \n",
      "... loss: 0.6479957103729248\n",
      "\n",
      "batch: 1/1 in epoch 626/1000 \n",
      "... loss: 0.647445023059845\n",
      "\n",
      "batch: 1/1 in epoch 627/1000 \n",
      "... loss: 0.6468857526779175\n",
      "\n",
      "batch: 1/1 in epoch 628/1000 \n",
      "... loss: 0.646317720413208\n",
      "\n",
      "batch: 1/1 in epoch 629/1000 \n",
      "... loss: 0.6457407474517822\n",
      "\n",
      "batch: 1/1 in epoch 630/1000 \n",
      "... loss: 0.6451544761657715\n",
      "\n",
      "batch: 1/1 in epoch 631/1000 \n",
      "... loss: 0.6445590853691101\n",
      "\n",
      "batch: 1/1 in epoch 632/1000 \n",
      "... loss: 0.6439543962478638\n",
      "\n",
      "batch: 1/1 in epoch 633/1000 \n",
      "... loss: 0.6433397531509399\n",
      "\n",
      "batch: 1/1 in epoch 634/1000 \n",
      "... loss: 0.6427154541015625\n",
      "\n",
      "batch: 1/1 in epoch 635/1000 \n",
      "... loss: 0.6420810222625732\n",
      "\n",
      "batch: 1/1 in epoch 636/1000 \n",
      "... loss: 0.6414365768432617\n",
      "\n",
      "batch: 1/1 in epoch 637/1000 \n",
      "... loss: 0.6407814621925354\n",
      "\n",
      "batch: 1/1 in epoch 638/1000 \n",
      "... loss: 0.6401158571243286\n",
      "\n",
      "batch: 1/1 in epoch 639/1000 \n",
      "... loss: 0.6394397020339966\n",
      "\n",
      "batch: 1/1 in epoch 640/1000 \n",
      "... loss: 0.6387522220611572\n",
      "\n",
      "batch: 1/1 in epoch 641/1000 \n",
      "... loss: 0.6380535364151001\n",
      "\n",
      "batch: 1/1 in epoch 642/1000 \n",
      "... loss: 0.6373434066772461\n",
      "\n",
      "batch: 1/1 in epoch 643/1000 \n",
      "... loss: 0.6366217732429504\n",
      "\n",
      "batch: 1/1 in epoch 644/1000 \n",
      "... loss: 0.6358882188796997\n",
      "\n",
      "batch: 1/1 in epoch 645/1000 \n",
      "... loss: 0.6351425647735596\n",
      "\n",
      "batch: 1/1 in epoch 646/1000 \n",
      "... loss: 0.6343845725059509\n",
      "\n",
      "batch: 1/1 in epoch 647/1000 \n",
      "... loss: 0.6336138248443604\n",
      "\n",
      "batch: 1/1 in epoch 648/1000 \n",
      "... loss: 0.6328306198120117\n",
      "\n",
      "batch: 1/1 in epoch 649/1000 \n",
      "... loss: 0.6320340633392334\n",
      "\n",
      "batch: 1/1 in epoch 650/1000 \n",
      "... loss: 0.6312243342399597\n",
      "\n",
      "batch: 1/1 in epoch 651/1000 \n",
      "... loss: 0.6304008960723877\n",
      "\n",
      "batch: 1/1 in epoch 652/1000 \n",
      "... loss: 0.6295638084411621\n",
      "\n",
      "batch: 1/1 in epoch 653/1000 \n",
      "... loss: 0.6287124752998352\n",
      "\n",
      "batch: 1/1 in epoch 654/1000 \n",
      "... loss: 0.6278465986251831\n",
      "\n",
      "batch: 1/1 in epoch 655/1000 \n",
      "... loss: 0.6269664764404297\n",
      "\n",
      "batch: 1/1 in epoch 656/1000 \n",
      "... loss: 0.626071035861969\n",
      "\n",
      "batch: 1/1 in epoch 657/1000 \n",
      "... loss: 0.6251604557037354\n",
      "\n",
      "batch: 1/1 in epoch 658/1000 \n",
      "... loss: 0.6242344975471497\n",
      "\n",
      "batch: 1/1 in epoch 659/1000 \n",
      "... loss: 0.6232924461364746\n",
      "\n",
      "batch: 1/1 in epoch 660/1000 \n",
      "... loss: 0.622334361076355\n",
      "\n",
      "batch: 1/1 in epoch 661/1000 \n",
      "... loss: 0.6213597059249878\n",
      "\n",
      "batch: 1/1 in epoch 662/1000 \n",
      "... loss: 0.6203685998916626\n",
      "\n",
      "batch: 1/1 in epoch 663/1000 \n",
      "... loss: 0.619360089302063\n",
      "\n",
      "batch: 1/1 in epoch 664/1000 \n",
      "... loss: 0.6183342337608337\n",
      "\n",
      "batch: 1/1 in epoch 665/1000 \n",
      "... loss: 0.6172906160354614\n",
      "\n",
      "batch: 1/1 in epoch 666/1000 \n",
      "... loss: 0.6162288188934326\n",
      "\n",
      "batch: 1/1 in epoch 667/1000 \n",
      "... loss: 0.6151486039161682\n",
      "\n",
      "batch: 1/1 in epoch 668/1000 \n",
      "... loss: 0.6140493750572205\n",
      "\n",
      "batch: 1/1 in epoch 669/1000 \n",
      "... loss: 0.6129311323165894\n",
      "\n",
      "batch: 1/1 in epoch 670/1000 \n",
      "... loss: 0.6117936372756958\n",
      "\n",
      "batch: 1/1 in epoch 671/1000 \n",
      "... loss: 0.6106357574462891\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 672/1000 \n",
      "... loss: 0.6094576120376587\n",
      "\n",
      "batch: 1/1 in epoch 673/1000 \n",
      "... loss: 0.6082589626312256\n",
      "\n",
      "batch: 1/1 in epoch 674/1000 \n",
      "... loss: 0.6070394515991211\n",
      "\n",
      "batch: 1/1 in epoch 675/1000 \n",
      "... loss: 0.6057977676391602\n",
      "\n",
      "batch: 1/1 in epoch 676/1000 \n",
      "... loss: 0.6045346260070801\n",
      "\n",
      "batch: 1/1 in epoch 677/1000 \n",
      "... loss: 0.603249192237854\n",
      "\n",
      "batch: 1/1 in epoch 678/1000 \n",
      "... loss: 0.6019406318664551\n",
      "\n",
      "batch: 1/1 in epoch 679/1000 \n",
      "... loss: 0.6006091237068176\n",
      "\n",
      "batch: 1/1 in epoch 680/1000 \n",
      "... loss: 0.5992540121078491\n",
      "\n",
      "batch: 1/1 in epoch 681/1000 \n",
      "... loss: 0.5978747606277466\n",
      "\n",
      "batch: 1/1 in epoch 682/1000 \n",
      "... loss: 0.5964714288711548\n",
      "\n",
      "batch: 1/1 in epoch 683/1000 \n",
      "... loss: 0.5950427651405334\n",
      "\n",
      "batch: 1/1 in epoch 684/1000 \n",
      "... loss: 0.5935887098312378\n",
      "\n",
      "batch: 1/1 in epoch 685/1000 \n",
      "... loss: 0.5921087265014648\n",
      "\n",
      "batch: 1/1 in epoch 686/1000 \n",
      "... loss: 0.5906026363372803\n",
      "\n",
      "batch: 1/1 in epoch 687/1000 \n",
      "... loss: 0.5890696048736572\n",
      "\n",
      "batch: 1/1 in epoch 688/1000 \n",
      "... loss: 0.5875096321105957\n",
      "\n",
      "batch: 1/1 in epoch 689/1000 \n",
      "... loss: 0.5859214067459106\n",
      "\n",
      "batch: 1/1 in epoch 690/1000 \n",
      "... loss: 0.5843051671981812\n",
      "\n",
      "batch: 1/1 in epoch 691/1000 \n",
      "... loss: 0.5826601982116699\n",
      "\n",
      "batch: 1/1 in epoch 692/1000 \n",
      "... loss: 0.5809859037399292\n",
      "\n",
      "batch: 1/1 in epoch 693/1000 \n",
      "... loss: 0.579282283782959\n",
      "\n",
      "batch: 1/1 in epoch 694/1000 \n",
      "... loss: 0.577548086643219\n",
      "\n",
      "batch: 1/1 in epoch 695/1000 \n",
      "... loss: 0.5757832527160645\n",
      "\n",
      "batch: 1/1 in epoch 696/1000 \n",
      "... loss: 0.5739873647689819\n",
      "\n",
      "batch: 1/1 in epoch 697/1000 \n",
      "... loss: 0.5721595287322998\n",
      "\n",
      "batch: 1/1 in epoch 698/1000 \n",
      "... loss: 0.5702998638153076\n",
      "\n",
      "batch: 1/1 in epoch 699/1000 \n",
      "... loss: 0.568407416343689\n",
      "\n",
      "batch: 1/1 in epoch 700/1000 \n",
      "... loss: 0.5664815902709961\n",
      "\n",
      "batch: 1/1 in epoch 701/1000 \n",
      "... loss: 0.5645219087600708\n",
      "\n",
      "batch: 1/1 in epoch 702/1000 \n",
      "... loss: 0.562528133392334\n",
      "\n",
      "batch: 1/1 in epoch 703/1000 \n",
      "... loss: 0.5604994297027588\n",
      "\n",
      "batch: 1/1 in epoch 704/1000 \n",
      "... loss: 0.5584357976913452\n",
      "\n",
      "batch: 1/1 in epoch 705/1000 \n",
      "... loss: 0.5563363432884216\n",
      "\n",
      "batch: 1/1 in epoch 706/1000 \n",
      "... loss: 0.5542006492614746\n",
      "\n",
      "batch: 1/1 in epoch 707/1000 \n",
      "... loss: 0.5520284175872803\n",
      "\n",
      "batch: 1/1 in epoch 708/1000 \n",
      "... loss: 0.5498190522193909\n",
      "\n",
      "batch: 1/1 in epoch 709/1000 \n",
      "... loss: 0.5475719571113586\n",
      "\n",
      "batch: 1/1 in epoch 710/1000 \n",
      "... loss: 0.5452869534492493\n",
      "\n",
      "batch: 1/1 in epoch 711/1000 \n",
      "... loss: 0.5429630279541016\n",
      "\n",
      "batch: 1/1 in epoch 712/1000 \n",
      "... loss: 0.5406003594398499\n",
      "\n",
      "batch: 1/1 in epoch 713/1000 \n",
      "... loss: 0.5381982326507568\n",
      "\n",
      "batch: 1/1 in epoch 714/1000 \n",
      "... loss: 0.5357562303543091\n",
      "\n",
      "batch: 1/1 in epoch 715/1000 \n",
      "... loss: 0.5332740545272827\n",
      "\n",
      "batch: 1/1 in epoch 716/1000 \n",
      "... loss: 0.53075110912323\n",
      "\n",
      "batch: 1/1 in epoch 717/1000 \n",
      "... loss: 0.5281871557235718\n",
      "\n",
      "batch: 1/1 in epoch 718/1000 \n",
      "... loss: 0.5255816578865051\n",
      "\n",
      "batch: 1/1 in epoch 719/1000 \n",
      "... loss: 0.52293461561203\n",
      "\n",
      "batch: 1/1 in epoch 720/1000 \n",
      "... loss: 0.520245373249054\n",
      "\n",
      "batch: 1/1 in epoch 721/1000 \n",
      "... loss: 0.517513632774353\n",
      "\n",
      "batch: 1/1 in epoch 722/1000 \n",
      "... loss: 0.5147390961647034\n",
      "\n",
      "batch: 1/1 in epoch 723/1000 \n",
      "... loss: 0.511921763420105\n",
      "\n",
      "batch: 1/1 in epoch 724/1000 \n",
      "... loss: 0.5090609788894653\n",
      "\n",
      "batch: 1/1 in epoch 725/1000 \n",
      "... loss: 0.506156861782074\n",
      "\n",
      "batch: 1/1 in epoch 726/1000 \n",
      "... loss: 0.5032088756561279\n",
      "\n",
      "batch: 1/1 in epoch 727/1000 \n",
      "... loss: 0.5002169609069824\n",
      "\n",
      "batch: 1/1 in epoch 728/1000 \n",
      "... loss: 0.4971811771392822\n",
      "\n",
      "batch: 1/1 in epoch 729/1000 \n",
      "... loss: 0.49410098791122437\n",
      "\n",
      "batch: 1/1 in epoch 730/1000 \n",
      "... loss: 0.49097681045532227\n",
      "\n",
      "batch: 1/1 in epoch 731/1000 \n",
      "... loss: 0.48780810832977295\n",
      "\n",
      "batch: 1/1 in epoch 732/1000 \n",
      "... loss: 0.4845949709415436\n",
      "\n",
      "batch: 1/1 in epoch 733/1000 \n",
      "... loss: 0.4813372790813446\n",
      "\n",
      "batch: 1/1 in epoch 734/1000 \n",
      "... loss: 0.4780352711677551\n",
      "\n",
      "batch: 1/1 in epoch 735/1000 \n",
      "... loss: 0.47468918561935425\n",
      "\n",
      "batch: 1/1 in epoch 736/1000 \n",
      "... loss: 0.47129857540130615\n",
      "\n",
      "batch: 1/1 in epoch 737/1000 \n",
      "... loss: 0.4678639769554138\n",
      "\n",
      "batch: 1/1 in epoch 738/1000 \n",
      "... loss: 0.464385449886322\n",
      "\n",
      "batch: 1/1 in epoch 739/1000 \n",
      "... loss: 0.46086350083351135\n",
      "\n",
      "batch: 1/1 in epoch 740/1000 \n",
      "... loss: 0.45729804039001465\n",
      "\n",
      "batch: 1/1 in epoch 741/1000 \n",
      "... loss: 0.45368969440460205\n",
      "\n",
      "batch: 1/1 in epoch 742/1000 \n",
      "... loss: 0.4500387907028198\n",
      "\n",
      "batch: 1/1 in epoch 743/1000 \n",
      "... loss: 0.4463455080986023\n",
      "\n",
      "batch: 1/1 in epoch 744/1000 \n",
      "... loss: 0.44261062145233154\n",
      "\n",
      "batch: 1/1 in epoch 745/1000 \n",
      "... loss: 0.4388348460197449\n",
      "\n",
      "batch: 1/1 in epoch 746/1000 \n",
      "... loss: 0.4350183606147766\n",
      "\n",
      "batch: 1/1 in epoch 747/1000 \n",
      "... loss: 0.4311622977256775\n",
      "\n",
      "batch: 1/1 in epoch 748/1000 \n",
      "... loss: 0.42726728320121765\n",
      "\n",
      "batch: 1/1 in epoch 749/1000 \n",
      "... loss: 0.4233343005180359\n",
      "\n",
      "batch: 1/1 in epoch 750/1000 \n",
      "... loss: 0.41936391592025757\n",
      "\n",
      "batch: 1/1 in epoch 751/1000 \n",
      "... loss: 0.41535747051239014\n",
      "\n",
      "batch: 1/1 in epoch 752/1000 \n",
      "... loss: 0.4113156795501709\n",
      "\n",
      "batch: 1/1 in epoch 753/1000 \n",
      "... loss: 0.407240092754364\n",
      "\n",
      "batch: 1/1 in epoch 754/1000 \n",
      "... loss: 0.403131365776062\n",
      "\n",
      "batch: 1/1 in epoch 755/1000 \n",
      "... loss: 0.3989911675453186\n",
      "\n",
      "batch: 1/1 in epoch 756/1000 \n",
      "... loss: 0.39482080936431885\n",
      "\n",
      "batch: 1/1 in epoch 757/1000 \n",
      "... loss: 0.3906213641166687\n",
      "\n",
      "batch: 1/1 in epoch 758/1000 \n",
      "... loss: 0.38639503717422485\n",
      "\n",
      "batch: 1/1 in epoch 759/1000 \n",
      "... loss: 0.3821426331996918\n",
      "\n",
      "batch: 1/1 in epoch 760/1000 \n",
      "... loss: 0.37786585092544556\n",
      "\n",
      "batch: 1/1 in epoch 761/1000 \n",
      "... loss: 0.3735666573047638\n",
      "\n",
      "batch: 1/1 in epoch 762/1000 \n",
      "... loss: 0.36924660205841064\n",
      "\n",
      "batch: 1/1 in epoch 763/1000 \n",
      "... loss: 0.3649073839187622\n",
      "\n",
      "batch: 1/1 in epoch 764/1000 \n",
      "... loss: 0.3605508804321289\n",
      "\n",
      "batch: 1/1 in epoch 765/1000 \n",
      "... loss: 0.3561789393424988\n",
      "\n",
      "batch: 1/1 in epoch 766/1000 \n",
      "... loss: 0.3517935276031494\n",
      "\n",
      "batch: 1/1 in epoch 767/1000 \n",
      "... loss: 0.3473966121673584\n",
      "\n",
      "batch: 1/1 in epoch 768/1000 \n",
      "... loss: 0.34299010038375854\n",
      "\n",
      "batch: 1/1 in epoch 769/1000 \n",
      "... loss: 0.3385760188102722\n",
      "\n",
      "batch: 1/1 in epoch 770/1000 \n",
      "... loss: 0.33415618538856506\n",
      "\n",
      "batch: 1/1 in epoch 771/1000 \n",
      "... loss: 0.3297330141067505\n",
      "\n",
      "batch: 1/1 in epoch 772/1000 \n",
      "... loss: 0.3253086805343628\n",
      "\n",
      "batch: 1/1 in epoch 773/1000 \n",
      "... loss: 0.3208850026130676\n",
      "\n",
      "batch: 1/1 in epoch 774/1000 \n",
      "... loss: 0.3164639472961426\n",
      "\n",
      "batch: 1/1 in epoch 775/1000 \n",
      "... loss: 0.31204771995544434\n",
      "\n",
      "batch: 1/1 in epoch 776/1000 \n",
      "... loss: 0.3076387047767639\n",
      "\n",
      "batch: 1/1 in epoch 777/1000 \n",
      "... loss: 0.30323874950408936\n",
      "\n",
      "batch: 1/1 in epoch 778/1000 \n",
      "... loss: 0.29885005950927734\n",
      "\n",
      "batch: 1/1 in epoch 779/1000 \n",
      "... loss: 0.29447442293167114\n",
      "\n",
      "batch: 1/1 in epoch 780/1000 \n",
      "... loss: 0.2901144027709961\n",
      "\n",
      "batch: 1/1 in epoch 781/1000 \n",
      "... loss: 0.2857717275619507\n",
      "\n",
      "batch: 1/1 in epoch 782/1000 \n",
      "... loss: 0.2814486026763916\n",
      "\n",
      "batch: 1/1 in epoch 783/1000 \n",
      "... loss: 0.2771467864513397\n",
      "\n",
      "batch: 1/1 in epoch 784/1000 \n",
      "... loss: 0.27286824584007263\n",
      "\n",
      "batch: 1/1 in epoch 785/1000 \n",
      "... loss: 0.26861506700515747\n",
      "\n",
      "batch: 1/1 in epoch 786/1000 \n",
      "... loss: 0.2643890976905823\n",
      "\n",
      "batch: 1/1 in epoch 787/1000 \n",
      "... loss: 0.26019197702407837\n",
      "\n",
      "batch: 1/1 in epoch 788/1000 \n",
      "... loss: 0.2560257613658905\n",
      "\n",
      "batch: 1/1 in epoch 789/1000 \n",
      "... loss: 0.2518919110298157\n",
      "\n",
      "batch: 1/1 in epoch 790/1000 \n",
      "... loss: 0.24779224395751953\n",
      "\n",
      "batch: 1/1 in epoch 791/1000 \n",
      "... loss: 0.24372828006744385\n",
      "\n",
      "batch: 1/1 in epoch 792/1000 \n",
      "... loss: 0.23970144987106323\n",
      "\n",
      "batch: 1/1 in epoch 793/1000 \n",
      "... loss: 0.23571346700191498\n",
      "\n",
      "batch: 1/1 in epoch 794/1000 \n",
      "... loss: 0.23176559805870056\n",
      "\n",
      "batch: 1/1 in epoch 795/1000 \n",
      "... loss: 0.22785915434360504\n",
      "\n",
      "batch: 1/1 in epoch 796/1000 \n",
      "... loss: 0.2239951491355896\n",
      "\n",
      "batch: 1/1 in epoch 797/1000 \n",
      "... loss: 0.22017526626586914\n",
      "\n",
      "batch: 1/1 in epoch 798/1000 \n",
      "... loss: 0.21640023589134216\n",
      "\n",
      "batch: 1/1 in epoch 799/1000 \n",
      "... loss: 0.2126712054014206\n",
      "\n",
      "batch: 1/1 in epoch 800/1000 \n",
      "... loss: 0.20898908376693726\n",
      "\n",
      "batch: 1/1 in epoch 801/1000 \n",
      "... loss: 0.20535463094711304\n",
      "\n",
      "batch: 1/1 in epoch 802/1000 \n",
      "... loss: 0.20176881551742554\n",
      "\n",
      "batch: 1/1 in epoch 803/1000 \n",
      "... loss: 0.1982322633266449\n",
      "\n",
      "batch: 1/1 in epoch 804/1000 \n",
      "... loss: 0.1947455257177353\n",
      "\n",
      "batch: 1/1 in epoch 805/1000 \n",
      "... loss: 0.1913093477487564\n",
      "\n",
      "batch: 1/1 in epoch 806/1000 \n",
      "... loss: 0.18792401254177094\n",
      "\n",
      "batch: 1/1 in epoch 807/1000 \n",
      "... loss: 0.1845899522304535\n",
      "\n",
      "batch: 1/1 in epoch 808/1000 \n",
      "... loss: 0.18130755424499512\n",
      "\n",
      "batch: 1/1 in epoch 809/1000 \n",
      "... loss: 0.17807704210281372\n",
      "\n",
      "batch: 1/1 in epoch 810/1000 \n",
      "... loss: 0.17489871382713318\n",
      "\n",
      "batch: 1/1 in epoch 811/1000 \n",
      "... loss: 0.1717725545167923\n",
      "\n",
      "batch: 1/1 in epoch 812/1000 \n",
      "... loss: 0.1686985194683075\n",
      "\n",
      "batch: 1/1 in epoch 813/1000 \n",
      "... loss: 0.16567692160606384\n",
      "\n",
      "batch: 1/1 in epoch 814/1000 \n",
      "... loss: 0.16270752251148224\n",
      "\n",
      "batch: 1/1 in epoch 815/1000 \n",
      "... loss: 0.15979009866714478\n",
      "\n",
      "batch: 1/1 in epoch 816/1000 \n",
      "... loss: 0.15692463517189026\n",
      "\n",
      "batch: 1/1 in epoch 817/1000 \n",
      "... loss: 0.15411090850830078\n",
      "\n",
      "batch: 1/1 in epoch 818/1000 \n",
      "... loss: 0.15134844183921814\n",
      "\n",
      "batch: 1/1 in epoch 819/1000 \n",
      "... loss: 0.14863714575767517\n",
      "\n",
      "batch: 1/1 in epoch 820/1000 \n",
      "... loss: 0.14597654342651367\n",
      "\n",
      "batch: 1/1 in epoch 821/1000 \n",
      "... loss: 0.14336630702018738\n",
      "\n",
      "batch: 1/1 in epoch 822/1000 \n",
      "... loss: 0.1408059000968933\n",
      "\n",
      "batch: 1/1 in epoch 823/1000 \n",
      "... loss: 0.13829483091831207\n",
      "\n",
      "batch: 1/1 in epoch 824/1000 \n",
      "... loss: 0.13583269715309143\n",
      "\n",
      "batch: 1/1 in epoch 825/1000 \n",
      "... loss: 0.1334189772605896\n",
      "\n",
      "batch: 1/1 in epoch 826/1000 \n",
      "... loss: 0.1310529261827469\n",
      "\n",
      "batch: 1/1 in epoch 827/1000 \n",
      "... loss: 0.12873408198356628\n",
      "\n",
      "batch: 1/1 in epoch 828/1000 \n",
      "... loss: 0.1264616847038269\n",
      "\n",
      "batch: 1/1 in epoch 829/1000 \n",
      "... loss: 0.12423539906740189\n",
      "\n",
      "batch: 1/1 in epoch 830/1000 \n",
      "... loss: 0.12205415219068527\n",
      "\n",
      "batch: 1/1 in epoch 831/1000 \n",
      "... loss: 0.11991767585277557\n",
      "\n",
      "batch: 1/1 in epoch 832/1000 \n",
      "... loss: 0.11782510578632355\n",
      "\n",
      "batch: 1/1 in epoch 833/1000 \n",
      "... loss: 0.11577565968036652\n",
      "\n",
      "batch: 1/1 in epoch 834/1000 \n",
      "... loss: 0.11376875638961792\n",
      "\n",
      "batch: 1/1 in epoch 835/1000 \n",
      "... loss: 0.11180361360311508\n",
      "\n",
      "batch: 1/1 in epoch 836/1000 \n",
      "... loss: 0.10987967252731323\n",
      "\n",
      "batch: 1/1 in epoch 837/1000 \n",
      "... loss: 0.10799611359834671\n",
      "\n",
      "batch: 1/1 in epoch 838/1000 \n",
      "... loss: 0.10615208745002747\n",
      "\n",
      "batch: 1/1 in epoch 839/1000 \n",
      "... loss: 0.10434681177139282\n",
      "\n",
      "batch: 1/1 in epoch 840/1000 \n",
      "... loss: 0.10258002579212189\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 841/1000 \n",
      "... loss: 0.10085035860538483\n",
      "\n",
      "batch: 1/1 in epoch 842/1000 \n",
      "... loss: 0.09915752708911896\n",
      "\n",
      "batch: 1/1 in epoch 843/1000 \n",
      "... loss: 0.0975007638335228\n",
      "\n",
      "batch: 1/1 in epoch 844/1000 \n",
      "... loss: 0.09587915241718292\n",
      "\n",
      "batch: 1/1 in epoch 845/1000 \n",
      "... loss: 0.09429207444190979\n",
      "\n",
      "batch: 1/1 in epoch 846/1000 \n",
      "... loss: 0.0927388072013855\n",
      "\n",
      "batch: 1/1 in epoch 847/1000 \n",
      "... loss: 0.09121870994567871\n",
      "\n",
      "batch: 1/1 in epoch 848/1000 \n",
      "... loss: 0.0897311121225357\n",
      "\n",
      "batch: 1/1 in epoch 849/1000 \n",
      "... loss: 0.08827508240938187\n",
      "\n",
      "batch: 1/1 in epoch 850/1000 \n",
      "... loss: 0.0868503749370575\n",
      "\n",
      "batch: 1/1 in epoch 851/1000 \n",
      "... loss: 0.08545581251382828\n",
      "\n",
      "batch: 1/1 in epoch 852/1000 \n",
      "... loss: 0.08409103006124496\n",
      "\n",
      "batch: 1/1 in epoch 853/1000 \n",
      "... loss: 0.08275526762008667\n",
      "\n",
      "batch: 1/1 in epoch 854/1000 \n",
      "... loss: 0.08144789934158325\n",
      "\n",
      "batch: 1/1 in epoch 855/1000 \n",
      "... loss: 0.08016834408044815\n",
      "\n",
      "batch: 1/1 in epoch 856/1000 \n",
      "... loss: 0.07891585677862167\n",
      "\n",
      "batch: 1/1 in epoch 857/1000 \n",
      "... loss: 0.07768997550010681\n",
      "\n",
      "batch: 1/1 in epoch 858/1000 \n",
      "... loss: 0.07649003714323044\n",
      "\n",
      "batch: 1/1 in epoch 859/1000 \n",
      "... loss: 0.07531541585922241\n",
      "\n",
      "batch: 1/1 in epoch 860/1000 \n",
      "... loss: 0.0741654708981514\n",
      "\n",
      "batch: 1/1 in epoch 861/1000 \n",
      "... loss: 0.07303979992866516\n",
      "\n",
      "batch: 1/1 in epoch 862/1000 \n",
      "... loss: 0.0719376653432846\n",
      "\n",
      "batch: 1/1 in epoch 863/1000 \n",
      "... loss: 0.07085862755775452\n",
      "\n",
      "batch: 1/1 in epoch 864/1000 \n",
      "... loss: 0.06980205327272415\n",
      "\n",
      "batch: 1/1 in epoch 865/1000 \n",
      "... loss: 0.06876762211322784\n",
      "\n",
      "batch: 1/1 in epoch 866/1000 \n",
      "... loss: 0.06775450706481934\n",
      "\n",
      "batch: 1/1 in epoch 867/1000 \n",
      "... loss: 0.06676249951124191\n",
      "\n",
      "batch: 1/1 in epoch 868/1000 \n",
      "... loss: 0.06579093635082245\n",
      "\n",
      "batch: 1/1 in epoch 869/1000 \n",
      "... loss: 0.06483921408653259\n",
      "\n",
      "batch: 1/1 in epoch 870/1000 \n",
      "... loss: 0.06390726566314697\n",
      "\n",
      "batch: 1/1 in epoch 871/1000 \n",
      "... loss: 0.06299415975809097\n",
      "\n",
      "batch: 1/1 in epoch 872/1000 \n",
      "... loss: 0.062099818140268326\n",
      "\n",
      "batch: 1/1 in epoch 873/1000 \n",
      "... loss: 0.06122357398271561\n",
      "\n",
      "batch: 1/1 in epoch 874/1000 \n",
      "... loss: 0.06036513298749924\n",
      "\n",
      "batch: 1/1 in epoch 875/1000 \n",
      "... loss: 0.05952392518520355\n",
      "\n",
      "batch: 1/1 in epoch 876/1000 \n",
      "... loss: 0.05869976803660393\n",
      "\n",
      "batch: 1/1 in epoch 877/1000 \n",
      "... loss: 0.05789192020893097\n",
      "\n",
      "batch: 1/1 in epoch 878/1000 \n",
      "... loss: 0.05710042268037796\n",
      "\n",
      "batch: 1/1 in epoch 879/1000 \n",
      "... loss: 0.05632447451353073\n",
      "\n",
      "batch: 1/1 in epoch 880/1000 \n",
      "... loss: 0.055563926696777344\n",
      "\n",
      "batch: 1/1 in epoch 881/1000 \n",
      "... loss: 0.05481843277812004\n",
      "\n",
      "batch: 1/1 in epoch 882/1000 \n",
      "... loss: 0.05408746004104614\n",
      "\n",
      "batch: 1/1 in epoch 883/1000 \n",
      "... loss: 0.05337092652916908\n",
      "\n",
      "batch: 1/1 in epoch 884/1000 \n",
      "... loss: 0.05266835540533066\n",
      "\n",
      "batch: 1/1 in epoch 885/1000 \n",
      "... loss: 0.05197921022772789\n",
      "\n",
      "batch: 1/1 in epoch 886/1000 \n",
      "... loss: 0.05130358040332794\n",
      "\n",
      "batch: 1/1 in epoch 887/1000 \n",
      "... loss: 0.050640858709812164\n",
      "\n",
      "batch: 1/1 in epoch 888/1000 \n",
      "... loss: 0.04999091476202011\n",
      "\n",
      "batch: 1/1 in epoch 889/1000 \n",
      "... loss: 0.049353308975696564\n",
      "\n",
      "batch: 1/1 in epoch 890/1000 \n",
      "... loss: 0.04872778803110123\n",
      "\n",
      "batch: 1/1 in epoch 891/1000 \n",
      "... loss: 0.048114143311977386\n",
      "\n",
      "batch: 1/1 in epoch 892/1000 \n",
      "... loss: 0.04751205816864967\n",
      "\n",
      "batch: 1/1 in epoch 893/1000 \n",
      "... loss: 0.04692121595144272\n",
      "\n",
      "batch: 1/1 in epoch 894/1000 \n",
      "... loss: 0.04634145647287369\n",
      "\n",
      "batch: 1/1 in epoch 895/1000 \n",
      "... loss: 0.045772355049848557\n",
      "\n",
      "batch: 1/1 in epoch 896/1000 \n",
      "... loss: 0.04521386697888374\n",
      "\n",
      "batch: 1/1 in epoch 897/1000 \n",
      "... loss: 0.044665612280368805\n",
      "\n",
      "batch: 1/1 in epoch 898/1000 \n",
      "... loss: 0.044127434492111206\n",
      "\n",
      "batch: 1/1 in epoch 899/1000 \n",
      "... loss: 0.04359900951385498\n",
      "\n",
      "batch: 1/1 in epoch 900/1000 \n",
      "... loss: 0.04308024048805237\n",
      "\n",
      "batch: 1/1 in epoch 901/1000 \n",
      "... loss: 0.04257068410515785\n",
      "\n",
      "batch: 1/1 in epoch 902/1000 \n",
      "... loss: 0.042070526629686356\n",
      "\n",
      "batch: 1/1 in epoch 903/1000 \n",
      "... loss: 0.04157920926809311\n",
      "\n",
      "batch: 1/1 in epoch 904/1000 \n",
      "... loss: 0.04109669104218483\n",
      "\n",
      "batch: 1/1 in epoch 905/1000 \n",
      "... loss: 0.040622636675834656\n",
      "\n",
      "batch: 1/1 in epoch 906/1000 \n",
      "... loss: 0.04015694558620453\n",
      "\n",
      "batch: 1/1 in epoch 907/1000 \n",
      "... loss: 0.03969951719045639\n",
      "\n",
      "batch: 1/1 in epoch 908/1000 \n",
      "... loss: 0.03925013542175293\n",
      "\n",
      "batch: 1/1 in epoch 909/1000 \n",
      "... loss: 0.03880840167403221\n",
      "\n",
      "batch: 1/1 in epoch 910/1000 \n",
      "... loss: 0.03837444633245468\n",
      "\n",
      "batch: 1/1 in epoch 911/1000 \n",
      "... loss: 0.03794793784618378\n",
      "\n",
      "batch: 1/1 in epoch 912/1000 \n",
      "... loss: 0.03752870857715607\n",
      "\n",
      "batch: 1/1 in epoch 913/1000 \n",
      "... loss: 0.037116654217243195\n",
      "\n",
      "batch: 1/1 in epoch 914/1000 \n",
      "... loss: 0.03671155869960785\n",
      "\n",
      "batch: 1/1 in epoch 915/1000 \n",
      "... loss: 0.036313362419605255\n",
      "\n",
      "batch: 1/1 in epoch 916/1000 \n",
      "... loss: 0.0359218530356884\n",
      "\n",
      "batch: 1/1 in epoch 917/1000 \n",
      "... loss: 0.03553692251443863\n",
      "\n",
      "batch: 1/1 in epoch 918/1000 \n",
      "... loss: 0.03515828773379326\n",
      "\n",
      "batch: 1/1 in epoch 919/1000 \n",
      "... loss: 0.034786075353622437\n",
      "\n",
      "batch: 1/1 in epoch 920/1000 \n",
      "... loss: 0.034419938921928406\n",
      "\n",
      "batch: 1/1 in epoch 921/1000 \n",
      "... loss: 0.034059830009937286\n",
      "\n",
      "batch: 1/1 in epoch 922/1000 \n",
      "... loss: 0.03370553255081177\n",
      "\n",
      "batch: 1/1 in epoch 923/1000 \n",
      "... loss: 0.03335704654455185\n",
      "\n",
      "batch: 1/1 in epoch 924/1000 \n",
      "... loss: 0.03301431983709335\n",
      "\n",
      "batch: 1/1 in epoch 925/1000 \n",
      "... loss: 0.032676901668310165\n",
      "\n",
      "batch: 1/1 in epoch 926/1000 \n",
      "... loss: 0.03234507888555527\n",
      "\n",
      "batch: 1/1 in epoch 927/1000 \n",
      "... loss: 0.03201834484934807\n",
      "\n",
      "batch: 1/1 in epoch 928/1000 \n",
      "... loss: 0.03169693052768707\n",
      "\n",
      "batch: 1/1 in epoch 929/1000 \n",
      "... loss: 0.031380608677864075\n",
      "\n",
      "batch: 1/1 in epoch 930/1000 \n",
      "... loss: 0.031069159507751465\n",
      "\n",
      "batch: 1/1 in epoch 931/1000 \n",
      "... loss: 0.03076264075934887\n",
      "\n",
      "batch: 1/1 in epoch 932/1000 \n",
      "... loss: 0.030460942536592484\n",
      "\n",
      "batch: 1/1 in epoch 933/1000 \n",
      "... loss: 0.03016383945941925\n",
      "\n",
      "batch: 1/1 in epoch 934/1000 \n",
      "... loss: 0.02987132966518402\n",
      "\n",
      "batch: 1/1 in epoch 935/1000 \n",
      "... loss: 0.029583308845758438\n",
      "\n",
      "batch: 1/1 in epoch 936/1000 \n",
      "... loss: 0.029299836605787277\n",
      "\n",
      "batch: 1/1 in epoch 937/1000 \n",
      "... loss: 0.029020626097917557\n",
      "\n",
      "batch: 1/1 in epoch 938/1000 \n",
      "... loss: 0.028745505958795547\n",
      "\n",
      "batch: 1/1 in epoch 939/1000 \n",
      "... loss: 0.028474539518356323\n",
      "\n",
      "batch: 1/1 in epoch 940/1000 \n",
      "... loss: 0.028207670897245407\n",
      "\n",
      "batch: 1/1 in epoch 941/1000 \n",
      "... loss: 0.027944790199398994\n",
      "\n",
      "batch: 1/1 in epoch 942/1000 \n",
      "... loss: 0.027685899287462234\n",
      "\n",
      "batch: 1/1 in epoch 943/1000 \n",
      "... loss: 0.027430709451436996\n",
      "\n",
      "batch: 1/1 in epoch 944/1000 \n",
      "... loss: 0.02717922441661358\n",
      "\n",
      "batch: 1/1 in epoch 945/1000 \n",
      "... loss: 0.02693162113428116\n",
      "\n",
      "batch: 1/1 in epoch 946/1000 \n",
      "... loss: 0.02668749913573265\n",
      "\n",
      "batch: 1/1 in epoch 947/1000 \n",
      "... loss: 0.026446914300322533\n",
      "\n",
      "batch: 1/1 in epoch 948/1000 \n",
      "... loss: 0.026209872215986252\n",
      "\n",
      "batch: 1/1 in epoch 949/1000 \n",
      "... loss: 0.025976084172725677\n",
      "\n",
      "batch: 1/1 in epoch 950/1000 \n",
      "... loss: 0.02574584260582924\n",
      "\n",
      "batch: 1/1 in epoch 951/1000 \n",
      "... loss: 0.025518687441945076\n",
      "\n",
      "batch: 1/1 in epoch 952/1000 \n",
      "... loss: 0.02529490739107132\n",
      "\n",
      "batch: 1/1 in epoch 953/1000 \n",
      "... loss: 0.02507415972650051\n",
      "\n",
      "batch: 1/1 in epoch 954/1000 \n",
      "... loss: 0.024856504052877426\n",
      "\n",
      "batch: 1/1 in epoch 955/1000 \n",
      "... loss: 0.02464199624955654\n",
      "\n",
      "batch: 1/1 in epoch 956/1000 \n",
      "... loss: 0.02443040907382965\n",
      "\n",
      "batch: 1/1 in epoch 957/1000 \n",
      "... loss: 0.02422180399298668\n",
      "\n",
      "batch: 1/1 in epoch 958/1000 \n",
      "... loss: 0.024015948176383972\n",
      "\n",
      "batch: 1/1 in epoch 959/1000 \n",
      "... loss: 0.023813020437955856\n",
      "\n",
      "batch: 1/1 in epoch 960/1000 \n",
      "... loss: 0.023612841963768005\n",
      "\n",
      "batch: 1/1 in epoch 961/1000 \n",
      "... loss: 0.02341536059975624\n",
      "\n",
      "batch: 1/1 in epoch 962/1000 \n",
      "... loss: 0.02322058007121086\n",
      "\n",
      "batch: 1/1 in epoch 963/1000 \n",
      "... loss: 0.023028438910841942\n",
      "\n",
      "batch: 1/1 in epoch 964/1000 \n",
      "... loss: 0.02283882349729538\n",
      "\n",
      "batch: 1/1 in epoch 965/1000 \n",
      "... loss: 0.022651854902505875\n",
      "\n",
      "batch: 1/1 in epoch 966/1000 \n",
      "... loss: 0.02246723882853985\n",
      "\n",
      "batch: 1/1 in epoch 967/1000 \n",
      "... loss: 0.022285096347332\n",
      "\n",
      "batch: 1/1 in epoch 968/1000 \n",
      "... loss: 0.02210531011223793\n",
      "\n",
      "batch: 1/1 in epoch 969/1000 \n",
      "... loss: 0.02192794159054756\n",
      "\n",
      "batch: 1/1 in epoch 970/1000 \n",
      "... loss: 0.021752875298261642\n",
      "\n",
      "batch: 1/1 in epoch 971/1000 \n",
      "... loss: 0.021580051630735397\n",
      "\n",
      "batch: 1/1 in epoch 972/1000 \n",
      "... loss: 0.021409474313259125\n",
      "\n",
      "batch: 1/1 in epoch 973/1000 \n",
      "... loss: 0.02124108374118805\n",
      "\n",
      "batch: 1/1 in epoch 974/1000 \n",
      "... loss: 0.02107488363981247\n",
      "\n",
      "batch: 1/1 in epoch 975/1000 \n",
      "... loss: 0.02091081440448761\n",
      "\n",
      "batch: 1/1 in epoch 976/1000 \n",
      "... loss: 0.020748822018504143\n",
      "\n",
      "batch: 1/1 in epoch 977/1000 \n",
      "... loss: 0.020588846877217293\n",
      "\n",
      "batch: 1/1 in epoch 978/1000 \n",
      "... loss: 0.02043088898062706\n",
      "\n",
      "batch: 1/1 in epoch 979/1000 \n",
      "... loss: 0.02027500979602337\n",
      "\n",
      "batch: 1/1 in epoch 980/1000 \n",
      "... loss: 0.02012091502547264\n",
      "\n",
      "batch: 1/1 in epoch 981/1000 \n",
      "... loss: 0.019968844950199127\n",
      "\n",
      "batch: 1/1 in epoch 982/1000 \n",
      "... loss: 0.019818618893623352\n",
      "\n",
      "batch: 1/1 in epoch 983/1000 \n",
      "... loss: 0.01967030018568039\n",
      "\n",
      "batch: 1/1 in epoch 984/1000 \n",
      "... loss: 0.019523771479725838\n",
      "\n",
      "batch: 1/1 in epoch 985/1000 \n",
      "... loss: 0.01937897503376007\n",
      "\n",
      "batch: 1/1 in epoch 986/1000 \n",
      "... loss: 0.019235970452427864\n",
      "\n",
      "batch: 1/1 in epoch 987/1000 \n",
      "... loss: 0.019094757735729218\n",
      "\n",
      "batch: 1/1 in epoch 988/1000 \n",
      "... loss: 0.01895521953701973\n",
      "\n",
      "batch: 1/1 in epoch 989/1000 \n",
      "... loss: 0.018817301839590073\n",
      "\n",
      "batch: 1/1 in epoch 990/1000 \n",
      "... loss: 0.0186811201274395\n",
      "\n",
      "batch: 1/1 in epoch 991/1000 \n",
      "... loss: 0.018546439707279205\n",
      "\n",
      "batch: 1/1 in epoch 992/1000 \n",
      "... loss: 0.018413381651043892\n",
      "\n",
      "batch: 1/1 in epoch 993/1000 \n",
      "... loss: 0.018282059580087662\n",
      "\n",
      "batch: 1/1 in epoch 994/1000 \n",
      "... loss: 0.01815206930041313\n",
      "\n",
      "batch: 1/1 in epoch 995/1000 \n",
      "... loss: 0.018023815006017685\n",
      "\n",
      "batch: 1/1 in epoch 996/1000 \n",
      "... loss: 0.01789689250290394\n",
      "\n",
      "batch: 1/1 in epoch 997/1000 \n",
      "... loss: 0.017771534621715546\n",
      "\n",
      "batch: 1/1 in epoch 998/1000 \n",
      "... loss: 0.017647508531808853\n",
      "\n",
      "batch: 1/1 in epoch 999/1000 \n",
      "... loss: 0.01752498745918274\n",
      "\n",
      "batch: 1/1 in epoch 1000/1000 \n",
      "... loss: 0.01740385964512825\n",
      "\n",
      "\n",
      "[[0, 1.410484790802002], [1, 1.03560209274292], [2, 0.8322607278823853], [3, 0.7617442607879639], [4, 0.7353168725967407], [5, 0.7236469984054565], [6, 0.7176548838615417], [7, 0.7140815258026123], [8, 0.7117377519607544], [9, 0.7100479602813721], [10, 0.7087364792823792], [11, 0.7076705694198608], [12, 0.7067698240280151], [13, 0.7059892416000366], [14, 0.7053015232086182], [15, 0.7046875953674316], [16, 0.7041341662406921], [17, 0.703632116317749], [18, 0.7031737565994263], [19, 0.7027531862258911], [20, 0.7023659944534302], [21, 0.7020078897476196], [22, 0.7016754746437073], [23, 0.7013661861419678], [24, 0.7010774612426758], [25, 0.7008074522018433], [26, 0.7005541324615479], [27, 0.7003159523010254], [28, 0.7000917196273804], [29, 0.6998800039291382], [30, 0.6996797323226929], [31, 0.6994901895523071], [32, 0.6993104219436646], [33, 0.6991391777992249], [34, 0.6989766359329224], [35, 0.6988216042518616], [36, 0.6986737251281738], [37, 0.6985323429107666], [38, 0.698397159576416], [39, 0.6982676982879639], [40, 0.6981435418128967], [41, 0.6980244517326355], [42, 0.6979100108146667], [43, 0.6978000402450562], [44, 0.6976940631866455], [45, 0.6975919604301453], [46, 0.6974937915802002], [47, 0.6973987817764282], [48, 0.6973072290420532], [49, 0.6972185373306274], [50, 0.6971327066421509], [51, 0.6970498561859131], [52, 0.6969695687294006], [53, 0.6968917846679688], [54, 0.6968163251876831], [55, 0.6967430114746094], [56, 0.6966718435287476], [57, 0.6966027021408081], [58, 0.696535587310791], [59, 0.6964703798294067], [60, 0.6964067220687866], [61, 0.6963446736335754], [62, 0.6962844729423523], [63, 0.6962257027626038], [64, 0.6961683630943298], [65, 0.6961123943328857], [66, 0.6960578560829163], [67, 0.6960045099258423], [68, 0.6959525346755981], [69, 0.6959017515182495], [70, 0.6958518028259277], [71, 0.695803165435791], [72, 0.6957554817199707], [73, 0.6957089900970459], [74, 0.6956632137298584], [75, 0.6956186294555664], [76, 0.6955748796463013], [77, 0.695531964302063], [78, 0.6954897046089172], [79, 0.6954485177993774], [80, 0.6954078674316406], [81, 0.6953680515289307], [82, 0.695328950881958], [83, 0.6952906847000122], [84, 0.6952527761459351], [85, 0.6952157616615295], [86, 0.6951793432235718], [87, 0.695143461227417], [88, 0.6951082944869995], [89, 0.6950736045837402], [90, 0.6950393915176392], [91, 0.6950058341026306], [92, 0.694972813129425], [93, 0.6949401497840881], [94, 0.6949079632759094], [95, 0.6948763132095337], [96, 0.6948451995849609], [97, 0.6948143243789673], [98, 0.6947838664054871], [99, 0.694753885269165], [100, 0.694724440574646], [101, 0.6946953535079956], [102, 0.6946665048599243], [103, 0.6946380734443665], [104, 0.6946101188659668], [105, 0.6945821046829224], [106, 0.6945549249649048], [107, 0.6945277452468872], [108, 0.6945011615753174], [109, 0.6944746971130371], [110, 0.6944483518600464], [111, 0.6944226026535034], [112, 0.6943968534469604], [113, 0.6943714618682861], [114, 0.6943464279174805], [115, 0.6943216323852539], [116, 0.6942970752716064], [117, 0.6942728757858276], [118, 0.694248616695404], [119, 0.6942247152328491], [120, 0.6942011117935181], [121, 0.6941777467727661], [122, 0.6941544413566589], [123, 0.6941314935684204], [124, 0.6941087245941162], [125, 0.6940860748291016], [126, 0.6940636038780212], [127, 0.6940412521362305], [128, 0.6940193176269531], [129, 0.693997323513031], [130, 0.6939756870269775], [131, 0.6939539909362793], [132, 0.6939326524734497], [133, 0.6939113736152649], [134, 0.6938902139663696], [135, 0.6938692331314087], [136, 0.6938484907150269], [137, 0.6938276886940002], [138, 0.6938072443008423], [139, 0.6937869787216187], [140, 0.6937664747238159], [141, 0.6937463283538818], [142, 0.6937262415885925], [143, 0.693706214427948], [144, 0.6936863660812378], [145, 0.6936668157577515], [146, 0.6936470866203308], [147, 0.6936275959014893], [148, 0.6936083436012268], [149, 0.6935889720916748], [150, 0.6935696601867676], [151, 0.6935505867004395], [152, 0.6935315132141113], [153, 0.6935124397277832], [154, 0.693493664264679], [155, 0.6934749484062195], [156, 0.6934561133384705], [157, 0.6934375762939453], [158, 0.6934190988540649], [159, 0.693400502204895], [160, 0.6933820247650146], [161, 0.6933636665344238], [162, 0.6933454275131226], [163, 0.6933271884918213], [164, 0.69330894947052], [165, 0.6932908296585083], [166, 0.6932728290557861], [167, 0.6932549476623535], [168, 0.6932368874549866], [169, 0.6932189464569092], [170, 0.6932010650634766], [171, 0.6931833028793335], [172, 0.6931654214859009], [173, 0.6931477785110474], [174, 0.6931299567222595], [175, 0.6931123733520508], [176, 0.6930948495864868], [177, 0.6930772066116333], [178, 0.6930596828460693], [179, 0.6930419206619263], [180, 0.6930246353149414], [181, 0.6930071711540222], [182, 0.6929897665977478], [183, 0.6929723024368286], [184, 0.6929547786712646], [185, 0.6929373741149902], [186, 0.6929201483726501], [187, 0.6929028034210205], [188, 0.6928853392601013], [189, 0.6928681135177612], [190, 0.6928508281707764], [191, 0.692833662033081], [192, 0.6928162574768066], [193, 0.6927989721298218], [194, 0.692781925201416], [195, 0.6927645206451416], [196, 0.6927474141120911], [197, 0.6927300691604614], [198, 0.6927129030227661], [199, 0.6926956176757812], [200, 0.6926782131195068], [201, 0.6926609873771667], [202, 0.6926437616348267], [203, 0.6926265954971313], [204, 0.6926091909408569], [205, 0.6925921440124512], [206, 0.6925747990608215], [207, 0.6925573945045471], [208, 0.6925402283668518], [209, 0.6925228834152222], [210, 0.6925054788589478], [211, 0.6924881935119629], [212, 0.6924707889556885], [213, 0.6924534440040588], [214, 0.692436158657074], [215, 0.6924186944961548], [216, 0.6924012899398804], [217, 0.692383885383606], [218, 0.692366361618042], [219, 0.6923487782478333], [220, 0.6923313140869141], [221, 0.6923136711120605], [222, 0.6922961473464966], [223, 0.6922785639762878], [224, 0.6922610998153687], [225, 0.6922433376312256], [226, 0.6922255754470825], [227, 0.692207932472229], [228, 0.6921900510787964], [229, 0.6921723484992981], [230, 0.6921545267105103], [231, 0.6921365261077881], [232, 0.692118763923645], [233, 0.6921006441116333], [234, 0.6920828819274902], [235, 0.692064642906189], [236, 0.6920466423034668], [237, 0.6920284032821655], [238, 0.6920104026794434], [239, 0.6919921040534973], [240, 0.6919739842414856], [241, 0.6919554471969604], [242, 0.6919372081756592], [243, 0.6919187903404236], [244, 0.6919001936912537], [245, 0.6918818354606628], [246, 0.6918632984161377], [247, 0.6918445825576782], [248, 0.691825807094574], [249, 0.6918070316314697], [250, 0.6917882561683655], [251, 0.691769540309906], [252, 0.6917506456375122], [253, 0.6917315721511841], [254, 0.691712498664856], [255, 0.6916934251785278], [256, 0.6916742324829102], [257, 0.6916549801826477], [258, 0.6916356086730957], [259, 0.6916163563728333], [260, 0.6915969252586365], [261, 0.6915773749351501], [262, 0.6915578246116638], [263, 0.6915380954742432], [264, 0.6915183663368225], [265, 0.6914985775947571], [266, 0.6914786100387573], [267, 0.6914587020874023], [268, 0.6914385557174683], [269, 0.6914185285568237], [270, 0.6913983821868896], [271, 0.691378116607666], [272, 0.6913575530052185], [273, 0.6913372278213501], [274, 0.6913167238235474], [275, 0.6912961006164551], [276, 0.6912752985954285], [277, 0.6912546157836914], [278, 0.6912335157394409], [279, 0.6912126541137695], [280, 0.691191554069519], [281, 0.6911704540252686], [282, 0.691149115562439], [283, 0.6911277174949646], [284, 0.6911063194274902], [285, 0.691084623336792], [286, 0.6910630464553833], [287, 0.6910412311553955], [288, 0.6910192966461182], [289, 0.6909974217414856], [290, 0.6909753084182739], [291, 0.6909530162811279], [292, 0.6909307837486267], [293, 0.6909084320068359], [294, 0.6908859610557556], [295, 0.6908633708953857], [296, 0.6908406019210815], [297, 0.6908175945281982], [298, 0.690794825553894], [299, 0.6907715797424316], [300, 0.6907483339309692], [301, 0.6907252073287964], [302, 0.6907016038894653], [303, 0.6906780004501343], [304, 0.6906542778015137], [305, 0.6906304359436035], [306, 0.6906067132949829], [307, 0.6905825734138489], [308, 0.6905583143234253], [309, 0.6905339956283569], [310, 0.6905093193054199], [311, 0.6904848217964172], [312, 0.6904600858688354], [313, 0.6904351115226746], [314, 0.6904101371765137], [315, 0.690385103225708], [316, 0.6903597116470337], [317, 0.6903342008590698], [318, 0.6903086304664612], [319, 0.6902828216552734], [320, 0.6902570128440857], [321, 0.6902308464050293], [322, 0.6902046799659729], [323, 0.690178394317627], [324, 0.6901518106460571], [325, 0.6901252269744873], [326, 0.6900984048843384], [327, 0.6900713443756104], [328, 0.6900444626808167], [329, 0.6900169253349304], [330, 0.6899895668029785], [331, 0.6899617910385132], [332, 0.6899341344833374], [333, 0.6899058818817139], [334, 0.6898778676986694], [335, 0.6898496150970459], [336, 0.6898208856582642], [337, 0.6897923946380615], [338, 0.689763605594635], [339, 0.6897343993186951], [340, 0.6897053122520447], [341, 0.6896758079528809], [342, 0.6896462440490723], [343, 0.6896162033081055], [344, 0.6895862817764282], [345, 0.6895562410354614], [346, 0.6895257234573364], [347, 0.6894952058792114], [348, 0.6894644498825073], [349, 0.6894333362579346], [350, 0.6894022226333618], [351, 0.68937087059021], [352, 0.6893391609191895], [353, 0.689307451248169], [354, 0.6892753839492798], [355, 0.689242959022522], [356, 0.6892105937004089], [357, 0.6891778707504272], [358, 0.6891449689865112], [359, 0.6891119480133057], [360, 0.6890785694122314], [361, 0.6890448927879333], [362, 0.6890111565589905], [363, 0.6889770030975342], [364, 0.6889427304267883], [365, 0.6889081597328186], [366, 0.6888733506202698], [367, 0.6888382434844971], [368, 0.6888031959533691], [369, 0.6887674331665039], [370, 0.6887317299842834], [371, 0.6886956691741943], [372, 0.6886594295501709], [373, 0.6886228322982788], [374, 0.6885861754417419], [375, 0.6885488629341125], [376, 0.6885115504264832], [377, 0.6884739995002747], [378, 0.6884362697601318], [379, 0.6883978843688965], [380, 0.6883594989776611], [381, 0.6883204579353333], [382, 0.6882815957069397], [383, 0.6882421970367432], [384, 0.6882027387619019], [385, 0.6881625652313232], [386, 0.6881224513053894], [387, 0.6880819797515869], [388, 0.6880409717559814], [389, 0.687999963760376], [390, 0.6879583597183228], [391, 0.6879165172576904], [392, 0.6878747344017029], [393, 0.6878322958946228], [394, 0.6877893805503845], [395, 0.6877462863922119], [396, 0.687703013420105], [397, 0.6876592040061951], [398, 0.6876150369644165], [399, 0.6875705718994141], [400, 0.6875259876251221], [401, 0.6874806880950928], [402, 0.6874352097511292], [403, 0.6873893141746521], [404, 0.6873432397842407], [405, 0.6872965693473816], [406, 0.6872495412826538], [407, 0.6872022151947021], [408, 0.6871546506881714], [409, 0.6871062517166138], [410, 0.6870578527450562], [411, 0.6870089173316956], [412, 0.6869596242904663], [413, 0.6869099140167236], [414, 0.686859667301178], [415, 0.6868091821670532], [416, 0.686758279800415], [417, 0.6867068409919739], [418, 0.6866551041603088], [419, 0.6866028308868408], [420, 0.6865502595901489], [421, 0.6864970922470093], [422, 0.6864435076713562], [423, 0.6863895654678345], [424, 0.6863349676132202], [425, 0.6862800717353821], [426, 0.6862246990203857], [427, 0.686168909072876], [428, 0.6861124038696289], [429, 0.686055600643158], [430, 0.6859982013702393], [431, 0.6859406232833862], [432, 0.6858822107315063], [433, 0.6858234405517578], [434, 0.6857640743255615], [435, 0.6857041716575623], [436, 0.6856437921524048], [437, 0.6855829954147339], [438, 0.6855214834213257], [439, 0.6854592561721802], [440, 0.6853969097137451], [441, 0.685333788394928], [442, 0.6852701902389526], [443, 0.6852059960365295], [444, 0.6851411461830139], [445, 0.6850758790969849], [446, 0.6850097179412842], [447, 0.6849431991577148], [448, 0.6848761439323425], [449, 0.6848081946372986], [450, 0.6847398281097412], [451, 0.6846706867218018], [452, 0.6846011877059937], [453, 0.6845308542251587], [454, 0.684459924697876], [455, 0.6843882203102112], [456, 0.6843159794807434], [457, 0.6842430830001831], [458, 0.6841692924499512], [459, 0.6840948462486267], [460, 0.6840200424194336], [461, 0.6839443445205688], [462, 0.6838676929473877], [463, 0.6837905645370483], [464, 0.6837127208709717], [465, 0.6836341023445129], [466, 0.6835546493530273], [467, 0.6834746599197388], [468, 0.6833937168121338], [469, 0.6833118200302124], [470, 0.6832294464111328], [471, 0.6831459999084473], [472, 0.683061957359314], [473, 0.6829769611358643], [474, 0.6828913688659668], [475, 0.6828047037124634], [476, 0.6827171444892883], [477, 0.6826289892196655], [478, 0.6825398206710815], [479, 0.6824498772621155], [480, 0.6823588609695435], [481, 0.6822668313980103], [482, 0.6821742057800293], [483, 0.6820803880691528], [484, 0.6819857954978943], [485, 0.6818901896476746], [486, 0.6817936897277832], [487, 0.6816960573196411], [488, 0.6815975308418274], [489, 0.6814979314804077], [490, 0.6813972592353821], [491, 0.6812956929206848], [492, 0.6811932325363159], [493, 0.681089460849762], [494, 0.6809844970703125], [495, 0.6808786392211914], [496, 0.6807717084884644], [497, 0.680663526058197], [498, 0.6805543899536133], [499, 0.6804440021514893], [500, 0.6803326606750488], [501, 0.6802197694778442], [502, 0.6801059246063232], [503, 0.6799910068511963], [504, 0.6798745393753052], [505, 0.6797569394111633], [506, 0.679638147354126], [507, 0.6795179843902588], [508, 0.6793967485427856], [509, 0.6792738437652588], [510, 0.679149866104126], [511, 0.6790244579315186], [512, 0.6788976192474365], [513, 0.6787695288658142], [514, 0.6786400079727173], [515, 0.6785091161727905], [516, 0.6783764958381653], [517, 0.6782426834106445], [518, 0.6781074404716492], [519, 0.6779706478118896], [520, 0.6778320670127869], [521, 0.6776924133300781], [522, 0.6775504350662231], [523, 0.6774075031280518], [524, 0.6772630214691162], [525, 0.6771166324615479], [526, 0.6769685745239258], [527, 0.67681884765625], [528, 0.6766674518585205], [529, 0.6765143275260925], [530, 0.6763595342636108], [531, 0.6762027740478516], [532, 0.6760441064834595], [533, 0.6758838295936584], [534, 0.6757216453552246], [535, 0.6755577325820923], [536, 0.675391435623169], [537, 0.6752234697341919], [538, 0.6750534772872925], [539, 0.674881637096405], [540, 0.6747076511383057], [541, 0.6745316386222839], [542, 0.6743534803390503], [543, 0.6741733551025391], [544, 0.6739909648895264], [545, 0.6738060712814331], [546, 0.6736193895339966], [547, 0.6734300255775452], [548, 0.6732383966445923], [549, 0.6730450987815857], [550, 0.6728488206863403], [551, 0.6726502776145935], [552, 0.6724493503570557], [553, 0.672245979309082], [554, 0.6720401048660278], [555, 0.671831488609314], [556, 0.6716203689575195], [557, 0.671406626701355], [558, 0.6711902618408203], [559, 0.6709710359573364], [560, 0.6707491874694824], [561, 0.6705245971679688], [562, 0.6702969074249268], [563, 0.6700664162635803], [564, 0.6698331832885742], [565, 0.6695966720581055], [566, 0.6693572998046875], [567, 0.6691147089004517], [568, 0.668869137763977], [569, 0.6686203479766846], [570, 0.6683681011199951], [571, 0.6681127548217773], [572, 0.6678538918495178], [573, 0.66759192943573], [574, 0.6673263311386108], [575, 0.6670573949813843], [576, 0.6667845249176025], [577, 0.6665081977844238], [578, 0.6662283539772034], [579, 0.6659445762634277], [580, 0.6656569838523865], [581, 0.6653655171394348], [582, 0.6650701761245728], [583, 0.6647707223892212], [584, 0.6644673347473145], [585, 0.6641594767570496], [586, 0.6638475060462952], [587, 0.6635313034057617], [588, 0.6632107496261597], [589, 0.6628857851028442], [590, 0.6625562906265259], [591, 0.6622223854064941], [592, 0.6618834733963013], [593, 0.6615397930145264], [594, 0.6611914038658142], [595, 0.6608381271362305], [596, 0.6604797840118408], [597, 0.6601161956787109], [598, 0.6597476005554199], [599, 0.6593737602233887], [600, 0.6589943170547485], [601, 0.6586093902587891], [602, 0.6582192182540894], [603, 0.6578231453895569], [604, 0.6574212312698364], [605, 0.6570136547088623], [606, 0.6565998792648315], [607, 0.6561801433563232], [608, 0.6557542085647583], [609, 0.6553219556808472], [610, 0.654883086681366], [611, 0.6544381380081177], [612, 0.653985857963562], [613, 0.6535270810127258], [614, 0.6530616879463196], [615, 0.6525888442993164], [616, 0.6521089673042297], [617, 0.6516218185424805], [618, 0.6511274576187134], [619, 0.6506251096725464], [620, 0.6501152515411377], [621, 0.6495975852012634], [622, 0.6490716934204102], [623, 0.6485379338264465], [624, 0.6479957103729248], [625, 0.647445023059845], [626, 0.6468857526779175], [627, 0.646317720413208], [628, 0.6457407474517822], [629, 0.6451544761657715], [630, 0.6445590853691101], [631, 0.6439543962478638], [632, 0.6433397531509399], [633, 0.6427154541015625], [634, 0.6420810222625732], [635, 0.6414365768432617], [636, 0.6407814621925354], [637, 0.6401158571243286], [638, 0.6394397020339966], [639, 0.6387522220611572], [640, 0.6380535364151001], [641, 0.6373434066772461], [642, 0.6366217732429504], [643, 0.6358882188796997], [644, 0.6351425647735596], [645, 0.6343845725059509], [646, 0.6336138248443604], [647, 0.6328306198120117], [648, 0.6320340633392334], [649, 0.6312243342399597], [650, 0.6304008960723877], [651, 0.6295638084411621], [652, 0.6287124752998352], [653, 0.6278465986251831], [654, 0.6269664764404297], [655, 0.626071035861969], [656, 0.6251604557037354], [657, 0.6242344975471497], [658, 0.6232924461364746], [659, 0.622334361076355], [660, 0.6213597059249878], [661, 0.6203685998916626], [662, 0.619360089302063], [663, 0.6183342337608337], [664, 0.6172906160354614], [665, 0.6162288188934326], [666, 0.6151486039161682], [667, 0.6140493750572205], [668, 0.6129311323165894], [669, 0.6117936372756958], [670, 0.6106357574462891], [671, 0.6094576120376587], [672, 0.6082589626312256], [673, 0.6070394515991211], [674, 0.6057977676391602], [675, 0.6045346260070801], [676, 0.603249192237854], [677, 0.6019406318664551], [678, 0.6006091237068176], [679, 0.5992540121078491], [680, 0.5978747606277466], [681, 0.5964714288711548], [682, 0.5950427651405334], [683, 0.5935887098312378], [684, 0.5921087265014648], [685, 0.5906026363372803], [686, 0.5890696048736572], [687, 0.5875096321105957], [688, 0.5859214067459106], [689, 0.5843051671981812], [690, 0.5826601982116699], [691, 0.5809859037399292], [692, 0.579282283782959], [693, 0.577548086643219], [694, 0.5757832527160645], [695, 0.5739873647689819], [696, 0.5721595287322998], [697, 0.5702998638153076], [698, 0.568407416343689], [699, 0.5664815902709961], [700, 0.5645219087600708], [701, 0.562528133392334], [702, 0.5604994297027588], [703, 0.5584357976913452], [704, 0.5563363432884216], [705, 0.5542006492614746], [706, 0.5520284175872803], [707, 0.5498190522193909], [708, 0.5475719571113586], [709, 0.5452869534492493], [710, 0.5429630279541016], [711, 0.5406003594398499], [712, 0.5381982326507568], [713, 0.5357562303543091], [714, 0.5332740545272827], [715, 0.53075110912323], [716, 0.5281871557235718], [717, 0.5255816578865051], [718, 0.52293461561203], [719, 0.520245373249054], [720, 0.517513632774353], [721, 0.5147390961647034], [722, 0.511921763420105], [723, 0.5090609788894653], [724, 0.506156861782074], [725, 0.5032088756561279], [726, 0.5002169609069824], [727, 0.4971811771392822], [728, 0.49410098791122437], [729, 0.49097681045532227], [730, 0.48780810832977295], [731, 0.4845949709415436], [732, 0.4813372790813446], [733, 0.4780352711677551], [734, 0.47468918561935425], [735, 0.47129857540130615], [736, 0.4678639769554138], [737, 0.464385449886322], [738, 0.46086350083351135], [739, 0.45729804039001465], [740, 0.45368969440460205], [741, 0.4500387907028198], [742, 0.4463455080986023], [743, 0.44261062145233154], [744, 0.4388348460197449], [745, 0.4350183606147766], [746, 0.4311622977256775], [747, 0.42726728320121765], [748, 0.4233343005180359], [749, 0.41936391592025757], [750, 0.41535747051239014], [751, 0.4113156795501709], [752, 0.407240092754364], [753, 0.403131365776062], [754, 0.3989911675453186], [755, 0.39482080936431885], [756, 0.3906213641166687], [757, 0.38639503717422485], [758, 0.3821426331996918], [759, 0.37786585092544556], [760, 0.3735666573047638], [761, 0.36924660205841064], [762, 0.3649073839187622], [763, 0.3605508804321289], [764, 0.3561789393424988], [765, 0.3517935276031494], [766, 0.3473966121673584], [767, 0.34299010038375854], [768, 0.3385760188102722], [769, 0.33415618538856506], [770, 0.3297330141067505], [771, 0.3253086805343628], [772, 0.3208850026130676], [773, 0.3164639472961426], [774, 0.31204771995544434], [775, 0.3076387047767639], [776, 0.30323874950408936], [777, 0.29885005950927734], [778, 0.29447442293167114], [779, 0.2901144027709961], [780, 0.2857717275619507], [781, 0.2814486026763916], [782, 0.2771467864513397], [783, 0.27286824584007263], [784, 0.26861506700515747], [785, 0.2643890976905823], [786, 0.26019197702407837], [787, 0.2560257613658905], [788, 0.2518919110298157], [789, 0.24779224395751953], [790, 0.24372828006744385], [791, 0.23970144987106323], [792, 0.23571346700191498], [793, 0.23176559805870056], [794, 0.22785915434360504], [795, 0.2239951491355896], [796, 0.22017526626586914], [797, 0.21640023589134216], [798, 0.2126712054014206], [799, 0.20898908376693726], [800, 0.20535463094711304], [801, 0.20176881551742554], [802, 0.1982322633266449], [803, 0.1947455257177353], [804, 0.1913093477487564], [805, 0.18792401254177094], [806, 0.1845899522304535], [807, 0.18130755424499512], [808, 0.17807704210281372], [809, 0.17489871382713318], [810, 0.1717725545167923], [811, 0.1686985194683075], [812, 0.16567692160606384], [813, 0.16270752251148224], [814, 0.15979009866714478], [815, 0.15692463517189026], [816, 0.15411090850830078], [817, 0.15134844183921814], [818, 0.14863714575767517], [819, 0.14597654342651367], [820, 0.14336630702018738], [821, 0.1408059000968933], [822, 0.13829483091831207], [823, 0.13583269715309143], [824, 0.1334189772605896], [825, 0.1310529261827469], [826, 0.12873408198356628], [827, 0.1264616847038269], [828, 0.12423539906740189], [829, 0.12205415219068527], [830, 0.11991767585277557], [831, 0.11782510578632355], [832, 0.11577565968036652], [833, 0.11376875638961792], [834, 0.11180361360311508], [835, 0.10987967252731323], [836, 0.10799611359834671], [837, 0.10615208745002747], [838, 0.10434681177139282], [839, 0.10258002579212189], [840, 0.10085035860538483], [841, 0.09915752708911896], [842, 0.0975007638335228], [843, 0.09587915241718292], [844, 0.09429207444190979], [845, 0.0927388072013855], [846, 0.09121870994567871], [847, 0.0897311121225357], [848, 0.08827508240938187], [849, 0.0868503749370575], [850, 0.08545581251382828], [851, 0.08409103006124496], [852, 0.08275526762008667], [853, 0.08144789934158325], [854, 0.08016834408044815], [855, 0.07891585677862167], [856, 0.07768997550010681], [857, 0.07649003714323044], [858, 0.07531541585922241], [859, 0.0741654708981514], [860, 0.07303979992866516], [861, 0.0719376653432846], [862, 0.07085862755775452], [863, 0.06980205327272415], [864, 0.06876762211322784], [865, 0.06775450706481934], [866, 0.06676249951124191], [867, 0.06579093635082245], [868, 0.06483921408653259], [869, 0.06390726566314697], [870, 0.06299415975809097], [871, 0.062099818140268326], [872, 0.06122357398271561], [873, 0.06036513298749924], [874, 0.05952392518520355], [875, 0.05869976803660393], [876, 0.05789192020893097], [877, 0.05710042268037796], [878, 0.05632447451353073], [879, 0.055563926696777344], [880, 0.05481843277812004], [881, 0.05408746004104614], [882, 0.05337092652916908], [883, 0.05266835540533066], [884, 0.05197921022772789], [885, 0.05130358040332794], [886, 0.050640858709812164], [887, 0.04999091476202011], [888, 0.049353308975696564], [889, 0.04872778803110123], [890, 0.048114143311977386], [891, 0.04751205816864967], [892, 0.04692121595144272], [893, 0.04634145647287369], [894, 0.045772355049848557], [895, 0.04521386697888374], [896, 0.044665612280368805], [897, 0.044127434492111206], [898, 0.04359900951385498], [899, 0.04308024048805237], [900, 0.04257068410515785], [901, 0.042070526629686356], [902, 0.04157920926809311], [903, 0.04109669104218483], [904, 0.040622636675834656], [905, 0.04015694558620453], [906, 0.03969951719045639], [907, 0.03925013542175293], [908, 0.03880840167403221], [909, 0.03837444633245468], [910, 0.03794793784618378], [911, 0.03752870857715607], [912, 0.037116654217243195], [913, 0.03671155869960785], [914, 0.036313362419605255], [915, 0.0359218530356884], [916, 0.03553692251443863], [917, 0.03515828773379326], [918, 0.034786075353622437], [919, 0.034419938921928406], [920, 0.034059830009937286], [921, 0.03370553255081177], [922, 0.03335704654455185], [923, 0.03301431983709335], [924, 0.032676901668310165], [925, 0.03234507888555527], [926, 0.03201834484934807], [927, 0.03169693052768707], [928, 0.031380608677864075], [929, 0.031069159507751465], [930, 0.03076264075934887], [931, 0.030460942536592484], [932, 0.03016383945941925], [933, 0.02987132966518402], [934, 0.029583308845758438], [935, 0.029299836605787277], [936, 0.029020626097917557], [937, 0.028745505958795547], [938, 0.028474539518356323], [939, 0.028207670897245407], [940, 0.027944790199398994], [941, 0.027685899287462234], [942, 0.027430709451436996], [943, 0.02717922441661358], [944, 0.02693162113428116], [945, 0.02668749913573265], [946, 0.026446914300322533], [947, 0.026209872215986252], [948, 0.025976084172725677], [949, 0.02574584260582924], [950, 0.025518687441945076], [951, 0.02529490739107132], [952, 0.02507415972650051], [953, 0.024856504052877426], [954, 0.02464199624955654], [955, 0.02443040907382965], [956, 0.02422180399298668], [957, 0.024015948176383972], [958, 0.023813020437955856], [959, 0.023612841963768005], [960, 0.02341536059975624], [961, 0.02322058007121086], [962, 0.023028438910841942], [963, 0.02283882349729538], [964, 0.022651854902505875], [965, 0.02246723882853985], [966, 0.022285096347332], [967, 0.02210531011223793], [968, 0.02192794159054756], [969, 0.021752875298261642], [970, 0.021580051630735397], [971, 0.021409474313259125], [972, 0.02124108374118805], [973, 0.02107488363981247], [974, 0.02091081440448761], [975, 0.020748822018504143], [976, 0.020588846877217293], [977, 0.02043088898062706], [978, 0.02027500979602337], [979, 0.02012091502547264], [980, 0.019968844950199127], [981, 0.019818618893623352], [982, 0.01967030018568039], [983, 0.019523771479725838], [984, 0.01937897503376007], [985, 0.019235970452427864], [986, 0.019094757735729218], [987, 0.01895521953701973], [988, 0.018817301839590073], [989, 0.0186811201274395], [990, 0.018546439707279205], [991, 0.018413381651043892], [992, 0.018282059580087662], [993, 0.01815206930041313], [994, 0.018023815006017685], [995, 0.01789689250290394], [996, 0.017771534621715546], [997, 0.017647508531808853], [998, 0.01752498745918274], [999, 0.01740385964512825]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/2\n",
      "... correct: 1\n",
      "\n",
      "average test loss: 0.017284181900322437, relative correct: 1.0\n",
      "\n",
      "confusion:\n",
      "[[1, 1], [0, 0]]\n",
      "... done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# debug set\n",
    "net_full = Lin_Net(8, 4, 64, 64, act_function)\n",
    "train_loader_debug, test_loader_debug = make_data(emotion_dataset, \"full\", batch_size, True)\n",
    "train(train_loader_debug, net_full, 1000, criterion, 100, \"../logs/cross_debug\", cuda, 0.1)\n",
    "test(test_loader_debug, net_full, criterion, 100, \"../logs/cross_debug\", cuda)\n",
    "\n",
    "print(\"... done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------- net_lin_emotion_full\")\n",
    "net_full = Lin_Net(8, 4, 64, act_function)\n",
    "train_loader_emotion_full, test_loader_emotion_full = make_data(emotion_dataset, \"full\", batch_size)\n",
    "train(train_loader_emotion_full, net_full, 100, criterion, 5000, \"../logs/cross_\"+net_name, cuda, 0.1)\n",
    "test(test_loader_emotion_full, net_full, criterion, 1000, \"../logs/cross_emotion_full\")\n",
    "\n",
    "print(\"-------- net_lin_emotion_nolex\")\n",
    "net_half = Lin_Net(4, 4, 64, act_function)\n",
    "train_loader_emotion_nolex, test_loader_emotion_nolex = make_data(emotion_dataset, \"nolex\", batch_size)\n",
    "train(train_loader_emotion_nolex, net_half, 100, criterion, 5000, \"../logs/cross_\"+net_name, cuda, 0.1)\n",
    "test(test_loader_emotion_nolex, net_half, criterion, 1000, \"../logs/cross_emotion_nolex\")\n",
    "\n",
    "print(\"-------- net_lin_emotion_lex\")\n",
    "net_half = Lin_Net(4, 4, 64, act_function)\n",
    "train_loader_emotion_lex, test_loader_emotion_lex = make_data(emotion_dataset, \"lex\", batch_size)\n",
    "train(train_loader_emotion_lex, net_half, 100, criterion, 5000, \"../logs/cross_\"+net_name, cuda, 0.1)\n",
    "test(test_loader_emotion_lex, net_half, criterion, 1000, \"../logs/cross_emotion_lex\")\n",
    "\n",
    "print(\"-------- net_lin_tweet_full\")\n",
    "net_full = Lin_Net(8, 4, 64, act_function)\n",
    "train_loader_tweet_full, test_loader_tweet_full = make_data(tweet_dataset, \"full\", batch_size)\n",
    "train(train_loader_tweet_full, net_full, 100, criterion, 5000, \"../logs/cross_\"+net_name, cuda, 0.1)\n",
    "test(test_loader_tweet_full, net_full, criterion, 1000, \"../logs/cross_tweet_full\")\n",
    "\n",
    "print(\"-------- net_lin_tweet_nolex\")\n",
    "net_half = Lin_Net(4, 4, 64, act_function)\n",
    "train_loader_tweet_nolex, test_loader_tweet_nolex = make_data(tweet_dataset, \"nolex\", batch_size)\n",
    "train(train_loader_tweet_nolex, net_half, 100, criterion, 5000, \"../logs/cross_\"+net_name, cuda, 0.1)\n",
    "test(test_loader_tweet_nolex, net_half, criterion, 1000, \"../logs/net_lin_tweet_nolex\")\n",
    "\n",
    "print(\"-------- net_lin_tweet_lex\")\n",
    "net_half = Lin_Net(4, 4, 64, act_function)\n",
    "train_loader_tweet_lex, test_loader_tweet_lex = make_data(tweet_dataset, \"lex\", batch_size)\n",
    "train(train_loader_tweet_lex, net_half, 100, criterion, 5000, \"../logs/cross_\"+net_name, cuda, 0.1)\n",
    "test(test_loader_tweet_lex, net_half, criterion, 1000, \"../logs/net_lin_tweet_lex\")\n",
    "\n",
    "print(\"...done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
