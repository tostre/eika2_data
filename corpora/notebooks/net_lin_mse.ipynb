{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin_Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, act_function):\n",
    "        super(Lin_Net, self).__init__()\n",
    "        self.act_function = act_function\n",
    "        \n",
    "        self.lin1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.lin3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # act_funtion = F.sigmoid oder F.relu\n",
    "        x = self.act_function(self.lin1(x))\n",
    "        x = self.act_function(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(D.Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = torch.from_numpy(x_tensor)\n",
    "        self.y = torch.from_numpy(y_tensor)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(dataset, features, batch_size, debug=False):\n",
    "    datasets = []\n",
    "    for file in dataset:\n",
    "        datasets.append(pd.read_csv(\"../\" + file))\n",
    "    dataset = pd.concat(datasets, axis=0, ignore_index=True)\n",
    "    \n",
    "    target = dataset[\"affect\"]\n",
    "    dataset_full = dataset[[\"word_count\", \"upper_word_count\", \"ent_word_count\", \"h_count\", \"s_count\", \"a_count\", \"f_count\", \"cons_punct_count\"]]\n",
    "    dataset_nolex = dataset[[\"word_count\", \"upper_word_count\", \"ent_word_count\", \"cons_punct_count\"]]\n",
    "    dataset_lex = dataset[[\"h_count\", \"s_count\", \"a_count\", \"f_count\"]]\n",
    "    \n",
    "    # make train and test sets\n",
    "    if features == \"full\": \n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_full, target, test_size=0.2)\n",
    "    elif features == \"nolex\":\n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_nolex, target, test_size=0.2)\n",
    "    elif features == \"lex\": \n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_lex, target, test_size=0.2)\n",
    "\n",
    "    # make data loaders\n",
    "    train_data = MyDataset(train_x.to_numpy(), train_y.to_numpy())\n",
    "    test_data = MyDataset(test_x.to_numpy(), test_y.to_numpy())\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    \n",
    "    if debug: \n",
    "        dataset_full = dataset_full.iloc[:10]\n",
    "        target = target[:10]\n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_full, target, test_size=0.8)\n",
    "        train_data = MyDataset(train_x.to_numpy(), train_y.to_numpy())\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "        test_loader = DataLoader(dataset=train_data, batch_size=1)\n",
    "    return train_loader, test_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(summary, file):\n",
    "    log = open(file, \"a\")\n",
    "    log.write(summary)\n",
    "    log.close()\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, epochs, criterion, print_every, save_name, cuda, lr):\n",
    "    open(save_name + \"_train\", \"w\").close()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.5)\n",
    "    error_curve = []\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        for index, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.float(), targets.float()\n",
    "            if cuda: \n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "                net = net.cuda()\n",
    "            pred = net(inputs)    \n",
    "            loss = criterion(pred, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if ((index) % print_every == 0):\n",
    "                log(\"batch: {}/{} in epoch {}/{} \\n... loss: {}\\n\".\n",
    "                    format((index+1), len(train_loader), (epoch+1), epochs, loss.item()), \n",
    "                    save_name + \"_train\")\n",
    "        # save network after every epoch\n",
    "        torch.save(net.state_dict(), save_name + \".pt\")  \n",
    "        # after every epoch save the error\n",
    "        error_curve.append([epoch, loss.item()])\n",
    "    log(\"\\n\" + str(error_curve), save_name + \"_train\")\n",
    "    plot = plt.plot([item[0] for item in error_curve], [item[1] for item in error_curve])\n",
    "    plt.savefig(save_name+\"_train_error.png\")\n",
    "\n",
    "def test(test_loader, net, criterion, print_every, save_name, cuda):\n",
    "    open(save_name + \"_test\", \"w\").close()\n",
    "    confusion = []\n",
    "    net.eval()\n",
    "    loss_sum, correct, correct2 = 0, 0, 0\n",
    "    for index, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        if cuda: \n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            net = net.cuda()\n",
    "        pred = net(inputs)\n",
    "        pred_class = round(pred.item())\n",
    "        loss_sum += criterion(pred, targets).item()\n",
    "        confusion.append([targets.item(), pred_class])\n",
    "        \n",
    "        # correct? \n",
    "        if pred_class == targets.item():\n",
    "            correct += 1\n",
    "        \n",
    "        if ((index) % print_every == 0):\n",
    "            log(\"batch: {}/{}\\n... correct: {}\\n\".\n",
    "                format((index+1), len(test_loader), correct), \n",
    "                save_name + \"_test\")\n",
    "           \n",
    "    # give end report\n",
    "    log(\"average test loss: {}, relative correct: {}\\n\\nconfusion:\\n{}\".\n",
    "        format((loss_sum / len(test_loader)), (correct / len(test_loader)),str(confusion)), \n",
    "        save_name + \"_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating variables\n"
     ]
    }
   ],
   "source": [
    "# create variables \n",
    "print(\"creating variables\")\n",
    "emotion_dataset = [\"emotion_classification_1_clean.csv\", \"emotion_classification_2_clean.csv\", \"emotion_classification_3_clean.csv\", \"emotion_classification_4_clean.csv\", \"emotion_classification_5_clean.csv\", \"emotion_classification_6_clean.csv\", \"emotion_classification_7_clean.csv\", \"emotion_classification_8_clean.csv\"]\n",
    "tweet_dataset = [\"crowdflower_clean.csv\", \"emoint_clean.csv\", \"tec_clean.csv\"]\n",
    "act_function = torch.sigmoid\n",
    "criterion = nn.MSELoss()\n",
    "cuda = torch.cuda.is_available()\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcel/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 1/1000 \n",
      "... loss: 1.7329624891281128\n",
      "\n",
      "batch: 1/1 in epoch 2/1000 \n",
      "... loss: 11.440106391906738\n",
      "\n",
      "batch: 1/1 in epoch 3/1000 \n",
      "... loss: 23.923999786376953\n",
      "\n",
      "batch: 1/1 in epoch 4/1000 \n",
      "... loss: 0.004358451813459396\n",
      "\n",
      "batch: 1/1 in epoch 5/1000 \n",
      "... loss: 0.31588196754455566\n",
      "\n",
      "batch: 1/1 in epoch 6/1000 \n",
      "... loss: 0.26433297991752625\n",
      "\n",
      "batch: 1/1 in epoch 7/1000 \n",
      "... loss: 0.10749535262584686\n",
      "\n",
      "batch: 1/1 in epoch 8/1000 \n",
      "... loss: 0.024315308779478073\n",
      "\n",
      "batch: 1/1 in epoch 9/1000 \n",
      "... loss: 0.003967489115893841\n",
      "\n",
      "batch: 1/1 in epoch 10/1000 \n",
      "... loss: 0.005499375984072685\n",
      "\n",
      "batch: 1/1 in epoch 11/1000 \n",
      "... loss: 0.007741155102849007\n",
      "\n",
      "batch: 1/1 in epoch 12/1000 \n",
      "... loss: 0.0068835108540952206\n",
      "\n",
      "batch: 1/1 in epoch 13/1000 \n",
      "... loss: 0.0049796630628407\n",
      "\n",
      "batch: 1/1 in epoch 14/1000 \n",
      "... loss: 0.0036837956868112087\n",
      "\n",
      "batch: 1/1 in epoch 15/1000 \n",
      "... loss: 0.003202561056241393\n",
      "\n",
      "batch: 1/1 in epoch 16/1000 \n",
      "... loss: 0.0031308613251894712\n",
      "\n",
      "batch: 1/1 in epoch 17/1000 \n",
      "... loss: 0.0031367570627480745\n",
      "\n",
      "batch: 1/1 in epoch 18/1000 \n",
      "... loss: 0.0031102283392101526\n",
      "\n",
      "batch: 1/1 in epoch 19/1000 \n",
      "... loss: 0.0030598791781812906\n",
      "\n",
      "batch: 1/1 in epoch 20/1000 \n",
      "... loss: 0.003011351218447089\n",
      "\n",
      "batch: 1/1 in epoch 21/1000 \n",
      "... loss: 0.0029733735136687756\n",
      "\n",
      "batch: 1/1 in epoch 22/1000 \n",
      "... loss: 0.0029427737463265657\n",
      "\n",
      "batch: 1/1 in epoch 23/1000 \n",
      "... loss: 0.002914741402491927\n",
      "\n",
      "batch: 1/1 in epoch 24/1000 \n",
      "... loss: 0.002887014066800475\n",
      "\n",
      "batch: 1/1 in epoch 25/1000 \n",
      "... loss: 0.0028592930175364017\n",
      "\n",
      "batch: 1/1 in epoch 26/1000 \n",
      "... loss: 0.0028318678960204124\n",
      "\n",
      "batch: 1/1 in epoch 27/1000 \n",
      "... loss: 0.002804945921525359\n",
      "\n",
      "batch: 1/1 in epoch 28/1000 \n",
      "... loss: 0.00277849193662405\n",
      "\n",
      "batch: 1/1 in epoch 29/1000 \n",
      "... loss: 0.0027524749748408794\n",
      "\n",
      "batch: 1/1 in epoch 30/1000 \n",
      "... loss: 0.0027268165722489357\n",
      "\n",
      "batch: 1/1 in epoch 31/1000 \n",
      "... loss: 0.0027015055529773235\n",
      "\n",
      "batch: 1/1 in epoch 32/1000 \n",
      "... loss: 0.00267653726041317\n",
      "\n",
      "batch: 1/1 in epoch 33/1000 \n",
      "... loss: 0.0026519170496612787\n",
      "\n",
      "batch: 1/1 in epoch 34/1000 \n",
      "... loss: 0.002627633512020111\n",
      "\n",
      "batch: 1/1 in epoch 35/1000 \n",
      "... loss: 0.0026036801282316446\n",
      "\n",
      "batch: 1/1 in epoch 36/1000 \n",
      "... loss: 0.0025800454895943403\n",
      "\n",
      "batch: 1/1 in epoch 37/1000 \n",
      "... loss: 0.002556738443672657\n",
      "\n",
      "batch: 1/1 in epoch 38/1000 \n",
      "... loss: 0.002533730585128069\n",
      "\n",
      "batch: 1/1 in epoch 39/1000 \n",
      "... loss: 0.002511034021154046\n",
      "\n",
      "batch: 1/1 in epoch 40/1000 \n",
      "... loss: 0.0024886364117264748\n",
      "\n",
      "batch: 1/1 in epoch 41/1000 \n",
      "... loss: 0.0024665272794663906\n",
      "\n",
      "batch: 1/1 in epoch 42/1000 \n",
      "... loss: 0.0024447068572044373\n",
      "\n",
      "batch: 1/1 in epoch 43/1000 \n",
      "... loss: 0.0024231697898358107\n",
      "\n",
      "batch: 1/1 in epoch 44/1000 \n",
      "... loss: 0.002401918638497591\n",
      "\n",
      "batch: 1/1 in epoch 45/1000 \n",
      "... loss: 0.002380932914093137\n",
      "\n",
      "batch: 1/1 in epoch 46/1000 \n",
      "... loss: 0.002360219368711114\n",
      "\n",
      "batch: 1/1 in epoch 47/1000 \n",
      "... loss: 0.0023397693876177073\n",
      "\n",
      "batch: 1/1 in epoch 48/1000 \n",
      "... loss: 0.0023195722606033087\n",
      "\n",
      "batch: 1/1 in epoch 49/1000 \n",
      "... loss: 0.0022996284533292055\n",
      "\n",
      "batch: 1/1 in epoch 50/1000 \n",
      "... loss: 0.0022799500729888678\n",
      "\n",
      "batch: 1/1 in epoch 51/1000 \n",
      "... loss: 0.0022605066187679768\n",
      "\n",
      "batch: 1/1 in epoch 52/1000 \n",
      "... loss: 0.0022412962280213833\n",
      "\n",
      "batch: 1/1 in epoch 53/1000 \n",
      "... loss: 0.002222325187176466\n",
      "\n",
      "batch: 1/1 in epoch 54/1000 \n",
      "... loss: 0.0022036030422896147\n",
      "\n",
      "batch: 1/1 in epoch 55/1000 \n",
      "... loss: 0.0021851020865142345\n",
      "\n",
      "batch: 1/1 in epoch 56/1000 \n",
      "... loss: 0.0021668127737939358\n",
      "\n",
      "batch: 1/1 in epoch 57/1000 \n",
      "... loss: 0.0021487632766366005\n",
      "\n",
      "batch: 1/1 in epoch 58/1000 \n",
      "... loss: 0.002130921697244048\n",
      "\n",
      "batch: 1/1 in epoch 59/1000 \n",
      "... loss: 0.002113297116011381\n",
      "\n",
      "batch: 1/1 in epoch 60/1000 \n",
      "... loss: 0.0020958767272531986\n",
      "\n",
      "batch: 1/1 in epoch 61/1000 \n",
      "... loss: 0.0020786754321306944\n",
      "\n",
      "batch: 1/1 in epoch 62/1000 \n",
      "... loss: 0.0020616641268134117\n",
      "\n",
      "batch: 1/1 in epoch 63/1000 \n",
      "... loss: 0.0020448656287044287\n",
      "\n",
      "batch: 1/1 in epoch 64/1000 \n",
      "... loss: 0.0020282650366425514\n",
      "\n",
      "batch: 1/1 in epoch 65/1000 \n",
      "... loss: 0.0020118418615311384\n",
      "\n",
      "batch: 1/1 in epoch 66/1000 \n",
      "... loss: 0.001995623577386141\n",
      "\n",
      "batch: 1/1 in epoch 67/1000 \n",
      "... loss: 0.001979588298127055\n",
      "\n",
      "batch: 1/1 in epoch 68/1000 \n",
      "... loss: 0.001963744405657053\n",
      "\n",
      "batch: 1/1 in epoch 69/1000 \n",
      "... loss: 0.001948080025613308\n",
      "\n",
      "batch: 1/1 in epoch 70/1000 \n",
      "... loss: 0.0019325832836329937\n",
      "\n",
      "batch: 1/1 in epoch 71/1000 \n",
      "... loss: 0.0019172737374901772\n",
      "\n",
      "batch: 1/1 in epoch 72/1000 \n",
      "... loss: 0.0019021371845155954\n",
      "\n",
      "batch: 1/1 in epoch 73/1000 \n",
      "... loss: 0.0018871667562052608\n",
      "\n",
      "batch: 1/1 in epoch 74/1000 \n",
      "... loss: 0.0018723664106801152\n",
      "\n",
      "batch: 1/1 in epoch 75/1000 \n",
      "... loss: 0.0018577298615127802\n",
      "\n",
      "batch: 1/1 in epoch 76/1000 \n",
      "... loss: 0.001843258156441152\n",
      "\n",
      "batch: 1/1 in epoch 77/1000 \n",
      "... loss: 0.0018289478030055761\n",
      "\n",
      "batch: 1/1 in epoch 78/1000 \n",
      "... loss: 0.0018147948430851102\n",
      "\n",
      "batch: 1/1 in epoch 79/1000 \n",
      "... loss: 0.0018008005572482944\n",
      "\n",
      "batch: 1/1 in epoch 80/1000 \n",
      "... loss: 0.0017869513249024749\n",
      "\n",
      "batch: 1/1 in epoch 81/1000 \n",
      "... loss: 0.0017732609994709492\n",
      "\n",
      "batch: 1/1 in epoch 82/1000 \n",
      "... loss: 0.0017597133992239833\n",
      "\n",
      "batch: 1/1 in epoch 83/1000 \n",
      "... loss: 0.001746302586980164\n",
      "\n",
      "batch: 1/1 in epoch 84/1000 \n",
      "... loss: 0.0017330498667433858\n",
      "\n",
      "batch: 1/1 in epoch 85/1000 \n",
      "... loss: 0.0017199366120621562\n",
      "\n",
      "batch: 1/1 in epoch 86/1000 \n",
      "... loss: 0.0017069594468921423\n",
      "\n",
      "batch: 1/1 in epoch 87/1000 \n",
      "... loss: 0.001694127218797803\n",
      "\n",
      "batch: 1/1 in epoch 88/1000 \n",
      "... loss: 0.0016814216505736113\n",
      "\n",
      "batch: 1/1 in epoch 89/1000 \n",
      "... loss: 0.0016688443720340729\n",
      "\n",
      "batch: 1/1 in epoch 90/1000 \n",
      "... loss: 0.0016564112156629562\n",
      "\n",
      "batch: 1/1 in epoch 91/1000 \n",
      "... loss: 0.001644106931053102\n",
      "\n",
      "batch: 1/1 in epoch 92/1000 \n",
      "... loss: 0.0016319232527166605\n",
      "\n",
      "batch: 1/1 in epoch 93/1000 \n",
      "... loss: 0.0016198687953874469\n",
      "\n",
      "batch: 1/1 in epoch 94/1000 \n",
      "... loss: 0.0016079333145171404\n",
      "\n",
      "batch: 1/1 in epoch 95/1000 \n",
      "... loss: 0.0015961204189807177\n",
      "\n",
      "batch: 1/1 in epoch 96/1000 \n",
      "... loss: 0.0015844342997297645\n",
      "\n",
      "batch: 1/1 in epoch 97/1000 \n",
      "... loss: 0.001572857378050685\n",
      "\n",
      "batch: 1/1 in epoch 98/1000 \n",
      "... loss: 0.0015613982686772943\n",
      "\n",
      "batch: 1/1 in epoch 99/1000 \n",
      "... loss: 0.0015500679146498442\n",
      "\n",
      "batch: 1/1 in epoch 100/1000 \n",
      "... loss: 0.0015388374449685216\n",
      "\n",
      "batch: 1/1 in epoch 101/1000 \n",
      "... loss: 0.001527720014564693\n",
      "\n",
      "batch: 1/1 in epoch 102/1000 \n",
      "... loss: 0.0015167148085311055\n",
      "\n",
      "batch: 1/1 in epoch 103/1000 \n",
      "... loss: 0.0015058189164847136\n",
      "\n",
      "batch: 1/1 in epoch 104/1000 \n",
      "... loss: 0.0014950245385989547\n",
      "\n",
      "batch: 1/1 in epoch 105/1000 \n",
      "... loss: 0.0014843379613012075\n",
      "\n",
      "batch: 1/1 in epoch 106/1000 \n",
      "... loss: 0.0014737538294866681\n",
      "\n",
      "batch: 1/1 in epoch 107/1000 \n",
      "... loss: 0.0014632781967520714\n",
      "\n",
      "batch: 1/1 in epoch 108/1000 \n",
      "... loss: 0.001452892436645925\n",
      "\n",
      "batch: 1/1 in epoch 109/1000 \n",
      "... loss: 0.0014426092384383082\n",
      "\n",
      "batch: 1/1 in epoch 110/1000 \n",
      "... loss: 0.0014324256917461753\n",
      "\n",
      "batch: 1/1 in epoch 111/1000 \n",
      "... loss: 0.0014223366742953658\n",
      "\n",
      "batch: 1/1 in epoch 112/1000 \n",
      "... loss: 0.001412346144206822\n",
      "\n",
      "batch: 1/1 in epoch 113/1000 \n",
      "... loss: 0.0014024510746821761\n",
      "\n",
      "batch: 1/1 in epoch 114/1000 \n",
      "... loss: 0.001392637612298131\n",
      "\n",
      "batch: 1/1 in epoch 115/1000 \n",
      "... loss: 0.0013829206582158804\n",
      "\n",
      "batch: 1/1 in epoch 116/1000 \n",
      "... loss: 0.0013732953229919076\n",
      "\n",
      "batch: 1/1 in epoch 117/1000 \n",
      "... loss: 0.0013637541560456157\n",
      "\n",
      "batch: 1/1 in epoch 118/1000 \n",
      "... loss: 0.0013543033273890615\n",
      "\n",
      "batch: 1/1 in epoch 119/1000 \n",
      "... loss: 0.001344940043054521\n",
      "\n",
      "batch: 1/1 in epoch 120/1000 \n",
      "... loss: 0.0013356548734009266\n",
      "\n",
      "batch: 1/1 in epoch 121/1000 \n",
      "... loss: 0.0013264563167467713\n",
      "\n",
      "batch: 1/1 in epoch 122/1000 \n",
      "... loss: 0.0013173414627090096\n",
      "\n",
      "batch: 1/1 in epoch 123/1000 \n",
      "... loss: 0.001308301230892539\n",
      "\n",
      "batch: 1/1 in epoch 124/1000 \n",
      "... loss: 0.0012993479613214731\n",
      "\n",
      "batch: 1/1 in epoch 125/1000 \n",
      "... loss: 0.0012904724571853876\n",
      "\n",
      "batch: 1/1 in epoch 126/1000 \n",
      "... loss: 0.001281672390177846\n",
      "\n",
      "batch: 1/1 in epoch 127/1000 \n",
      "... loss: 0.00127294915728271\n",
      "\n",
      "batch: 1/1 in epoch 128/1000 \n",
      "... loss: 0.0012643022928386927\n",
      "\n",
      "batch: 1/1 in epoch 129/1000 \n",
      "... loss: 0.0012557252775877714\n",
      "\n",
      "batch: 1/1 in epoch 130/1000 \n",
      "... loss: 0.001247225794941187\n",
      "\n",
      "batch: 1/1 in epoch 131/1000 \n",
      "... loss: 0.0012387949973344803\n",
      "\n",
      "batch: 1/1 in epoch 132/1000 \n",
      "... loss: 0.0012304409174248576\n",
      "\n",
      "batch: 1/1 in epoch 133/1000 \n",
      "... loss: 0.0012221505166962743\n",
      "\n",
      "batch: 1/1 in epoch 134/1000 \n",
      "... loss: 0.0012139339232817292\n",
      "\n",
      "batch: 1/1 in epoch 135/1000 \n",
      "... loss: 0.0012057843850925565\n",
      "\n",
      "batch: 1/1 in epoch 136/1000 \n",
      "... loss: 0.0011977035319432616\n",
      "\n",
      "batch: 1/1 in epoch 137/1000 \n",
      "... loss: 0.0011896848445758224\n",
      "\n",
      "batch: 1/1 in epoch 138/1000 \n",
      "... loss: 0.0011817340273410082\n",
      "\n",
      "batch: 1/1 in epoch 139/1000 \n",
      "... loss: 0.0011738446773961186\n",
      "\n",
      "batch: 1/1 in epoch 140/1000 \n",
      "... loss: 0.0011660224990919232\n",
      "\n",
      "batch: 1/1 in epoch 141/1000 \n",
      "... loss: 0.0011582670267671347\n",
      "\n",
      "batch: 1/1 in epoch 142/1000 \n",
      "... loss: 0.0011505697621032596\n",
      "\n",
      "batch: 1/1 in epoch 143/1000 \n",
      "... loss: 0.0011429303558543324\n",
      "\n",
      "batch: 1/1 in epoch 144/1000 \n",
      "... loss: 0.0011353547452017665\n",
      "\n",
      "batch: 1/1 in epoch 145/1000 \n",
      "... loss: 0.0011278282618150115\n",
      "\n",
      "batch: 1/1 in epoch 146/1000 \n",
      "... loss: 0.001120376749895513\n",
      "\n",
      "batch: 1/1 in epoch 147/1000 \n",
      "... loss: 0.0011129718041047454\n",
      "\n",
      "batch: 1/1 in epoch 148/1000 \n",
      "... loss: 0.001105627161450684\n",
      "\n",
      "batch: 1/1 in epoch 149/1000 \n",
      "... loss: 0.0010983383981510997\n",
      "\n",
      "batch: 1/1 in epoch 150/1000 \n",
      "... loss: 0.0010911072604358196\n",
      "\n",
      "batch: 1/1 in epoch 151/1000 \n",
      "... loss: 0.0010839254828169942\n",
      "\n",
      "batch: 1/1 in epoch 152/1000 \n",
      "... loss: 0.0010768006322905421\n",
      "\n",
      "batch: 1/1 in epoch 153/1000 \n",
      "... loss: 0.0010697267716750503\n",
      "\n",
      "batch: 1/1 in epoch 154/1000 \n",
      "... loss: 0.0010627091396600008\n",
      "\n",
      "batch: 1/1 in epoch 155/1000 \n",
      "... loss: 0.0010557378409430385\n",
      "\n",
      "batch: 1/1 in epoch 156/1000 \n",
      "... loss: 0.0010488262632861733\n",
      "\n",
      "batch: 1/1 in epoch 157/1000 \n",
      "... loss: 0.0010419604368507862\n",
      "\n",
      "batch: 1/1 in epoch 158/1000 \n",
      "... loss: 0.001035145833157003\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 159/1000 \n",
      "... loss: 0.001028376747854054\n",
      "\n",
      "batch: 1/1 in epoch 160/1000 \n",
      "... loss: 0.0010216583032160997\n",
      "\n",
      "batch: 1/1 in epoch 161/1000 \n",
      "... loss: 0.0010149847948923707\n",
      "\n",
      "batch: 1/1 in epoch 162/1000 \n",
      "... loss: 0.001008361461572349\n",
      "\n",
      "batch: 1/1 in epoch 163/1000 \n",
      "... loss: 0.0010017863241955638\n",
      "\n",
      "batch: 1/1 in epoch 164/1000 \n",
      "... loss: 0.0009952514665201306\n",
      "\n",
      "batch: 1/1 in epoch 165/1000 \n",
      "... loss: 0.0009887679480016232\n",
      "\n",
      "batch: 1/1 in epoch 166/1000 \n",
      "... loss: 0.0009823262225836515\n",
      "\n",
      "batch: 1/1 in epoch 167/1000 \n",
      "... loss: 0.0009759241947904229\n",
      "\n",
      "batch: 1/1 in epoch 168/1000 \n",
      "... loss: 0.0009695764747448266\n",
      "\n",
      "batch: 1/1 in epoch 169/1000 \n",
      "... loss: 0.0009632605942897499\n",
      "\n",
      "batch: 1/1 in epoch 170/1000 \n",
      "... loss: 0.0009569949470460415\n",
      "\n",
      "batch: 1/1 in epoch 171/1000 \n",
      "... loss: 0.0009507680661045015\n",
      "\n",
      "batch: 1/1 in epoch 172/1000 \n",
      "... loss: 0.000944579835049808\n",
      "\n",
      "batch: 1/1 in epoch 173/1000 \n",
      "... loss: 0.0009384391596540809\n",
      "\n",
      "batch: 1/1 in epoch 174/1000 \n",
      "... loss: 0.0009323367848992348\n",
      "\n",
      "batch: 1/1 in epoch 175/1000 \n",
      "... loss: 0.0009262670646421611\n",
      "\n",
      "batch: 1/1 in epoch 176/1000 \n",
      "... loss: 0.0009202460641972721\n",
      "\n",
      "batch: 1/1 in epoch 177/1000 \n",
      "... loss: 0.000914262724108994\n",
      "\n",
      "batch: 1/1 in epoch 178/1000 \n",
      "... loss: 0.0009083151235245168\n",
      "\n",
      "batch: 1/1 in epoch 179/1000 \n",
      "... loss: 0.0009024048340506852\n",
      "\n",
      "batch: 1/1 in epoch 180/1000 \n",
      "... loss: 0.000896535231731832\n",
      "\n",
      "batch: 1/1 in epoch 181/1000 \n",
      "... loss: 0.0008906990406103432\n",
      "\n",
      "batch: 1/1 in epoch 182/1000 \n",
      "... loss: 0.0008849049336276948\n",
      "\n",
      "batch: 1/1 in epoch 183/1000 \n",
      "... loss: 0.0008791369036771357\n",
      "\n",
      "batch: 1/1 in epoch 184/1000 \n",
      "... loss: 0.0008734159055165946\n",
      "\n",
      "batch: 1/1 in epoch 185/1000 \n",
      "... loss: 0.0008677258156239986\n",
      "\n",
      "batch: 1/1 in epoch 186/1000 \n",
      "... loss: 0.000862071814481169\n",
      "\n",
      "batch: 1/1 in epoch 187/1000 \n",
      "... loss: 0.00085645035142079\n",
      "\n",
      "batch: 1/1 in epoch 188/1000 \n",
      "... loss: 0.0008508663740940392\n",
      "\n",
      "batch: 1/1 in epoch 189/1000 \n",
      "... loss: 0.0008453128393739462\n",
      "\n",
      "batch: 1/1 in epoch 190/1000 \n",
      "... loss: 0.000839796441141516\n",
      "\n",
      "batch: 1/1 in epoch 191/1000 \n",
      "... loss: 0.0008343119407072663\n",
      "\n",
      "batch: 1/1 in epoch 192/1000 \n",
      "... loss: 0.0008288557291962206\n",
      "\n",
      "batch: 1/1 in epoch 193/1000 \n",
      "... loss: 0.0008234395645558834\n",
      "\n",
      "batch: 1/1 in epoch 194/1000 \n",
      "... loss: 0.0008180514560081065\n",
      "\n",
      "batch: 1/1 in epoch 195/1000 \n",
      "... loss: 0.0008126929169520736\n",
      "\n",
      "batch: 1/1 in epoch 196/1000 \n",
      "... loss: 0.0008073740755207837\n",
      "\n",
      "batch: 1/1 in epoch 197/1000 \n",
      "... loss: 0.0008020793902687728\n",
      "\n",
      "batch: 1/1 in epoch 198/1000 \n",
      "... loss: 0.0007968139252625406\n",
      "\n",
      "batch: 1/1 in epoch 199/1000 \n",
      "... loss: 0.0007915859459899366\n",
      "\n",
      "batch: 1/1 in epoch 200/1000 \n",
      "... loss: 0.000786385266110301\n",
      "\n",
      "batch: 1/1 in epoch 201/1000 \n",
      "... loss: 0.0007812116527929902\n",
      "\n",
      "batch: 1/1 in epoch 202/1000 \n",
      "... loss: 0.0007760734297335148\n",
      "\n",
      "batch: 1/1 in epoch 203/1000 \n",
      "... loss: 0.0007709587807767093\n",
      "\n",
      "batch: 1/1 in epoch 204/1000 \n",
      "... loss: 0.0007658791728317738\n",
      "\n",
      "batch: 1/1 in epoch 205/1000 \n",
      "... loss: 0.0007608262239955366\n",
      "\n",
      "batch: 1/1 in epoch 206/1000 \n",
      "... loss: 0.000755803135689348\n",
      "\n",
      "batch: 1/1 in epoch 207/1000 \n",
      "... loss: 0.0007508032722398639\n",
      "\n",
      "batch: 1/1 in epoch 208/1000 \n",
      "... loss: 0.0007458378677256405\n",
      "\n",
      "batch: 1/1 in epoch 209/1000 \n",
      "... loss: 0.0007408970850519836\n",
      "\n",
      "batch: 1/1 in epoch 210/1000 \n",
      "... loss: 0.0007359904702752829\n",
      "\n",
      "batch: 1/1 in epoch 211/1000 \n",
      "... loss: 0.0007311050430871546\n",
      "\n",
      "batch: 1/1 in epoch 212/1000 \n",
      "... loss: 0.0007262487197294831\n",
      "\n",
      "batch: 1/1 in epoch 213/1000 \n",
      "... loss: 0.0007214214419946074\n",
      "\n",
      "batch: 1/1 in epoch 214/1000 \n",
      "... loss: 0.0007166197756305337\n",
      "\n",
      "batch: 1/1 in epoch 215/1000 \n",
      "... loss: 0.0007118437206372619\n",
      "\n",
      "batch: 1/1 in epoch 216/1000 \n",
      "... loss: 0.0007070963620208204\n",
      "\n",
      "batch: 1/1 in epoch 217/1000 \n",
      "... loss: 0.0007023743237368762\n",
      "\n",
      "batch: 1/1 in epoch 218/1000 \n",
      "... loss: 0.0006976791773922741\n",
      "\n",
      "batch: 1/1 in epoch 219/1000 \n",
      "... loss: 0.000693012319970876\n",
      "\n",
      "batch: 1/1 in epoch 220/1000 \n",
      "... loss: 0.0006883689202368259\n",
      "\n",
      "batch: 1/1 in epoch 221/1000 \n",
      "... loss: 0.0006837567198090255\n",
      "\n",
      "batch: 1/1 in epoch 222/1000 \n",
      "... loss: 0.0006791647174395621\n",
      "\n",
      "batch: 1/1 in epoch 223/1000 \n",
      "... loss: 0.0006746005965396762\n",
      "\n",
      "batch: 1/1 in epoch 224/1000 \n",
      "... loss: 0.0006700595840811729\n",
      "\n",
      "batch: 1/1 in epoch 225/1000 \n",
      "... loss: 0.0006655462202616036\n",
      "\n",
      "batch: 1/1 in epoch 226/1000 \n",
      "... loss: 0.0006610588170588017\n",
      "\n",
      "batch: 1/1 in epoch 227/1000 \n",
      "... loss: 0.0006565957446582615\n",
      "\n",
      "batch: 1/1 in epoch 228/1000 \n",
      "... loss: 0.000652158516459167\n",
      "\n",
      "batch: 1/1 in epoch 229/1000 \n",
      "... loss: 0.0006477468996308744\n",
      "\n",
      "batch: 1/1 in epoch 230/1000 \n",
      "... loss: 0.0006433593807742\n",
      "\n",
      "batch: 1/1 in epoch 231/1000 \n",
      "... loss: 0.000638995785266161\n",
      "\n",
      "batch: 1/1 in epoch 232/1000 \n",
      "... loss: 0.0006346575682982802\n",
      "\n",
      "batch: 1/1 in epoch 233/1000 \n",
      "... loss: 0.0006303416448645294\n",
      "\n",
      "batch: 1/1 in epoch 234/1000 \n",
      "... loss: 0.0006260568043217063\n",
      "\n",
      "batch: 1/1 in epoch 235/1000 \n",
      "... loss: 0.00062178960070014\n",
      "\n",
      "batch: 1/1 in epoch 236/1000 \n",
      "... loss: 0.000617551791947335\n",
      "\n",
      "batch: 1/1 in epoch 237/1000 \n",
      "... loss: 0.0006133343558758497\n",
      "\n",
      "batch: 1/1 in epoch 238/1000 \n",
      "... loss: 0.0006091431714594364\n",
      "\n",
      "batch: 1/1 in epoch 239/1000 \n",
      "... loss: 0.0006049751536920667\n",
      "\n",
      "batch: 1/1 in epoch 240/1000 \n",
      "... loss: 0.0006008331547491252\n",
      "\n",
      "batch: 1/1 in epoch 241/1000 \n",
      "... loss: 0.0005967156030237675\n",
      "\n",
      "batch: 1/1 in epoch 242/1000 \n",
      "... loss: 0.0005926208687014878\n",
      "\n",
      "batch: 1/1 in epoch 243/1000 \n",
      "... loss: 0.000588550406973809\n",
      "\n",
      "batch: 1/1 in epoch 244/1000 \n",
      "... loss: 0.0005845025880262256\n",
      "\n",
      "batch: 1/1 in epoch 245/1000 \n",
      "... loss: 0.0005804759566672146\n",
      "\n",
      "batch: 1/1 in epoch 246/1000 \n",
      "... loss: 0.0005764775560237467\n",
      "\n",
      "batch: 1/1 in epoch 247/1000 \n",
      "... loss: 0.0005725029041059315\n",
      "\n",
      "batch: 1/1 in epoch 248/1000 \n",
      "... loss: 0.0005685506039299071\n",
      "\n",
      "batch: 1/1 in epoch 249/1000 \n",
      "... loss: 0.0005646232748404145\n",
      "\n",
      "batch: 1/1 in epoch 250/1000 \n",
      "... loss: 0.0005607180646620691\n",
      "\n",
      "batch: 1/1 in epoch 251/1000 \n",
      "... loss: 0.0005568419001065195\n",
      "\n",
      "batch: 1/1 in epoch 252/1000 \n",
      "... loss: 0.0005529819172807038\n",
      "\n",
      "batch: 1/1 in epoch 253/1000 \n",
      "... loss: 0.0005491480114869773\n",
      "\n",
      "batch: 1/1 in epoch 254/1000 \n",
      "... loss: 0.0005453357589431107\n",
      "\n",
      "batch: 1/1 in epoch 255/1000 \n",
      "... loss: 0.0005415478954091668\n",
      "\n",
      "batch: 1/1 in epoch 256/1000 \n",
      "... loss: 0.0005377843044698238\n",
      "\n",
      "batch: 1/1 in epoch 257/1000 \n",
      "... loss: 0.00053404486970976\n",
      "\n",
      "batch: 1/1 in epoch 258/1000 \n",
      "... loss: 0.0005303294165059924\n",
      "\n",
      "batch: 1/1 in epoch 259/1000 \n",
      "... loss: 0.0005266351508907974\n",
      "\n",
      "batch: 1/1 in epoch 260/1000 \n",
      "... loss: 0.0005229647504165769\n",
      "\n",
      "batch: 1/1 in epoch 261/1000 \n",
      "... loss: 0.0005193180404603481\n",
      "\n",
      "batch: 1/1 in epoch 262/1000 \n",
      "... loss: 0.0005156922270543873\n",
      "\n",
      "batch: 1/1 in epoch 263/1000 \n",
      "... loss: 0.0005120898713357747\n",
      "\n",
      "batch: 1/1 in epoch 264/1000 \n",
      "... loss: 0.0005085163284093142\n",
      "\n",
      "batch: 1/1 in epoch 265/1000 \n",
      "... loss: 0.0005049632745794952\n",
      "\n",
      "batch: 1/1 in epoch 266/1000 \n",
      "... loss: 0.0005014307098463178\n",
      "\n",
      "batch: 1/1 in epoch 267/1000 \n",
      "... loss: 0.000497918576002121\n",
      "\n",
      "batch: 1/1 in epoch 268/1000 \n",
      "... loss: 0.0004944346146658063\n",
      "\n",
      "batch: 1/1 in epoch 269/1000 \n",
      "... loss: 0.0004909708513878286\n",
      "\n",
      "batch: 1/1 in epoch 270/1000 \n",
      "... loss: 0.0004875298182014376\n",
      "\n",
      "batch: 1/1 in epoch 271/1000 \n",
      "... loss: 0.0004841152695007622\n",
      "\n",
      "batch: 1/1 in epoch 272/1000 \n",
      "... loss: 0.00048071928904391825\n",
      "\n",
      "batch: 1/1 in epoch 273/1000 \n",
      "... loss: 0.0004773469700012356\n",
      "\n",
      "batch: 1/1 in epoch 274/1000 \n",
      "... loss: 0.00047400081530213356\n",
      "\n",
      "batch: 1/1 in epoch 275/1000 \n",
      "... loss: 0.00047067416016943753\n",
      "\n",
      "batch: 1/1 in epoch 276/1000 \n",
      "... loss: 0.0004673695657402277\n",
      "\n",
      "batch: 1/1 in epoch 277/1000 \n",
      "... loss: 0.00046408941852860153\n",
      "\n",
      "batch: 1/1 in epoch 278/1000 \n",
      "... loss: 0.0004608298186212778\n",
      "\n",
      "batch: 1/1 in epoch 279/1000 \n",
      "... loss: 0.000457593152532354\n",
      "\n",
      "batch: 1/1 in epoch 280/1000 \n",
      "... loss: 0.0004543806135188788\n",
      "\n",
      "batch: 1/1 in epoch 281/1000 \n",
      "... loss: 0.0004511882725637406\n",
      "\n",
      "batch: 1/1 in epoch 282/1000 \n",
      "... loss: 0.00044801976764574647\n",
      "\n",
      "batch: 1/1 in epoch 283/1000 \n",
      "... loss: 0.00044487000559456646\n",
      "\n",
      "batch: 1/1 in epoch 284/1000 \n",
      "... loss: 0.00044174384674988687\n",
      "\n",
      "batch: 1/1 in epoch 285/1000 \n",
      "... loss: 0.0004386424843687564\n",
      "\n",
      "batch: 1/1 in epoch 286/1000 \n",
      "... loss: 0.0004355607379693538\n",
      "\n",
      "batch: 1/1 in epoch 287/1000 \n",
      "... loss: 0.00043250349699519575\n",
      "\n",
      "batch: 1/1 in epoch 288/1000 \n",
      "... loss: 0.0004294619429856539\n",
      "\n",
      "batch: 1/1 in epoch 289/1000 \n",
      "... loss: 0.00042645083158276975\n",
      "\n",
      "batch: 1/1 in epoch 290/1000 \n",
      "... loss: 0.00042345523252151906\n",
      "\n",
      "batch: 1/1 in epoch 291/1000 \n",
      "... loss: 0.0004204836150165647\n",
      "\n",
      "batch: 1/1 in epoch 292/1000 \n",
      "... loss: 0.00041753100231289864\n",
      "\n",
      "batch: 1/1 in epoch 293/1000 \n",
      "... loss: 0.00041460213833488524\n",
      "\n",
      "batch: 1/1 in epoch 294/1000 \n",
      "... loss: 0.0004116920754313469\n",
      "\n",
      "batch: 1/1 in epoch 295/1000 \n",
      "... loss: 0.0004088078858330846\n",
      "\n",
      "batch: 1/1 in epoch 296/1000 \n",
      "... loss: 0.0004059386847075075\n",
      "\n",
      "batch: 1/1 in epoch 297/1000 \n",
      "... loss: 0.00040309751057066023\n",
      "\n",
      "batch: 1/1 in epoch 298/1000 \n",
      "... loss: 0.00040027109207585454\n",
      "\n",
      "batch: 1/1 in epoch 299/1000 \n",
      "... loss: 0.0003974688588641584\n",
      "\n",
      "batch: 1/1 in epoch 300/1000 \n",
      "... loss: 0.00039469069452024996\n",
      "\n",
      "batch: 1/1 in epoch 301/1000 \n",
      "... loss: 0.0003919293521903455\n",
      "\n",
      "batch: 1/1 in epoch 302/1000 \n",
      "... loss: 0.00038918713107705116\n",
      "\n",
      "batch: 1/1 in epoch 303/1000 \n",
      "... loss: 0.0003864697355311364\n",
      "\n",
      "batch: 1/1 in epoch 304/1000 \n",
      "... loss: 0.0003837700642179698\n",
      "\n",
      "batch: 1/1 in epoch 305/1000 \n",
      "... loss: 0.0003810926282312721\n",
      "\n",
      "batch: 1/1 in epoch 306/1000 \n",
      "... loss: 0.00037843387690372765\n",
      "\n",
      "batch: 1/1 in epoch 307/1000 \n",
      "... loss: 0.0003757959639187902\n",
      "\n",
      "batch: 1/1 in epoch 308/1000 \n",
      "... loss: 0.0003731764736585319\n",
      "\n",
      "batch: 1/1 in epoch 309/1000 \n",
      "... loss: 0.0003705787821672857\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 310/1000 \n",
      "... loss: 0.00036800047382712364\n",
      "\n",
      "batch: 1/1 in epoch 311/1000 \n",
      "... loss: 0.0003654425381682813\n",
      "\n",
      "batch: 1/1 in epoch 312/1000 \n",
      "... loss: 0.0003629026177804917\n",
      "\n",
      "batch: 1/1 in epoch 313/1000 \n",
      "... loss: 0.0003603862423915416\n",
      "\n",
      "batch: 1/1 in epoch 314/1000 \n",
      "... loss: 0.0003578831674531102\n",
      "\n",
      "batch: 1/1 in epoch 315/1000 \n",
      "... loss: 0.00035540226963348687\n",
      "\n",
      "batch: 1/1 in epoch 316/1000 \n",
      "... loss: 0.000352941220626235\n",
      "\n",
      "batch: 1/1 in epoch 317/1000 \n",
      "... loss: 0.00035049987491220236\n",
      "\n",
      "batch: 1/1 in epoch 318/1000 \n",
      "... loss: 0.0003480758750811219\n",
      "\n",
      "batch: 1/1 in epoch 319/1000 \n",
      "... loss: 0.00034567140392027795\n",
      "\n",
      "batch: 1/1 in epoch 320/1000 \n",
      "... loss: 0.000343284074915573\n",
      "\n",
      "batch: 1/1 in epoch 321/1000 \n",
      "... loss: 0.0003409171476960182\n",
      "\n",
      "batch: 1/1 in epoch 322/1000 \n",
      "... loss: 0.00033856937079690397\n",
      "\n",
      "batch: 1/1 in epoch 323/1000 \n",
      "... loss: 0.0003362373390700668\n",
      "\n",
      "batch: 1/1 in epoch 324/1000 \n",
      "... loss: 0.00033392643672414124\n",
      "\n",
      "batch: 1/1 in epoch 325/1000 \n",
      "... loss: 0.0003316322108730674\n",
      "\n",
      "batch: 1/1 in epoch 326/1000 \n",
      "... loss: 0.00032935559283941984\n",
      "\n",
      "batch: 1/1 in epoch 327/1000 \n",
      "... loss: 0.00032709763036109507\n",
      "\n",
      "batch: 1/1 in epoch 328/1000 \n",
      "... loss: 0.0003248592256568372\n",
      "\n",
      "batch: 1/1 in epoch 329/1000 \n",
      "... loss: 0.00032263496541418135\n",
      "\n",
      "batch: 1/1 in epoch 330/1000 \n",
      "... loss: 0.00032043110695667565\n",
      "\n",
      "batch: 1/1 in epoch 331/1000 \n",
      "... loss: 0.0003182433429174125\n",
      "\n",
      "batch: 1/1 in epoch 332/1000 \n",
      "... loss: 0.000316073652356863\n",
      "\n",
      "batch: 1/1 in epoch 333/1000 \n",
      "... loss: 0.00031391982338391244\n",
      "\n",
      "batch: 1/1 in epoch 334/1000 \n",
      "... loss: 0.0003117839223705232\n",
      "\n",
      "batch: 1/1 in epoch 335/1000 \n",
      "... loss: 0.0003096646978519857\n",
      "\n",
      "batch: 1/1 in epoch 336/1000 \n",
      "... loss: 0.0003075631975661963\n",
      "\n",
      "batch: 1/1 in epoch 337/1000 \n",
      "... loss: 0.0003054771514143795\n",
      "\n",
      "batch: 1/1 in epoch 338/1000 \n",
      "... loss: 0.0003034065302927047\n",
      "\n",
      "batch: 1/1 in epoch 339/1000 \n",
      "... loss: 0.0003013553796336055\n",
      "\n",
      "batch: 1/1 in epoch 340/1000 \n",
      "... loss: 0.00029931837343610823\n",
      "\n",
      "batch: 1/1 in epoch 341/1000 \n",
      "... loss: 0.0002972985676024109\n",
      "\n",
      "batch: 1/1 in epoch 342/1000 \n",
      "... loss: 0.0002952968643512577\n",
      "\n",
      "batch: 1/1 in epoch 343/1000 \n",
      "... loss: 0.00029330907273106277\n",
      "\n",
      "batch: 1/1 in epoch 344/1000 \n",
      "... loss: 0.0002913361240644008\n",
      "\n",
      "batch: 1/1 in epoch 345/1000 \n",
      "... loss: 0.00028937796014361084\n",
      "\n",
      "batch: 1/1 in epoch 346/1000 \n",
      "... loss: 0.00028743952861987054\n",
      "\n",
      "batch: 1/1 in epoch 347/1000 \n",
      "... loss: 0.0002855136408470571\n",
      "\n",
      "batch: 1/1 in epoch 348/1000 \n",
      "... loss: 0.0002836052735801786\n",
      "\n",
      "batch: 1/1 in epoch 349/1000 \n",
      "... loss: 0.0002817093045450747\n",
      "\n",
      "batch: 1/1 in epoch 350/1000 \n",
      "... loss: 0.00027982768369838595\n",
      "\n",
      "batch: 1/1 in epoch 351/1000 \n",
      "... loss: 0.0002779642818495631\n",
      "\n",
      "batch: 1/1 in epoch 352/1000 \n",
      "... loss: 0.00027611604309640825\n",
      "\n",
      "batch: 1/1 in epoch 353/1000 \n",
      "... loss: 0.00027427886379882693\n",
      "\n",
      "batch: 1/1 in epoch 354/1000 \n",
      "... loss: 0.0002724596415646374\n",
      "\n",
      "batch: 1/1 in epoch 355/1000 \n",
      "... loss: 0.0002706533414311707\n",
      "\n",
      "batch: 1/1 in epoch 356/1000 \n",
      "... loss: 0.000268862844677642\n",
      "\n",
      "batch: 1/1 in epoch 357/1000 \n",
      "... loss: 0.00026708506629802287\n",
      "\n",
      "batch: 1/1 in epoch 358/1000 \n",
      "... loss: 0.00026532390620559454\n",
      "\n",
      "batch: 1/1 in epoch 359/1000 \n",
      "... loss: 0.0002635733690112829\n",
      "\n",
      "batch: 1/1 in epoch 360/1000 \n",
      "... loss: 0.00026183732552453876\n",
      "\n",
      "batch: 1/1 in epoch 361/1000 \n",
      "... loss: 0.00026011854060925543\n",
      "\n",
      "batch: 1/1 in epoch 362/1000 \n",
      "... loss: 0.00025841023307293653\n",
      "\n",
      "batch: 1/1 in epoch 363/1000 \n",
      "... loss: 0.00025671516777947545\n",
      "\n",
      "batch: 1/1 in epoch 364/1000 \n",
      "... loss: 0.0002550352073740214\n",
      "\n",
      "batch: 1/1 in epoch 365/1000 \n",
      "... loss: 0.00025336837279610336\n",
      "\n",
      "batch: 1/1 in epoch 366/1000 \n",
      "... loss: 0.00025171643937937915\n",
      "\n",
      "batch: 1/1 in epoch 367/1000 \n",
      "... loss: 0.00025007178192026913\n",
      "\n",
      "batch: 1/1 in epoch 368/1000 \n",
      "... loss: 0.0002484466240275651\n",
      "\n",
      "batch: 1/1 in epoch 369/1000 \n",
      "... loss: 0.0002468323800712824\n",
      "\n",
      "batch: 1/1 in epoch 370/1000 \n",
      "... loss: 0.00024522992316633463\n",
      "\n",
      "batch: 1/1 in epoch 371/1000 \n",
      "... loss: 0.00024363827833440155\n",
      "\n",
      "batch: 1/1 in epoch 372/1000 \n",
      "... loss: 0.00024206294619943947\n",
      "\n",
      "batch: 1/1 in epoch 373/1000 \n",
      "... loss: 0.00024049918283708394\n",
      "\n",
      "batch: 1/1 in epoch 374/1000 \n",
      "... loss: 0.00023894786136224866\n",
      "\n",
      "batch: 1/1 in epoch 375/1000 \n",
      "... loss: 0.00023740615870337933\n",
      "\n",
      "batch: 1/1 in epoch 376/1000 \n",
      "... loss: 0.0002358813362661749\n",
      "\n",
      "batch: 1/1 in epoch 377/1000 \n",
      "... loss: 0.00023436507035512477\n",
      "\n",
      "batch: 1/1 in epoch 378/1000 \n",
      "... loss: 0.00023286188661586493\n",
      "\n",
      "batch: 1/1 in epoch 379/1000 \n",
      "... loss: 0.00023137079551815987\n",
      "\n",
      "batch: 1/1 in epoch 380/1000 \n",
      "... loss: 0.00022989082208368927\n",
      "\n",
      "batch: 1/1 in epoch 381/1000 \n",
      "... loss: 0.000228421893552877\n",
      "\n",
      "batch: 1/1 in epoch 382/1000 \n",
      "... loss: 0.0002269657707074657\n",
      "\n",
      "batch: 1/1 in epoch 383/1000 \n",
      "... loss: 0.0002255214494653046\n",
      "\n",
      "batch: 1/1 in epoch 384/1000 \n",
      "... loss: 0.00022408709628507495\n",
      "\n",
      "batch: 1/1 in epoch 385/1000 \n",
      "... loss: 0.0002226653159596026\n",
      "\n",
      "batch: 1/1 in epoch 386/1000 \n",
      "... loss: 0.00022125338728073984\n",
      "\n",
      "batch: 1/1 in epoch 387/1000 \n",
      "... loss: 0.00021985213970765471\n",
      "\n",
      "batch: 1/1 in epoch 388/1000 \n",
      "... loss: 0.00021846414892934263\n",
      "\n",
      "batch: 1/1 in epoch 389/1000 \n",
      "... loss: 0.0002170867082895711\n",
      "\n",
      "batch: 1/1 in epoch 390/1000 \n",
      "... loss: 0.00021571711113210768\n",
      "\n",
      "batch: 1/1 in epoch 391/1000 \n",
      "... loss: 0.0002143588353646919\n",
      "\n",
      "batch: 1/1 in epoch 392/1000 \n",
      "... loss: 0.00021301268134266138\n",
      "\n",
      "batch: 1/1 in epoch 393/1000 \n",
      "... loss: 0.00021167770319152623\n",
      "\n",
      "batch: 1/1 in epoch 394/1000 \n",
      "... loss: 0.00021035296958871186\n",
      "\n",
      "batch: 1/1 in epoch 395/1000 \n",
      "... loss: 0.00020903756376355886\n",
      "\n",
      "batch: 1/1 in epoch 396/1000 \n",
      "... loss: 0.0002077314566122368\n",
      "\n",
      "batch: 1/1 in epoch 397/1000 \n",
      "... loss: 0.0002064371365122497\n",
      "\n",
      "batch: 1/1 in epoch 398/1000 \n",
      "... loss: 0.0002051519841188565\n",
      "\n",
      "batch: 1/1 in epoch 399/1000 \n",
      "... loss: 0.00020387764379847795\n",
      "\n",
      "batch: 1/1 in epoch 400/1000 \n",
      "... loss: 0.0002026106812991202\n",
      "\n",
      "batch: 1/1 in epoch 401/1000 \n",
      "... loss: 0.000201356117031537\n",
      "\n",
      "batch: 1/1 in epoch 402/1000 \n",
      "... loss: 0.00020011050219181925\n",
      "\n",
      "batch: 1/1 in epoch 403/1000 \n",
      "... loss: 0.00019887548114638776\n",
      "\n",
      "batch: 1/1 in epoch 404/1000 \n",
      "... loss: 0.00019764932221733034\n",
      "\n",
      "batch: 1/1 in epoch 405/1000 \n",
      "... loss: 0.0001964327966561541\n",
      "\n",
      "batch: 1/1 in epoch 406/1000 \n",
      "... loss: 0.00019522335787769407\n",
      "\n",
      "batch: 1/1 in epoch 407/1000 \n",
      "... loss: 0.00019402428006287664\n",
      "\n",
      "batch: 1/1 in epoch 408/1000 \n",
      "... loss: 0.00019283553410787135\n",
      "\n",
      "batch: 1/1 in epoch 409/1000 \n",
      "... loss: 0.00019165538833476603\n",
      "\n",
      "batch: 1/1 in epoch 410/1000 \n",
      "... loss: 0.00019048381363973022\n",
      "\n",
      "batch: 1/1 in epoch 411/1000 \n",
      "... loss: 0.00018931909289676696\n",
      "\n",
      "batch: 1/1 in epoch 412/1000 \n",
      "... loss: 0.00018816938973031938\n",
      "\n",
      "batch: 1/1 in epoch 413/1000 \n",
      "... loss: 0.00018702319357544184\n",
      "\n",
      "batch: 1/1 in epoch 414/1000 \n",
      "... loss: 0.0001858870091382414\n",
      "\n",
      "batch: 1/1 in epoch 415/1000 \n",
      "... loss: 0.00018476076365914196\n",
      "\n",
      "batch: 1/1 in epoch 416/1000 \n",
      "... loss: 0.000183642769115977\n",
      "\n",
      "batch: 1/1 in epoch 417/1000 \n",
      "... loss: 0.00018253141024615616\n",
      "\n",
      "batch: 1/1 in epoch 418/1000 \n",
      "... loss: 0.00018142983026336879\n",
      "\n",
      "batch: 1/1 in epoch 419/1000 \n",
      "... loss: 0.00018033479864243418\n",
      "\n",
      "batch: 1/1 in epoch 420/1000 \n",
      "... loss: 0.0001792494731489569\n",
      "\n",
      "batch: 1/1 in epoch 421/1000 \n",
      "... loss: 0.00017817298066802323\n",
      "\n",
      "batch: 1/1 in epoch 422/1000 \n",
      "... loss: 0.00017710606334730983\n",
      "\n",
      "batch: 1/1 in epoch 423/1000 \n",
      "... loss: 0.0001760439481586218\n",
      "\n",
      "batch: 1/1 in epoch 424/1000 \n",
      "... loss: 0.00017498974921181798\n",
      "\n",
      "batch: 1/1 in epoch 425/1000 \n",
      "... loss: 0.00017394580936525017\n",
      "\n",
      "batch: 1/1 in epoch 426/1000 \n",
      "... loss: 0.00017290654068347067\n",
      "\n",
      "batch: 1/1 in epoch 427/1000 \n",
      "... loss: 0.00017187742923852056\n",
      "\n",
      "batch: 1/1 in epoch 428/1000 \n",
      "... loss: 0.00017085605941247195\n",
      "\n",
      "batch: 1/1 in epoch 429/1000 \n",
      "... loss: 0.00016984161629807204\n",
      "\n",
      "batch: 1/1 in epoch 430/1000 \n",
      "... loss: 0.00016883484204299748\n",
      "\n",
      "batch: 1/1 in epoch 431/1000 \n",
      "... loss: 0.00016783647879492491\n",
      "\n",
      "batch: 1/1 in epoch 432/1000 \n",
      "... loss: 0.00016684566799085587\n",
      "\n",
      "batch: 1/1 in epoch 433/1000 \n",
      "... loss: 0.00016586011042818427\n",
      "\n",
      "batch: 1/1 in epoch 434/1000 \n",
      "... loss: 0.00016488358960486948\n",
      "\n",
      "batch: 1/1 in epoch 435/1000 \n",
      "... loss: 0.00016391149256378412\n",
      "\n",
      "batch: 1/1 in epoch 436/1000 \n",
      "... loss: 0.00016294985834974796\n",
      "\n",
      "batch: 1/1 in epoch 437/1000 \n",
      "... loss: 0.00016199410310946405\n",
      "\n",
      "batch: 1/1 in epoch 438/1000 \n",
      "... loss: 0.00016104569658637047\n",
      "\n",
      "batch: 1/1 in epoch 439/1000 \n",
      "... loss: 0.00016010459512472153\n",
      "\n",
      "batch: 1/1 in epoch 440/1000 \n",
      "... loss: 0.00015916925622150302\n",
      "\n",
      "batch: 1/1 in epoch 441/1000 \n",
      "... loss: 0.00015824190631974488\n",
      "\n",
      "batch: 1/1 in epoch 442/1000 \n",
      "... loss: 0.00015732174506410956\n",
      "\n",
      "batch: 1/1 in epoch 443/1000 \n",
      "... loss: 0.00015640800120308995\n",
      "\n",
      "batch: 1/1 in epoch 444/1000 \n",
      "... loss: 0.00015549990348517895\n",
      "\n",
      "batch: 1/1 in epoch 445/1000 \n",
      "... loss: 0.00015459962014574558\n",
      "\n",
      "batch: 1/1 in epoch 446/1000 \n",
      "... loss: 0.00015370416804216802\n",
      "\n",
      "batch: 1/1 in epoch 447/1000 \n",
      "... loss: 0.00015281501691788435\n",
      "\n",
      "batch: 1/1 in epoch 448/1000 \n",
      "... loss: 0.0001519335783086717\n",
      "\n",
      "batch: 1/1 in epoch 449/1000 \n",
      "... loss: 0.000151059080963023\n",
      "\n",
      "batch: 1/1 in epoch 450/1000 \n",
      "... loss: 0.00015019149577710778\n",
      "\n",
      "batch: 1/1 in epoch 451/1000 \n",
      "... loss: 0.00014932930935174227\n",
      "\n",
      "batch: 1/1 in epoch 452/1000 \n",
      "... loss: 0.00014847108104731888\n",
      "\n",
      "batch: 1/1 in epoch 453/1000 \n",
      "... loss: 0.000147623271914199\n",
      "\n",
      "batch: 1/1 in epoch 454/1000 \n",
      "... loss: 0.0001467793481424451\n",
      "\n",
      "batch: 1/1 in epoch 455/1000 \n",
      "... loss: 0.0001459399936720729\n",
      "\n",
      "batch: 1/1 in epoch 456/1000 \n",
      "... loss: 0.00014510878827422857\n",
      "\n",
      "batch: 1/1 in epoch 457/1000 \n",
      "... loss: 0.00014428282156586647\n",
      "\n",
      "batch: 1/1 in epoch 458/1000 \n",
      "... loss: 0.00014346207899507135\n",
      "\n",
      "batch: 1/1 in epoch 459/1000 \n",
      "... loss: 0.0001426493690814823\n",
      "\n",
      "batch: 1/1 in epoch 460/1000 \n",
      "... loss: 0.00014184181054588407\n",
      "\n",
      "batch: 1/1 in epoch 461/1000 \n",
      "... loss: 0.00014103864668868482\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 462/1000 \n",
      "... loss: 0.0001402420166414231\n",
      "\n",
      "batch: 1/1 in epoch 463/1000 \n",
      "... loss: 0.0001394497521687299\n",
      "\n",
      "batch: 1/1 in epoch 464/1000 \n",
      "... loss: 0.00013866534573026001\n",
      "\n",
      "batch: 1/1 in epoch 465/1000 \n",
      "... loss: 0.00013788454816676676\n",
      "\n",
      "batch: 1/1 in epoch 466/1000 \n",
      "... loss: 0.00013711083738598973\n",
      "\n",
      "batch: 1/1 in epoch 467/1000 \n",
      "... loss: 0.0001363421033602208\n",
      "\n",
      "batch: 1/1 in epoch 468/1000 \n",
      "... loss: 0.0001355776039417833\n",
      "\n",
      "batch: 1/1 in epoch 469/1000 \n",
      "... loss: 0.0001348207879345864\n",
      "\n",
      "batch: 1/1 in epoch 470/1000 \n",
      "... loss: 0.0001340674643870443\n",
      "\n",
      "batch: 1/1 in epoch 471/1000 \n",
      "... loss: 0.00013331901573110372\n",
      "\n",
      "batch: 1/1 in epoch 472/1000 \n",
      "... loss: 0.00013257678074296564\n",
      "\n",
      "batch: 1/1 in epoch 473/1000 \n",
      "... loss: 0.00013184003182686865\n",
      "\n",
      "batch: 1/1 in epoch 474/1000 \n",
      "... loss: 0.00013110738655086607\n",
      "\n",
      "batch: 1/1 in epoch 475/1000 \n",
      "... loss: 0.0001303829048993066\n",
      "\n",
      "batch: 1/1 in epoch 476/1000 \n",
      "... loss: 0.0001296597474720329\n",
      "\n",
      "batch: 1/1 in epoch 477/1000 \n",
      "... loss: 0.00012894267274532467\n",
      "\n",
      "batch: 1/1 in epoch 478/1000 \n",
      "... loss: 0.00012823095312342048\n",
      "\n",
      "batch: 1/1 in epoch 479/1000 \n",
      "... loss: 0.0001275239046663046\n",
      "\n",
      "batch: 1/1 in epoch 480/1000 \n",
      "... loss: 0.00012682216765824705\n",
      "\n",
      "batch: 1/1 in epoch 481/1000 \n",
      "... loss: 0.0001261263678316027\n",
      "\n",
      "batch: 1/1 in epoch 482/1000 \n",
      "... loss: 0.00012543382763396949\n",
      "\n",
      "batch: 1/1 in epoch 483/1000 \n",
      "... loss: 0.0001247465261258185\n",
      "\n",
      "batch: 1/1 in epoch 484/1000 \n",
      "... loss: 0.00012406376481521875\n",
      "\n",
      "batch: 1/1 in epoch 485/1000 \n",
      "... loss: 0.00012338485976215452\n",
      "\n",
      "batch: 1/1 in epoch 486/1000 \n",
      "... loss: 0.00012271244486328214\n",
      "\n",
      "batch: 1/1 in epoch 487/1000 \n",
      "... loss: 0.0001220431731780991\n",
      "\n",
      "batch: 1/1 in epoch 488/1000 \n",
      "... loss: 0.0001213803407154046\n",
      "\n",
      "batch: 1/1 in epoch 489/1000 \n",
      "... loss: 0.00012072061508661136\n",
      "\n",
      "batch: 1/1 in epoch 490/1000 \n",
      "... loss: 0.00012006399629171938\n",
      "\n",
      "batch: 1/1 in epoch 491/1000 \n",
      "... loss: 0.00011941308184759691\n",
      "\n",
      "batch: 1/1 in epoch 492/1000 \n",
      "... loss: 0.00011876782809849828\n",
      "\n",
      "batch: 1/1 in epoch 493/1000 \n",
      "... loss: 0.00011812561569968238\n",
      "\n",
      "batch: 1/1 in epoch 494/1000 \n",
      "... loss: 0.00011748902034014463\n",
      "\n",
      "batch: 1/1 in epoch 495/1000 \n",
      "... loss: 0.00011685543722705916\n",
      "\n",
      "batch: 1/1 in epoch 496/1000 \n",
      "... loss: 0.00011622806778177619\n",
      "\n",
      "batch: 1/1 in epoch 497/1000 \n",
      "... loss: 0.0001156023790827021\n",
      "\n",
      "batch: 1/1 in epoch 498/1000 \n",
      "... loss: 0.00011498157982714474\n",
      "\n",
      "batch: 1/1 in epoch 499/1000 \n",
      "... loss: 0.0001143662811955437\n",
      "\n",
      "batch: 1/1 in epoch 500/1000 \n",
      "... loss: 0.00011375390022294596\n",
      "\n",
      "batch: 1/1 in epoch 501/1000 \n",
      "... loss: 0.00011314506264170632\n",
      "\n",
      "batch: 1/1 in epoch 502/1000 \n",
      "... loss: 0.00011254165292484686\n",
      "\n",
      "batch: 1/1 in epoch 503/1000 \n",
      "... loss: 0.00011194175021955743\n",
      "\n",
      "batch: 1/1 in epoch 504/1000 \n",
      "... loss: 0.00011134596570627764\n",
      "\n",
      "batch: 1/1 in epoch 505/1000 \n",
      "... loss: 0.00011075428483309224\n",
      "\n",
      "batch: 1/1 in epoch 506/1000 \n",
      "... loss: 0.00011016792996088043\n",
      "\n",
      "batch: 1/1 in epoch 507/1000 \n",
      "... loss: 0.00010958188067888841\n",
      "\n",
      "batch: 1/1 in epoch 508/1000 \n",
      "... loss: 0.00010900237248279154\n",
      "\n",
      "batch: 1/1 in epoch 509/1000 \n",
      "... loss: 0.00010842688789125532\n",
      "\n",
      "batch: 1/1 in epoch 510/1000 \n",
      "... loss: 0.00010785416088765487\n",
      "\n",
      "batch: 1/1 in epoch 511/1000 \n",
      "... loss: 0.00010728480265242979\n",
      "\n",
      "batch: 1/1 in epoch 512/1000 \n",
      "... loss: 0.00010672065400285646\n",
      "\n",
      "batch: 1/1 in epoch 513/1000 \n",
      "... loss: 0.00010615859355311841\n",
      "\n",
      "batch: 1/1 in epoch 514/1000 \n",
      "... loss: 0.00010560292867012322\n",
      "\n",
      "batch: 1/1 in epoch 515/1000 \n",
      "... loss: 0.00010504748934181407\n",
      "\n",
      "batch: 1/1 in epoch 516/1000 \n",
      "... loss: 0.00010449596447870135\n",
      "\n",
      "batch: 1/1 in epoch 517/1000 \n",
      "... loss: 0.00010395074787084013\n",
      "\n",
      "batch: 1/1 in epoch 518/1000 \n",
      "... loss: 0.00010340816515963525\n",
      "\n",
      "batch: 1/1 in epoch 519/1000 \n",
      "... loss: 0.00010286820906912908\n",
      "\n",
      "batch: 1/1 in epoch 520/1000 \n",
      "... loss: 0.00010233208740828559\n",
      "\n",
      "batch: 1/1 in epoch 521/1000 \n",
      "... loss: 0.0001017997637973167\n",
      "\n",
      "batch: 1/1 in epoch 522/1000 \n",
      "... loss: 0.0001012712309602648\n",
      "\n",
      "batch: 1/1 in epoch 523/1000 \n",
      "... loss: 0.00010074466990772635\n",
      "\n",
      "batch: 1/1 in epoch 524/1000 \n",
      "... loss: 0.00010022366041084751\n",
      "\n",
      "batch: 1/1 in epoch 525/1000 \n",
      "... loss: 9.970400424208492e-05\n",
      "\n",
      "batch: 1/1 in epoch 526/1000 \n",
      "... loss: 9.91892593447119e-05\n",
      "\n",
      "batch: 1/1 in epoch 527/1000 \n",
      "... loss: 9.867762128124014e-05\n",
      "\n",
      "batch: 1/1 in epoch 528/1000 \n",
      "... loss: 9.81678967946209e-05\n",
      "\n",
      "batch: 1/1 in epoch 529/1000 \n",
      "... loss: 9.766243601916358e-05\n",
      "\n",
      "batch: 1/1 in epoch 530/1000 \n",
      "... loss: 9.716004569781944e-05\n",
      "\n",
      "batch: 1/1 in epoch 531/1000 \n",
      "... loss: 9.666188270784914e-05\n",
      "\n",
      "batch: 1/1 in epoch 532/1000 \n",
      "... loss: 9.616558236302808e-05\n",
      "\n",
      "batch: 1/1 in epoch 533/1000 \n",
      "... loss: 9.567288361722603e-05\n",
      "\n",
      "batch: 1/1 in epoch 534/1000 \n",
      "... loss: 9.518262231722474e-05\n",
      "\n",
      "batch: 1/1 in epoch 535/1000 \n",
      "... loss: 9.469709766563028e-05\n",
      "\n",
      "batch: 1/1 in epoch 536/1000 \n",
      "... loss: 9.42139740800485e-05\n",
      "\n",
      "batch: 1/1 in epoch 537/1000 \n",
      "... loss: 9.373381908517331e-05\n",
      "\n",
      "batch: 1/1 in epoch 538/1000 \n",
      "... loss: 9.325603605248034e-05\n",
      "\n",
      "batch: 1/1 in epoch 539/1000 \n",
      "... loss: 9.278176730731502e-05\n",
      "\n",
      "batch: 1/1 in epoch 540/1000 \n",
      "... loss: 9.231100557371974e-05\n",
      "\n",
      "batch: 1/1 in epoch 541/1000 \n",
      "... loss: 9.18420118978247e-05\n",
      "\n",
      "batch: 1/1 in epoch 542/1000 \n",
      "... loss: 9.137705637840554e-05\n",
      "\n",
      "batch: 1/1 in epoch 543/1000 \n",
      "... loss: 9.091498941415921e-05\n",
      "\n",
      "batch: 1/1 in epoch 544/1000 \n",
      "... loss: 9.045522892847657e-05\n",
      "\n",
      "batch: 1/1 in epoch 545/1000 \n",
      "... loss: 8.999832789413631e-05\n",
      "\n",
      "batch: 1/1 in epoch 546/1000 \n",
      "... loss: 8.9545406808611e-05\n",
      "\n",
      "batch: 1/1 in epoch 547/1000 \n",
      "... loss: 8.909418829716742e-05\n",
      "\n",
      "batch: 1/1 in epoch 548/1000 \n",
      "... loss: 8.864747360348701e-05\n",
      "\n",
      "batch: 1/1 in epoch 549/1000 \n",
      "... loss: 8.820020593702793e-05\n",
      "\n",
      "batch: 1/1 in epoch 550/1000 \n",
      "... loss: 8.775909373071045e-05\n",
      "\n",
      "batch: 1/1 in epoch 551/1000 \n",
      "... loss: 8.731908746995032e-05\n",
      "\n",
      "batch: 1/1 in epoch 552/1000 \n",
      "... loss: 8.688186062499881e-05\n",
      "\n",
      "batch: 1/1 in epoch 553/1000 \n",
      "... loss: 8.644849731354043e-05\n",
      "\n",
      "batch: 1/1 in epoch 554/1000 \n",
      "... loss: 8.60173167893663e-05\n",
      "\n",
      "batch: 1/1 in epoch 555/1000 \n",
      "... loss: 8.558777335565537e-05\n",
      "\n",
      "batch: 1/1 in epoch 556/1000 \n",
      "... loss: 8.516039815731347e-05\n",
      "\n",
      "batch: 1/1 in epoch 557/1000 \n",
      "... loss: 8.473848720313981e-05\n",
      "\n",
      "batch: 1/1 in epoch 558/1000 \n",
      "... loss: 8.431652531726286e-05\n",
      "\n",
      "batch: 1/1 in epoch 559/1000 \n",
      "... loss: 8.389889990212396e-05\n",
      "\n",
      "batch: 1/1 in epoch 560/1000 \n",
      "... loss: 8.348339179065078e-05\n",
      "\n",
      "batch: 1/1 in epoch 561/1000 \n",
      "... loss: 8.306892414111644e-05\n",
      "\n",
      "batch: 1/1 in epoch 562/1000 \n",
      "... loss: 8.265927317552269e-05\n",
      "\n",
      "batch: 1/1 in epoch 563/1000 \n",
      "... loss: 8.225172496167943e-05\n",
      "\n",
      "batch: 1/1 in epoch 564/1000 \n",
      "... loss: 8.184355829143897e-05\n",
      "\n",
      "batch: 1/1 in epoch 565/1000 \n",
      "... loss: 8.144124876707792e-05\n",
      "\n",
      "batch: 1/1 in epoch 566/1000 \n",
      "... loss: 8.10410056146793e-05\n",
      "\n",
      "batch: 1/1 in epoch 567/1000 \n",
      "... loss: 8.064228313742206e-05\n",
      "\n",
      "batch: 1/1 in epoch 568/1000 \n",
      "... loss: 8.0245612480212e-05\n",
      "\n",
      "batch: 1/1 in epoch 569/1000 \n",
      "... loss: 7.985311822267249e-05\n",
      "\n",
      "batch: 1/1 in epoch 570/1000 \n",
      "... loss: 7.946263940539211e-05\n",
      "\n",
      "batch: 1/1 in epoch 571/1000 \n",
      "... loss: 7.907312829047441e-05\n",
      "\n",
      "batch: 1/1 in epoch 572/1000 \n",
      "... loss: 7.868561806390062e-05\n",
      "\n",
      "batch: 1/1 in epoch 573/1000 \n",
      "... loss: 7.830224058125168e-05\n",
      "\n",
      "batch: 1/1 in epoch 574/1000 \n",
      "... loss: 7.792136602802202e-05\n",
      "\n",
      "batch: 1/1 in epoch 575/1000 \n",
      "... loss: 7.754195394227281e-05\n",
      "\n",
      "batch: 1/1 in epoch 576/1000 \n",
      "... loss: 7.716398249613121e-05\n",
      "\n",
      "batch: 1/1 in epoch 577/1000 \n",
      "... loss: 7.678955444134772e-05\n",
      "\n",
      "batch: 1/1 in epoch 578/1000 \n",
      "... loss: 7.641602860530838e-05\n",
      "\n",
      "batch: 1/1 in epoch 579/1000 \n",
      "... loss: 7.604550046380609e-05\n",
      "\n",
      "batch: 1/1 in epoch 580/1000 \n",
      "... loss: 7.567794091301039e-05\n",
      "\n",
      "batch: 1/1 in epoch 581/1000 \n",
      "... loss: 7.531127630500123e-05\n",
      "\n",
      "batch: 1/1 in epoch 582/1000 \n",
      "... loss: 7.494756573578343e-05\n",
      "\n",
      "batch: 1/1 in epoch 583/1000 \n",
      "... loss: 7.458679465344176e-05\n",
      "\n",
      "batch: 1/1 in epoch 584/1000 \n",
      "... loss: 7.422586350003257e-05\n",
      "\n",
      "batch: 1/1 in epoch 585/1000 \n",
      "... loss: 7.386888319160789e-05\n",
      "\n",
      "batch: 1/1 in epoch 586/1000 \n",
      "... loss: 7.351378008024767e-05\n",
      "\n",
      "batch: 1/1 in epoch 587/1000 \n",
      "... loss: 7.316056144190952e-05\n",
      "\n",
      "batch: 1/1 in epoch 588/1000 \n",
      "... loss: 7.280869613168761e-05\n",
      "\n",
      "batch: 1/1 in epoch 589/1000 \n",
      "... loss: 7.246022141771391e-05\n",
      "\n",
      "batch: 1/1 in epoch 590/1000 \n",
      "... loss: 7.211206684587523e-05\n",
      "\n",
      "batch: 1/1 in epoch 591/1000 \n",
      "... loss: 7.17682924005203e-05\n",
      "\n",
      "batch: 1/1 in epoch 592/1000 \n",
      "... loss: 7.142483809730038e-05\n",
      "\n",
      "batch: 1/1 in epoch 593/1000 \n",
      "... loss: 7.108421414159238e-05\n",
      "\n",
      "batch: 1/1 in epoch 594/1000 \n",
      "... loss: 7.074540917528793e-05\n",
      "\n",
      "batch: 1/1 in epoch 595/1000 \n",
      "... loss: 7.04084086464718e-05\n",
      "\n",
      "batch: 1/1 in epoch 596/1000 \n",
      "... loss: 7.007171370787546e-05\n",
      "\n",
      "batch: 1/1 in epoch 597/1000 \n",
      "... loss: 6.973881681915373e-05\n",
      "\n",
      "batch: 1/1 in epoch 598/1000 \n",
      "... loss: 6.940820458112285e-05\n",
      "\n",
      "batch: 1/1 in epoch 599/1000 \n",
      "... loss: 6.907936040079221e-05\n",
      "\n",
      "batch: 1/1 in epoch 600/1000 \n",
      "... loss: 6.875179678900167e-05\n",
      "\n",
      "batch: 1/1 in epoch 601/1000 \n",
      "... loss: 6.84269834891893e-05\n",
      "\n",
      "batch: 1/1 in epoch 602/1000 \n",
      "... loss: 6.810244667576626e-05\n",
      "\n",
      "batch: 1/1 in epoch 603/1000 \n",
      "... loss: 6.778015085728839e-05\n",
      "\n",
      "batch: 1/1 in epoch 604/1000 \n",
      "... loss: 6.74620532663539e-05\n",
      "\n",
      "batch: 1/1 in epoch 605/1000 \n",
      "... loss: 6.714226037729532e-05\n",
      "\n",
      "batch: 1/1 in epoch 606/1000 \n",
      "... loss: 6.682711682515219e-05\n",
      "\n",
      "batch: 1/1 in epoch 607/1000 \n",
      "... loss: 6.651174771832302e-05\n",
      "\n",
      "batch: 1/1 in epoch 608/1000 \n",
      "... loss: 6.620100612053648e-05\n",
      "\n",
      "batch: 1/1 in epoch 609/1000 \n",
      "... loss: 6.588905671378598e-05\n",
      "\n",
      "batch: 1/1 in epoch 610/1000 \n",
      "... loss: 6.558073800988495e-05\n",
      "\n",
      "batch: 1/1 in epoch 611/1000 \n",
      "... loss: 6.527314690174535e-05\n",
      "\n",
      "batch: 1/1 in epoch 612/1000 \n",
      "... loss: 6.496723653981462e-05\n",
      "\n",
      "batch: 1/1 in epoch 613/1000 \n",
      "... loss: 6.466299237217754e-05\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 614/1000 \n",
      "... loss: 6.436138937715441e-05\n",
      "\n",
      "batch: 1/1 in epoch 615/1000 \n",
      "... loss: 6.406144530046731e-05\n",
      "\n",
      "batch: 1/1 in epoch 616/1000 \n",
      "... loss: 6.376314559020102e-05\n",
      "\n",
      "batch: 1/1 in epoch 617/1000 \n",
      "... loss: 6.346649752231315e-05\n",
      "\n",
      "batch: 1/1 in epoch 618/1000 \n",
      "... loss: 6.317054067039862e-05\n",
      "\n",
      "batch: 1/1 in epoch 619/1000 \n",
      "... loss: 6.287716678343713e-05\n",
      "\n",
      "batch: 1/1 in epoch 620/1000 \n",
      "... loss: 6.258588837226853e-05\n",
      "\n",
      "batch: 1/1 in epoch 621/1000 \n",
      "... loss: 6.229528662515804e-05\n",
      "\n",
      "batch: 1/1 in epoch 622/1000 \n",
      "... loss: 6.200582720339298e-05\n",
      "\n",
      "batch: 1/1 in epoch 623/1000 \n",
      "... loss: 6.171985296532512e-05\n",
      "\n",
      "batch: 1/1 in epoch 624/1000 \n",
      "... loss: 6.143360951682553e-05\n",
      "\n",
      "batch: 1/1 in epoch 625/1000 \n",
      "... loss: 6.115082214819267e-05\n",
      "\n",
      "batch: 1/1 in epoch 626/1000 \n",
      "... loss: 6.086776193114929e-05\n",
      "\n",
      "batch: 1/1 in epoch 627/1000 \n",
      "... loss: 6.0588139604078606e-05\n",
      "\n",
      "batch: 1/1 in epoch 628/1000 \n",
      "... loss: 6.030823351466097e-05\n",
      "\n",
      "batch: 1/1 in epoch 629/1000 \n",
      "... loss: 6.0030826716683805e-05\n",
      "\n",
      "batch: 1/1 in epoch 630/1000 \n",
      "... loss: 5.975359817966819e-05\n",
      "\n",
      "batch: 1/1 in epoch 631/1000 \n",
      "... loss: 5.948068792349659e-05\n",
      "\n",
      "batch: 1/1 in epoch 632/1000 \n",
      "... loss: 5.9207482991041616e-05\n",
      "\n",
      "batch: 1/1 in epoch 633/1000 \n",
      "... loss: 5.893674097023904e-05\n",
      "\n",
      "batch: 1/1 in epoch 634/1000 \n",
      "... loss: 5.866707215318456e-05\n",
      "\n",
      "batch: 1/1 in epoch 635/1000 \n",
      "... loss: 5.839802179252729e-05\n",
      "\n",
      "batch: 1/1 in epoch 636/1000 \n",
      "... loss: 5.8131408877670765e-05\n",
      "\n",
      "batch: 1/1 in epoch 637/1000 \n",
      "... loss: 5.786586189060472e-05\n",
      "\n",
      "batch: 1/1 in epoch 638/1000 \n",
      "... loss: 5.760091880802065e-05\n",
      "\n",
      "batch: 1/1 in epoch 639/1000 \n",
      "... loss: 5.733929356210865e-05\n",
      "\n",
      "batch: 1/1 in epoch 640/1000 \n",
      "... loss: 5.7077813835348934e-05\n",
      "\n",
      "batch: 1/1 in epoch 641/1000 \n",
      "... loss: 5.681828042725101e-05\n",
      "\n",
      "batch: 1/1 in epoch 642/1000 \n",
      "... loss: 5.655978384311311e-05\n",
      "\n",
      "batch: 1/1 in epoch 643/1000 \n",
      "... loss: 5.630367013509385e-05\n",
      "\n",
      "batch: 1/1 in epoch 644/1000 \n",
      "... loss: 5.6047683756332844e-05\n",
      "\n",
      "batch: 1/1 in epoch 645/1000 \n",
      "... loss: 5.579406933975406e-05\n",
      "\n",
      "batch: 1/1 in epoch 646/1000 \n",
      "... loss: 5.5541469919262454e-05\n",
      "\n",
      "batch: 1/1 in epoch 647/1000 \n",
      "... loss: 5.52903329662513e-05\n",
      "\n",
      "batch: 1/1 in epoch 648/1000 \n",
      "... loss: 5.503975989995524e-05\n",
      "\n",
      "batch: 1/1 in epoch 649/1000 \n",
      "... loss: 5.479152605403215e-05\n",
      "\n",
      "batch: 1/1 in epoch 650/1000 \n",
      "... loss: 5.454385245684534e-05\n",
      "\n",
      "batch: 1/1 in epoch 651/1000 \n",
      "... loss: 5.429849261417985e-05\n",
      "\n",
      "batch: 1/1 in epoch 652/1000 \n",
      "... loss: 5.405456613516435e-05\n",
      "\n",
      "batch: 1/1 in epoch 653/1000 \n",
      "... loss: 5.3811185352969915e-05\n",
      "\n",
      "batch: 1/1 in epoch 654/1000 \n",
      "... loss: 5.356923065846786e-05\n",
      "\n",
      "batch: 1/1 in epoch 655/1000 \n",
      "... loss: 5.332869113772176e-05\n",
      "\n",
      "batch: 1/1 in epoch 656/1000 \n",
      "... loss: 5.308955951477401e-05\n",
      "\n",
      "batch: 1/1 in epoch 657/1000 \n",
      "... loss: 5.285139923216775e-05\n",
      "\n",
      "batch: 1/1 in epoch 658/1000 \n",
      "... loss: 5.26155017723795e-05\n",
      "\n",
      "batch: 1/1 in epoch 659/1000 \n",
      "... loss: 5.237927325651981e-05\n",
      "\n",
      "batch: 1/1 in epoch 660/1000 \n",
      "... loss: 5.214486373006366e-05\n",
      "\n",
      "batch: 1/1 in epoch 661/1000 \n",
      "... loss: 5.191226955503225e-05\n",
      "\n",
      "batch: 1/1 in epoch 662/1000 \n",
      "... loss: 5.1680624892469496e-05\n",
      "\n",
      "batch: 1/1 in epoch 663/1000 \n",
      "... loss: 5.1449922466417775e-05\n",
      "\n",
      "batch: 1/1 in epoch 664/1000 \n",
      "... loss: 5.1220169552834705e-05\n",
      "\n",
      "batch: 1/1 in epoch 665/1000 \n",
      "... loss: 5.099262489238754e-05\n",
      "\n",
      "batch: 1/1 in epoch 666/1000 \n",
      "... loss: 5.0766440836014226e-05\n",
      "\n",
      "batch: 1/1 in epoch 667/1000 \n",
      "... loss: 5.054033681517467e-05\n",
      "\n",
      "batch: 1/1 in epoch 668/1000 \n",
      "... loss: 5.0316004490014166e-05\n",
      "\n",
      "batch: 1/1 in epoch 669/1000 \n",
      "... loss: 5.009258893551305e-05\n",
      "\n",
      "batch: 1/1 in epoch 670/1000 \n",
      "... loss: 4.9871359806274995e-05\n",
      "\n",
      "batch: 1/1 in epoch 671/1000 \n",
      "... loss: 4.9650199798634276e-05\n",
      "\n",
      "batch: 1/1 in epoch 672/1000 \n",
      "... loss: 4.9430367653258145e-05\n",
      "\n",
      "batch: 1/1 in epoch 673/1000 \n",
      "... loss: 4.921269282931462e-05\n",
      "\n",
      "batch: 1/1 in epoch 674/1000 \n",
      "... loss: 4.899508712696843e-05\n",
      "\n",
      "batch: 1/1 in epoch 675/1000 \n",
      "... loss: 4.877837636740878e-05\n",
      "\n",
      "batch: 1/1 in epoch 676/1000 \n",
      "... loss: 4.856256055063568e-05\n",
      "\n",
      "batch: 1/1 in epoch 677/1000 \n",
      "... loss: 4.834929859498516e-05\n",
      "\n",
      "batch: 1/1 in epoch 678/1000 \n",
      "... loss: 4.813650230062194e-05\n",
      "\n",
      "batch: 1/1 in epoch 679/1000 \n",
      "... loss: 4.792459003510885e-05\n",
      "\n",
      "batch: 1/1 in epoch 680/1000 \n",
      "... loss: 4.7713969252072275e-05\n",
      "\n",
      "batch: 1/1 in epoch 681/1000 \n",
      "... loss: 4.750504740513861e-05\n",
      "\n",
      "batch: 1/1 in epoch 682/1000 \n",
      "... loss: 4.729575812234543e-05\n",
      "\n",
      "batch: 1/1 in epoch 683/1000 \n",
      "... loss: 4.708939013653435e-05\n",
      "\n",
      "batch: 1/1 in epoch 684/1000 \n",
      "... loss: 4.688265107688494e-05\n",
      "\n",
      "batch: 1/1 in epoch 685/1000 \n",
      "... loss: 4.66780002170708e-05\n",
      "\n",
      "batch: 1/1 in epoch 686/1000 \n",
      "... loss: 4.647379319067113e-05\n",
      "\n",
      "batch: 1/1 in epoch 687/1000 \n",
      "... loss: 4.627044472726993e-05\n",
      "\n",
      "batch: 1/1 in epoch 688/1000 \n",
      "... loss: 4.60675400972832e-05\n",
      "\n",
      "batch: 1/1 in epoch 689/1000 \n",
      "... loss: 4.586790964822285e-05\n",
      "\n",
      "batch: 1/1 in epoch 690/1000 \n",
      "... loss: 4.5666693040402606e-05\n",
      "\n",
      "batch: 1/1 in epoch 691/1000 \n",
      "... loss: 4.546833224594593e-05\n",
      "\n",
      "batch: 1/1 in epoch 692/1000 \n",
      "... loss: 4.527000055531971e-05\n",
      "\n",
      "batch: 1/1 in epoch 693/1000 \n",
      "... loss: 4.5073305955156684e-05\n",
      "\n",
      "batch: 1/1 in epoch 694/1000 \n",
      "... loss: 4.4878237531520426e-05\n",
      "\n",
      "batch: 1/1 in epoch 695/1000 \n",
      "... loss: 4.4683987653115764e-05\n",
      "\n",
      "batch: 1/1 in epoch 696/1000 \n",
      "... loss: 4.4488970161182806e-05\n",
      "\n",
      "batch: 1/1 in epoch 697/1000 \n",
      "... loss: 4.429636101122014e-05\n",
      "\n",
      "batch: 1/1 in epoch 698/1000 \n",
      "... loss: 4.410495967022143e-05\n",
      "\n",
      "batch: 1/1 in epoch 699/1000 \n",
      "... loss: 4.3913580157095566e-05\n",
      "\n",
      "batch: 1/1 in epoch 700/1000 \n",
      "... loss: 4.3724194256355986e-05\n",
      "\n",
      "batch: 1/1 in epoch 701/1000 \n",
      "... loss: 4.3535608710953966e-05\n",
      "\n",
      "batch: 1/1 in epoch 702/1000 \n",
      "... loss: 4.334743061917834e-05\n",
      "\n",
      "batch: 1/1 in epoch 703/1000 \n",
      "... loss: 4.316004924476147e-05\n",
      "\n",
      "batch: 1/1 in epoch 704/1000 \n",
      "... loss: 4.297385748941451e-05\n",
      "\n",
      "batch: 1/1 in epoch 705/1000 \n",
      "... loss: 4.278885171515867e-05\n",
      "\n",
      "batch: 1/1 in epoch 706/1000 \n",
      "... loss: 4.2604628106346354e-05\n",
      "\n",
      "batch: 1/1 in epoch 707/1000 \n",
      "... loss: 4.2421583202667534e-05\n",
      "\n",
      "batch: 1/1 in epoch 708/1000 \n",
      "... loss: 4.223854193696752e-05\n",
      "\n",
      "batch: 1/1 in epoch 709/1000 \n",
      "... loss: 4.205782897770405e-05\n",
      "\n",
      "batch: 1/1 in epoch 710/1000 \n",
      "... loss: 4.187750528217293e-05\n",
      "\n",
      "batch: 1/1 in epoch 711/1000 \n",
      "... loss: 4.1698338463902473e-05\n",
      "\n",
      "batch: 1/1 in epoch 712/1000 \n",
      "... loss: 4.151878601987846e-05\n",
      "\n",
      "batch: 1/1 in epoch 713/1000 \n",
      "... loss: 4.13411580666434e-05\n",
      "\n",
      "batch: 1/1 in epoch 714/1000 \n",
      "... loss: 4.116467243875377e-05\n",
      "\n",
      "batch: 1/1 in epoch 715/1000 \n",
      "... loss: 4.0988561522681266e-05\n",
      "\n",
      "batch: 1/1 in epoch 716/1000 \n",
      "... loss: 4.081321458215825e-05\n",
      "\n",
      "batch: 1/1 in epoch 717/1000 \n",
      "... loss: 4.063975939061493e-05\n",
      "\n",
      "batch: 1/1 in epoch 718/1000 \n",
      "... loss: 4.046591857331805e-05\n",
      "\n",
      "batch: 1/1 in epoch 719/1000 \n",
      "... loss: 4.029282717965543e-05\n",
      "\n",
      "batch: 1/1 in epoch 720/1000 \n",
      "... loss: 4.012161662103608e-05\n",
      "\n",
      "batch: 1/1 in epoch 721/1000 \n",
      "... loss: 3.995152292191051e-05\n",
      "\n",
      "batch: 1/1 in epoch 722/1000 \n",
      "... loss: 3.978066524723545e-05\n",
      "\n",
      "batch: 1/1 in epoch 723/1000 \n",
      "... loss: 3.9612423279322684e-05\n",
      "\n",
      "batch: 1/1 in epoch 724/1000 \n",
      "... loss: 3.9444163121515885e-05\n",
      "\n",
      "batch: 1/1 in epoch 725/1000 \n",
      "... loss: 3.927625948563218e-05\n",
      "\n",
      "batch: 1/1 in epoch 726/1000 \n",
      "... loss: 3.910946179530583e-05\n",
      "\n",
      "batch: 1/1 in epoch 727/1000 \n",
      "... loss: 3.894413384841755e-05\n",
      "\n",
      "batch: 1/1 in epoch 728/1000 \n",
      "... loss: 3.8778784073656425e-05\n",
      "\n",
      "batch: 1/1 in epoch 729/1000 \n",
      "... loss: 3.861527147819288e-05\n",
      "\n",
      "batch: 1/1 in epoch 730/1000 \n",
      "... loss: 3.8452471926575527e-05\n",
      "\n",
      "batch: 1/1 in epoch 731/1000 \n",
      "... loss: 3.828964690910652e-05\n",
      "\n",
      "batch: 1/1 in epoch 732/1000 \n",
      "... loss: 3.8127902371343225e-05\n",
      "\n",
      "batch: 1/1 in epoch 733/1000 \n",
      "... loss: 3.79665034415666e-05\n",
      "\n",
      "batch: 1/1 in epoch 734/1000 \n",
      "... loss: 3.7806908949278295e-05\n",
      "\n",
      "batch: 1/1 in epoch 735/1000 \n",
      "... loss: 3.764801658689976e-05\n",
      "\n",
      "batch: 1/1 in epoch 736/1000 \n",
      "... loss: 3.748982635443099e-05\n",
      "\n",
      "batch: 1/1 in epoch 737/1000 \n",
      "... loss: 3.733197081601247e-05\n",
      "\n",
      "batch: 1/1 in epoch 738/1000 \n",
      "... loss: 3.7174442695686594e-05\n",
      "\n",
      "batch: 1/1 in epoch 739/1000 \n",
      "... loss: 3.7019064620835707e-05\n",
      "\n",
      "batch: 1/1 in epoch 740/1000 \n",
      "... loss: 3.686292620841414e-05\n",
      "\n",
      "batch: 1/1 in epoch 741/1000 \n",
      "... loss: 3.670819933176972e-05\n",
      "\n",
      "batch: 1/1 in epoch 742/1000 \n",
      "... loss: 3.655416003311984e-05\n",
      "\n",
      "batch: 1/1 in epoch 743/1000 \n",
      "... loss: 3.64011648343876e-05\n",
      "\n",
      "batch: 1/1 in epoch 744/1000 \n",
      "... loss: 3.624920645961538e-05\n",
      "\n",
      "batch: 1/1 in epoch 745/1000 \n",
      "... loss: 3.609792111092247e-05\n",
      "\n",
      "batch: 1/1 in epoch 746/1000 \n",
      "... loss: 3.594659938244149e-05\n",
      "\n",
      "batch: 1/1 in epoch 747/1000 \n",
      "... loss: 3.579559415811673e-05\n",
      "\n",
      "batch: 1/1 in epoch 748/1000 \n",
      "... loss: 3.564633152564056e-05\n",
      "\n",
      "batch: 1/1 in epoch 749/1000 \n",
      "... loss: 3.549808752723038e-05\n",
      "\n",
      "batch: 1/1 in epoch 750/1000 \n",
      "... loss: 3.535015639499761e-05\n",
      "\n",
      "batch: 1/1 in epoch 751/1000 \n",
      "... loss: 3.520253085298464e-05\n",
      "\n",
      "batch: 1/1 in epoch 752/1000 \n",
      "... loss: 3.505556742311455e-05\n",
      "\n",
      "batch: 1/1 in epoch 753/1000 \n",
      "... loss: 3.490996823529713e-05\n",
      "\n",
      "batch: 1/1 in epoch 754/1000 \n",
      "... loss: 3.47646746376995e-05\n",
      "\n",
      "batch: 1/1 in epoch 755/1000 \n",
      "... loss: 3.462002860032953e-05\n",
      "\n",
      "batch: 1/1 in epoch 756/1000 \n",
      "... loss: 3.447639028308913e-05\n",
      "\n",
      "batch: 1/1 in epoch 757/1000 \n",
      "... loss: 3.433305028011091e-05\n",
      "\n",
      "batch: 1/1 in epoch 758/1000 \n",
      "... loss: 3.4190703445347026e-05\n",
      "\n",
      "batch: 1/1 in epoch 759/1000 \n",
      "... loss: 3.4048651286866516e-05\n",
      "\n",
      "batch: 1/1 in epoch 760/1000 \n",
      "... loss: 3.390863275853917e-05\n",
      "\n",
      "batch: 1/1 in epoch 761/1000 \n",
      "... loss: 3.376751556061208e-05\n",
      "\n",
      "batch: 1/1 in epoch 762/1000 \n",
      "... loss: 3.362842107890174e-05\n",
      "\n",
      "batch: 1/1 in epoch 763/1000 \n",
      "... loss: 3.348892641952261e-05\n",
      "\n",
      "batch: 1/1 in epoch 764/1000 \n",
      "... loss: 3.335040673846379e-05\n",
      "\n",
      "batch: 1/1 in epoch 765/1000 \n",
      "... loss: 3.321320764371194e-05\n",
      "\n",
      "batch: 1/1 in epoch 766/1000 \n",
      "... loss: 3.3076288673328236e-05\n",
      "\n",
      "batch: 1/1 in epoch 767/1000 \n",
      "... loss: 3.293931149528362e-05\n",
      "\n",
      "batch: 1/1 in epoch 768/1000 \n",
      "... loss: 3.280398595961742e-05\n",
      "\n",
      "batch: 1/1 in epoch 769/1000 \n",
      "... loss: 3.266927524236962e-05\n",
      "\n",
      "batch: 1/1 in epoch 770/1000 \n",
      "... loss: 3.253450631746091e-05\n",
      "\n",
      "batch: 1/1 in epoch 771/1000 \n",
      "... loss: 3.2400690542999655e-05\n",
      "\n",
      "batch: 1/1 in epoch 772/1000 \n",
      "... loss: 3.226681292289868e-05\n",
      "\n",
      "batch: 1/1 in epoch 773/1000 \n",
      "... loss: 3.213490344933234e-05\n",
      "\n",
      "batch: 1/1 in epoch 774/1000 \n",
      "... loss: 3.200292485416867e-05\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 775/1000 \n",
      "... loss: 3.1871895771473646e-05\n",
      "\n",
      "batch: 1/1 in epoch 776/1000 \n",
      "... loss: 3.174079392920248e-05\n",
      "\n",
      "batch: 1/1 in epoch 777/1000 \n",
      "... loss: 3.161130371154286e-05\n",
      "\n",
      "batch: 1/1 in epoch 778/1000 \n",
      "... loss: 3.14817443722859e-05\n",
      "\n",
      "batch: 1/1 in epoch 779/1000 \n",
      "... loss: 3.135311999358237e-05\n",
      "\n",
      "batch: 1/1 in epoch 780/1000 \n",
      "... loss: 3.12244264932815e-05\n",
      "\n",
      "batch: 1/1 in epoch 781/1000 \n",
      "... loss: 3.109666067757644e-05\n",
      "\n",
      "batch: 1/1 in epoch 782/1000 \n",
      "... loss: 3.096915679634549e-05\n",
      "\n",
      "batch: 1/1 in epoch 783/1000 \n",
      "... loss: 3.084390118601732e-05\n",
      "\n",
      "batch: 1/1 in epoch 784/1000 \n",
      "... loss: 3.0717579647898674e-05\n",
      "\n",
      "batch: 1/1 in epoch 785/1000 \n",
      "... loss: 3.059184382436797e-05\n",
      "\n",
      "batch: 1/1 in epoch 786/1000 \n",
      "... loss: 3.0467354008578695e-05\n",
      "\n",
      "batch: 1/1 in epoch 787/1000 \n",
      "... loss: 3.0344102924573235e-05\n",
      "\n",
      "batch: 1/1 in epoch 788/1000 \n",
      "... loss: 3.022012060682755e-05\n",
      "\n",
      "batch: 1/1 in epoch 789/1000 \n",
      "... loss: 3.009671672771219e-05\n",
      "\n",
      "batch: 1/1 in epoch 790/1000 \n",
      "... loss: 2.9974871722515672e-05\n",
      "\n",
      "batch: 1/1 in epoch 791/1000 \n",
      "... loss: 2.9853274099878035e-05\n",
      "\n",
      "batch: 1/1 in epoch 792/1000 \n",
      "... loss: 2.9731598260696046e-05\n",
      "\n",
      "batch: 1/1 in epoch 793/1000 \n",
      "... loss: 2.9611142963403836e-05\n",
      "\n",
      "batch: 1/1 in epoch 794/1000 \n",
      "... loss: 2.9491580789908767e-05\n",
      "\n",
      "batch: 1/1 in epoch 795/1000 \n",
      "... loss: 2.9371936761890538e-05\n",
      "\n",
      "batch: 1/1 in epoch 796/1000 \n",
      "... loss: 2.925253465946298e-05\n",
      "\n",
      "batch: 1/1 in epoch 797/1000 \n",
      "... loss: 2.9134342184988782e-05\n",
      "\n",
      "batch: 1/1 in epoch 798/1000 \n",
      "... loss: 2.9016069674980827e-05\n",
      "\n",
      "batch: 1/1 in epoch 799/1000 \n",
      "... loss: 2.8899317840114236e-05\n",
      "\n",
      "batch: 1/1 in epoch 800/1000 \n",
      "... loss: 2.878152190533001e-05\n",
      "\n",
      "batch: 1/1 in epoch 801/1000 \n",
      "... loss: 2.866588329197839e-05\n",
      "\n",
      "batch: 1/1 in epoch 802/1000 \n",
      "... loss: 2.8549839043989778e-05\n",
      "\n",
      "batch: 1/1 in epoch 803/1000 \n",
      "... loss: 2.84352991002379e-05\n",
      "\n",
      "batch: 1/1 in epoch 804/1000 \n",
      "... loss: 2.8320357159827836e-05\n",
      "\n",
      "batch: 1/1 in epoch 805/1000 \n",
      "... loss: 2.8205964554217644e-05\n",
      "\n",
      "batch: 1/1 in epoch 806/1000 \n",
      "... loss: 2.8092435968574136e-05\n",
      "\n",
      "batch: 1/1 in epoch 807/1000 \n",
      "... loss: 2.7979136575595476e-05\n",
      "\n",
      "batch: 1/1 in epoch 808/1000 \n",
      "... loss: 2.7867323296959512e-05\n",
      "\n",
      "batch: 1/1 in epoch 809/1000 \n",
      "... loss: 2.7754791517509148e-05\n",
      "\n",
      "batch: 1/1 in epoch 810/1000 \n",
      "... loss: 2.7643116482067853e-05\n",
      "\n",
      "batch: 1/1 in epoch 811/1000 \n",
      "... loss: 2.753228909568861e-05\n",
      "\n",
      "batch: 1/1 in epoch 812/1000 \n",
      "... loss: 2.7422311177360825e-05\n",
      "\n",
      "batch: 1/1 in epoch 813/1000 \n",
      "... loss: 2.731224049057346e-05\n",
      "\n",
      "batch: 1/1 in epoch 814/1000 \n",
      "... loss: 2.7203013814869337e-05\n",
      "\n",
      "batch: 1/1 in epoch 815/1000 \n",
      "... loss: 2.7093694370705634e-05\n",
      "\n",
      "batch: 1/1 in epoch 816/1000 \n",
      "... loss: 2.6984596843249165e-05\n",
      "\n",
      "batch: 1/1 in epoch 817/1000 \n",
      "... loss: 2.6876643460127525e-05\n",
      "\n",
      "batch: 1/1 in epoch 818/1000 \n",
      "... loss: 2.6769524993142113e-05\n",
      "\n",
      "batch: 1/1 in epoch 819/1000 \n",
      "... loss: 2.666292857611552e-05\n",
      "\n",
      "batch: 1/1 in epoch 820/1000 \n",
      "... loss: 2.6555624572210945e-05\n",
      "\n",
      "batch: 1/1 in epoch 821/1000 \n",
      "... loss: 2.645006861712318e-05\n",
      "\n",
      "batch: 1/1 in epoch 822/1000 \n",
      "... loss: 2.634441443660762e-05\n",
      "\n",
      "batch: 1/1 in epoch 823/1000 \n",
      "... loss: 2.6238667487632483e-05\n",
      "\n",
      "batch: 1/1 in epoch 824/1000 \n",
      "... loss: 2.613435390230734e-05\n",
      "\n",
      "batch: 1/1 in epoch 825/1000 \n",
      "... loss: 2.6030855224234983e-05\n",
      "\n",
      "batch: 1/1 in epoch 826/1000 \n",
      "... loss: 2.5926650778274052e-05\n",
      "\n",
      "batch: 1/1 in epoch 827/1000 \n",
      "... loss: 2.5823263058555312e-05\n",
      "\n",
      "batch: 1/1 in epoch 828/1000 \n",
      "... loss: 2.572098674136214e-05\n",
      "\n",
      "batch: 1/1 in epoch 829/1000 \n",
      "... loss: 2.561770634201821e-05\n",
      "\n",
      "batch: 1/1 in epoch 830/1000 \n",
      "... loss: 2.5516441382933408e-05\n",
      "\n",
      "batch: 1/1 in epoch 831/1000 \n",
      "... loss: 2.5415078198420815e-05\n",
      "\n",
      "batch: 1/1 in epoch 832/1000 \n",
      "... loss: 2.531451355025638e-05\n",
      "\n",
      "batch: 1/1 in epoch 833/1000 \n",
      "... loss: 2.5213852495653555e-05\n",
      "\n",
      "batch: 1/1 in epoch 834/1000 \n",
      "... loss: 2.5113387891906314e-05\n",
      "\n",
      "batch: 1/1 in epoch 835/1000 \n",
      "... loss: 2.5013720005517825e-05\n",
      "\n",
      "batch: 1/1 in epoch 836/1000 \n",
      "... loss: 2.491544364602305e-05\n",
      "\n",
      "batch: 1/1 in epoch 837/1000 \n",
      "... loss: 2.481676528987009e-05\n",
      "\n",
      "batch: 1/1 in epoch 838/1000 \n",
      "... loss: 2.4718874556128867e-05\n",
      "\n",
      "batch: 1/1 in epoch 839/1000 \n",
      "... loss: 2.462058728269767e-05\n",
      "\n",
      "batch: 1/1 in epoch 840/1000 \n",
      "... loss: 2.45230839936994e-05\n",
      "\n",
      "batch: 1/1 in epoch 841/1000 \n",
      "... loss: 2.442636468913406e-05\n",
      "\n",
      "batch: 1/1 in epoch 842/1000 \n",
      "... loss: 2.4329838197445497e-05\n",
      "\n",
      "batch: 1/1 in epoch 843/1000 \n",
      "... loss: 2.4233793737948872e-05\n",
      "\n",
      "batch: 1/1 in epoch 844/1000 \n",
      "... loss: 2.413823312963359e-05\n",
      "\n",
      "batch: 1/1 in epoch 845/1000 \n",
      "... loss: 2.4043445591814816e-05\n",
      "\n",
      "batch: 1/1 in epoch 846/1000 \n",
      "... loss: 2.3948552552610636e-05\n",
      "\n",
      "batch: 1/1 in epoch 847/1000 \n",
      "... loss: 2.3854137907619588e-05\n",
      "\n",
      "batch: 1/1 in epoch 848/1000 \n",
      "... loss: 2.3759910618537106e-05\n",
      "\n",
      "batch: 1/1 in epoch 849/1000 \n",
      "... loss: 2.3667029381613247e-05\n",
      "\n",
      "batch: 1/1 in epoch 850/1000 \n",
      "... loss: 2.3573462385684252e-05\n",
      "\n",
      "batch: 1/1 in epoch 851/1000 \n",
      "... loss: 2.348036832700018e-05\n",
      "\n",
      "batch: 1/1 in epoch 852/1000 \n",
      "... loss: 2.338774902455043e-05\n",
      "\n",
      "batch: 1/1 in epoch 853/1000 \n",
      "... loss: 2.3296172003028914e-05\n",
      "\n",
      "batch: 1/1 in epoch 854/1000 \n",
      "... loss: 2.3204778699437156e-05\n",
      "\n",
      "batch: 1/1 in epoch 855/1000 \n",
      "... loss: 2.3113561837817542e-05\n",
      "\n",
      "batch: 1/1 in epoch 856/1000 \n",
      "... loss: 2.3023098037810996e-05\n",
      "\n",
      "batch: 1/1 in epoch 857/1000 \n",
      "... loss: 2.293338366143871e-05\n",
      "\n",
      "batch: 1/1 in epoch 858/1000 \n",
      "... loss: 2.2843274564365856e-05\n",
      "\n",
      "batch: 1/1 in epoch 859/1000 \n",
      "... loss: 2.2753909433959052e-05\n",
      "\n",
      "batch: 1/1 in epoch 860/1000 \n",
      "... loss: 2.266472074552439e-05\n",
      "\n",
      "batch: 1/1 in epoch 861/1000 \n",
      "... loss: 2.2576556148123927e-05\n",
      "\n",
      "batch: 1/1 in epoch 862/1000 \n",
      "... loss: 2.2488562535727397e-05\n",
      "\n",
      "batch: 1/1 in epoch 863/1000 \n",
      "... loss: 2.2399895897251554e-05\n",
      "\n",
      "batch: 1/1 in epoch 864/1000 \n",
      "... loss: 2.2313093722914346e-05\n",
      "\n",
      "batch: 1/1 in epoch 865/1000 \n",
      "... loss: 2.2225334760150872e-05\n",
      "\n",
      "batch: 1/1 in epoch 866/1000 \n",
      "... loss: 2.213831066910643e-05\n",
      "\n",
      "batch: 1/1 in epoch 867/1000 \n",
      "... loss: 2.2052015992812812e-05\n",
      "\n",
      "batch: 1/1 in epoch 868/1000 \n",
      "... loss: 2.1965890482533723e-05\n",
      "\n",
      "batch: 1/1 in epoch 869/1000 \n",
      "... loss: 2.1879934138269164e-05\n",
      "\n",
      "batch: 1/1 in epoch 870/1000 \n",
      "... loss: 2.1795260181534104e-05\n",
      "\n",
      "batch: 1/1 in epoch 871/1000 \n",
      "... loss: 2.171074811485596e-05\n",
      "\n",
      "batch: 1/1 in epoch 872/1000 \n",
      "... loss: 2.162640157621354e-05\n",
      "\n",
      "batch: 1/1 in epoch 873/1000 \n",
      "... loss: 2.154222056560684e-05\n",
      "\n",
      "batch: 1/1 in epoch 874/1000 \n",
      "... loss: 2.1457923139678314e-05\n",
      "\n",
      "batch: 1/1 in epoch 875/1000 \n",
      "... loss: 2.1374622519942932e-05\n",
      "\n",
      "batch: 1/1 in epoch 876/1000 \n",
      "... loss: 2.1291756638674997e-05\n",
      "\n",
      "batch: 1/1 in epoch 877/1000 \n",
      "... loss: 2.1208777980064042e-05\n",
      "\n",
      "batch: 1/1 in epoch 878/1000 \n",
      "... loss: 2.1127054424141534e-05\n",
      "\n",
      "batch: 1/1 in epoch 879/1000 \n",
      "... loss: 2.1044945242465474e-05\n",
      "\n",
      "batch: 1/1 in epoch 880/1000 \n",
      "... loss: 2.0962994312867522e-05\n",
      "\n",
      "batch: 1/1 in epoch 881/1000 \n",
      "... loss: 2.0881747332168743e-05\n",
      "\n",
      "batch: 1/1 in epoch 882/1000 \n",
      "... loss: 2.0800931451958604e-05\n",
      "\n",
      "batch: 1/1 in epoch 883/1000 \n",
      "... loss: 2.072027200483717e-05\n",
      "\n",
      "batch: 1/1 in epoch 884/1000 \n",
      "... loss: 2.0640311049646698e-05\n",
      "\n",
      "batch: 1/1 in epoch 885/1000 \n",
      "... loss: 2.0560504708555527e-05\n",
      "\n",
      "batch: 1/1 in epoch 886/1000 \n",
      "... loss: 2.0480851162574254e-05\n",
      "\n",
      "batch: 1/1 in epoch 887/1000 \n",
      "... loss: 2.0401892470545135e-05\n",
      "\n",
      "batch: 1/1 in epoch 888/1000 \n",
      "... loss: 2.0323086573625915e-05\n",
      "\n",
      "batch: 1/1 in epoch 889/1000 \n",
      "... loss: 2.0243895050953142e-05\n",
      "\n",
      "batch: 1/1 in epoch 890/1000 \n",
      "... loss: 2.016619691858068e-05\n",
      "\n",
      "batch: 1/1 in epoch 891/1000 \n",
      "... loss: 2.0088382370886393e-05\n",
      "\n",
      "batch: 1/1 in epoch 892/1000 \n",
      "... loss: 2.0011249944218434e-05\n",
      "\n",
      "batch: 1/1 in epoch 893/1000 \n",
      "... loss: 1.993373552977573e-05\n",
      "\n",
      "batch: 1/1 in epoch 894/1000 \n",
      "... loss: 1.9857166989822872e-05\n",
      "\n",
      "batch: 1/1 in epoch 895/1000 \n",
      "... loss: 1.9780214643105865e-05\n",
      "\n",
      "batch: 1/1 in epoch 896/1000 \n",
      "... loss: 1.9704471924342215e-05\n",
      "\n",
      "batch: 1/1 in epoch 897/1000 \n",
      "... loss: 1.962860915227793e-05\n",
      "\n",
      "batch: 1/1 in epoch 898/1000 \n",
      "... loss: 1.955315747181885e-05\n",
      "\n",
      "batch: 1/1 in epoch 899/1000 \n",
      "... loss: 1.9477849491522647e-05\n",
      "\n",
      "batch: 1/1 in epoch 900/1000 \n",
      "... loss: 1.9403212718316354e-05\n",
      "\n",
      "batch: 1/1 in epoch 901/1000 \n",
      "... loss: 1.9328717826283537e-05\n",
      "\n",
      "batch: 1/1 in epoch 902/1000 \n",
      "... loss: 1.9254368453403004e-05\n",
      "\n",
      "batch: 1/1 in epoch 903/1000 \n",
      "... loss: 1.9180684830644168e-05\n",
      "\n",
      "batch: 1/1 in epoch 904/1000 \n",
      "... loss: 1.910766150103882e-05\n",
      "\n",
      "batch: 1/1 in epoch 905/1000 \n",
      "... loss: 1.903425800264813e-05\n",
      "\n",
      "batch: 1/1 in epoch 906/1000 \n",
      "... loss: 1.8960477973450907e-05\n",
      "\n",
      "batch: 1/1 in epoch 907/1000 \n",
      "... loss: 1.8888393242377788e-05\n",
      "\n",
      "batch: 1/1 in epoch 908/1000 \n",
      "... loss: 1.881593016150873e-05\n",
      "\n",
      "batch: 1/1 in epoch 909/1000 \n",
      "... loss: 1.874309054983314e-05\n",
      "\n",
      "batch: 1/1 in epoch 910/1000 \n",
      "... loss: 1.8672453734325245e-05\n",
      "\n",
      "batch: 1/1 in epoch 911/1000 \n",
      "... loss: 1.8600918338051997e-05\n",
      "\n",
      "batch: 1/1 in epoch 912/1000 \n",
      "... loss: 1.852952118497342e-05\n",
      "\n",
      "batch: 1/1 in epoch 913/1000 \n",
      "... loss: 1.845928818511311e-05\n",
      "\n",
      "batch: 1/1 in epoch 914/1000 \n",
      "... loss: 1.838867501646746e-05\n",
      "\n",
      "batch: 1/1 in epoch 915/1000 \n",
      "... loss: 1.8317941794521175e-05\n",
      "\n",
      "batch: 1/1 in epoch 916/1000 \n",
      "... loss: 1.8248365449835546e-05\n",
      "\n",
      "batch: 1/1 in epoch 917/1000 \n",
      "... loss: 1.8178157915826887e-05\n",
      "\n",
      "batch: 1/1 in epoch 918/1000 \n",
      "... loss: 1.8109607481164858e-05\n",
      "\n",
      "batch: 1/1 in epoch 919/1000 \n",
      "... loss: 1.804017483664211e-05\n",
      "\n",
      "batch: 1/1 in epoch 920/1000 \n",
      "... loss: 1.7971380657400005e-05\n",
      "\n",
      "batch: 1/1 in epoch 921/1000 \n",
      "... loss: 1.7903472325997427e-05\n",
      "\n",
      "batch: 1/1 in epoch 922/1000 \n",
      "... loss: 1.7834689060691744e-05\n",
      "\n",
      "batch: 1/1 in epoch 923/1000 \n",
      "... loss: 1.7767291865311563e-05\n",
      "\n",
      "batch: 1/1 in epoch 924/1000 \n",
      "... loss: 1.769951995811425e-05\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/1 in epoch 925/1000 \n",
      "... loss: 1.7631879018153995e-05\n",
      "\n",
      "batch: 1/1 in epoch 926/1000 \n",
      "... loss: 1.7564867448527366e-05\n",
      "\n",
      "batch: 1/1 in epoch 927/1000 \n",
      "... loss: 1.7497983208158985e-05\n",
      "\n",
      "batch: 1/1 in epoch 928/1000 \n",
      "... loss: 1.743247230479028e-05\n",
      "\n",
      "batch: 1/1 in epoch 929/1000 \n",
      "... loss: 1.7365591702400707e-05\n",
      "\n",
      "batch: 1/1 in epoch 930/1000 \n",
      "... loss: 1.7299584214924835e-05\n",
      "\n",
      "batch: 1/1 in epoch 931/1000 \n",
      "... loss: 1.7234198821824975e-05\n",
      "\n",
      "batch: 1/1 in epoch 932/1000 \n",
      "... loss: 1.7168935301015154e-05\n",
      "\n",
      "batch: 1/1 in epoch 933/1000 \n",
      "... loss: 1.7103795471484773e-05\n",
      "\n",
      "batch: 1/1 in epoch 934/1000 \n",
      "... loss: 1.7038781152223237e-05\n",
      "\n",
      "batch: 1/1 in epoch 935/1000 \n",
      "... loss: 1.6974379832390696e-05\n",
      "\n",
      "batch: 1/1 in epoch 936/1000 \n",
      "... loss: 1.6910100384848192e-05\n",
      "\n",
      "batch: 1/1 in epoch 937/1000 \n",
      "... loss: 1.6846188373165205e-05\n",
      "\n",
      "batch: 1/1 in epoch 938/1000 \n",
      "... loss: 1.6782398233772255e-05\n",
      "\n",
      "batch: 1/1 in epoch 939/1000 \n",
      "... loss: 1.671848258411046e-05\n",
      "\n",
      "batch: 1/1 in epoch 940/1000 \n",
      "... loss: 1.6655663785059005e-05\n",
      "\n",
      "batch: 1/1 in epoch 941/1000 \n",
      "... loss: 1.65936926350696e-05\n",
      "\n",
      "batch: 1/1 in epoch 942/1000 \n",
      "... loss: 1.6530380889889784e-05\n",
      "\n",
      "batch: 1/1 in epoch 943/1000 \n",
      "... loss: 1.6467918612761423e-05\n",
      "\n",
      "batch: 1/1 in epoch 944/1000 \n",
      "... loss: 1.6405812857556157e-05\n",
      "\n",
      "batch: 1/1 in epoch 945/1000 \n",
      "... loss: 1.634382533666212e-05\n",
      "\n",
      "batch: 1/1 in epoch 946/1000 \n",
      "... loss: 1.6282196156680584e-05\n",
      "\n",
      "batch: 1/1 in epoch 947/1000 \n",
      "... loss: 1.6220683392020874e-05\n",
      "\n",
      "batch: 1/1 in epoch 948/1000 \n",
      "... loss: 1.6159765436896123e-05\n",
      "\n",
      "batch: 1/1 in epoch 949/1000 \n",
      "... loss: 1.60989638970932e-05\n",
      "\n",
      "batch: 1/1 in epoch 950/1000 \n",
      "... loss: 1.6038275134633295e-05\n",
      "\n",
      "batch: 1/1 in epoch 951/1000 \n",
      "... loss: 1.5977941075107083e-05\n",
      "\n",
      "batch: 1/1 in epoch 952/1000 \n",
      "... loss: 1.591795626154635e-05\n",
      "\n",
      "batch: 1/1 in epoch 953/1000 \n",
      "... loss: 1.5858086044318043e-05\n",
      "\n",
      "batch: 1/1 in epoch 954/1000 \n",
      "... loss: 1.579809031682089e-05\n",
      "\n",
      "batch: 1/1 in epoch 955/1000 \n",
      "... loss: 1.5738682122901082e-05\n",
      "\n",
      "batch: 1/1 in epoch 956/1000 \n",
      "... loss: 1.5679857824579813e-05\n",
      "\n",
      "batch: 1/1 in epoch 957/1000 \n",
      "... loss: 1.56209080159897e-05\n",
      "\n",
      "batch: 1/1 in epoch 958/1000 \n",
      "... loss: 1.5562303815386258e-05\n",
      "\n",
      "batch: 1/1 in epoch 959/1000 \n",
      "... loss: 1.5503810573136434e-05\n",
      "\n",
      "batch: 1/1 in epoch 960/1000 \n",
      "... loss: 1.544566111988388e-05\n",
      "\n",
      "batch: 1/1 in epoch 961/1000 \n",
      "... loss: 1.5387622624984942e-05\n",
      "\n",
      "batch: 1/1 in epoch 962/1000 \n",
      "... loss: 1.533039176138118e-05\n",
      "\n",
      "batch: 1/1 in epoch 963/1000 \n",
      "... loss: 1.5272335076588206e-05\n",
      "\n",
      "batch: 1/1 in epoch 964/1000 \n",
      "... loss: 1.5215320672723465e-05\n",
      "\n",
      "batch: 1/1 in epoch 965/1000 \n",
      "... loss: 1.5158643691393081e-05\n",
      "\n",
      "batch: 1/1 in epoch 966/1000 \n",
      "... loss: 1.5101608369150199e-05\n",
      "\n",
      "batch: 1/1 in epoch 967/1000 \n",
      "... loss: 1.504514420958003e-05\n",
      "\n",
      "batch: 1/1 in epoch 968/1000 \n",
      "... loss: 1.4989478586358018e-05\n",
      "\n",
      "batch: 1/1 in epoch 969/1000 \n",
      "... loss: 1.4933222701074556e-05\n",
      "\n",
      "batch: 1/1 in epoch 970/1000 \n",
      "... loss: 1.4877534340484999e-05\n",
      "\n",
      "batch: 1/1 in epoch 971/1000 \n",
      "... loss: 1.4821491276961751e-05\n",
      "\n",
      "batch: 1/1 in epoch 972/1000 \n",
      "... loss: 1.4766011190658901e-05\n",
      "\n",
      "batch: 1/1 in epoch 973/1000 \n",
      "... loss: 1.4711092262587044e-05\n",
      "\n",
      "batch: 1/1 in epoch 974/1000 \n",
      "... loss: 1.465673358325148e-05\n",
      "\n",
      "batch: 1/1 in epoch 975/1000 \n",
      "... loss: 1.460133535147179e-05\n",
      "\n",
      "batch: 1/1 in epoch 976/1000 \n",
      "... loss: 1.454649736842839e-05\n",
      "\n",
      "batch: 1/1 in epoch 977/1000 \n",
      "... loss: 1.4492896298179403e-05\n",
      "\n",
      "batch: 1/1 in epoch 978/1000 \n",
      "... loss: 1.4438941434491426e-05\n",
      "\n",
      "batch: 1/1 in epoch 979/1000 \n",
      "... loss: 1.4385086615220644e-05\n",
      "\n",
      "batch: 1/1 in epoch 980/1000 \n",
      "... loss: 1.433133365935646e-05\n",
      "\n",
      "batch: 1/1 in epoch 981/1000 \n",
      "... loss: 1.4278130947786849e-05\n",
      "\n",
      "batch: 1/1 in epoch 982/1000 \n",
      "... loss: 1.4225027371139731e-05\n",
      "\n",
      "batch: 1/1 in epoch 983/1000 \n",
      "... loss: 1.417247131030308e-05\n",
      "\n",
      "batch: 1/1 in epoch 984/1000 \n",
      "... loss: 1.4119341358309612e-05\n",
      "\n",
      "batch: 1/1 in epoch 985/1000 \n",
      "... loss: 1.4067428310227115e-05\n",
      "\n",
      "batch: 1/1 in epoch 986/1000 \n",
      "... loss: 1.4014493899594527e-05\n",
      "\n",
      "batch: 1/1 in epoch 987/1000 \n",
      "... loss: 1.3962774573883507e-05\n",
      "\n",
      "batch: 1/1 in epoch 988/1000 \n",
      "... loss: 1.3911150745116174e-05\n",
      "\n",
      "batch: 1/1 in epoch 989/1000 \n",
      "... loss: 1.385895666317083e-05\n",
      "\n",
      "batch: 1/1 in epoch 990/1000 \n",
      "... loss: 1.3807747563987505e-05\n",
      "\n",
      "batch: 1/1 in epoch 991/1000 \n",
      "... loss: 1.3756852240476292e-05\n",
      "\n",
      "batch: 1/1 in epoch 992/1000 \n",
      "... loss: 1.3705390301765874e-05\n",
      "\n",
      "batch: 1/1 in epoch 993/1000 \n",
      "... loss: 1.365490516036516e-05\n",
      "\n",
      "batch: 1/1 in epoch 994/1000 \n",
      "... loss: 1.3603853403765243e-05\n",
      "\n",
      "batch: 1/1 in epoch 995/1000 \n",
      "... loss: 1.3553777534980327e-05\n",
      "\n",
      "batch: 1/1 in epoch 996/1000 \n",
      "... loss: 1.3503353329724632e-05\n",
      "\n",
      "batch: 1/1 in epoch 997/1000 \n",
      "... loss: 1.3453461178869475e-05\n",
      "\n",
      "batch: 1/1 in epoch 998/1000 \n",
      "... loss: 1.3403660886979196e-05\n",
      "\n",
      "batch: 1/1 in epoch 999/1000 \n",
      "... loss: 1.3354170732782222e-05\n",
      "\n",
      "batch: 1/1 in epoch 1000/1000 \n",
      "... loss: 1.3304555068316404e-05\n",
      "\n",
      "\n",
      "[[0, 1.7329624891281128], [1, 11.440106391906738], [2, 23.923999786376953], [3, 0.004358451813459396], [4, 0.31588196754455566], [5, 0.26433297991752625], [6, 0.10749535262584686], [7, 0.024315308779478073], [8, 0.003967489115893841], [9, 0.005499375984072685], [10, 0.007741155102849007], [11, 0.0068835108540952206], [12, 0.0049796630628407], [13, 0.0036837956868112087], [14, 0.003202561056241393], [15, 0.0031308613251894712], [16, 0.0031367570627480745], [17, 0.0031102283392101526], [18, 0.0030598791781812906], [19, 0.003011351218447089], [20, 0.0029733735136687756], [21, 0.0029427737463265657], [22, 0.002914741402491927], [23, 0.002887014066800475], [24, 0.0028592930175364017], [25, 0.0028318678960204124], [26, 0.002804945921525359], [27, 0.00277849193662405], [28, 0.0027524749748408794], [29, 0.0027268165722489357], [30, 0.0027015055529773235], [31, 0.00267653726041317], [32, 0.0026519170496612787], [33, 0.002627633512020111], [34, 0.0026036801282316446], [35, 0.0025800454895943403], [36, 0.002556738443672657], [37, 0.002533730585128069], [38, 0.002511034021154046], [39, 0.0024886364117264748], [40, 0.0024665272794663906], [41, 0.0024447068572044373], [42, 0.0024231697898358107], [43, 0.002401918638497591], [44, 0.002380932914093137], [45, 0.002360219368711114], [46, 0.0023397693876177073], [47, 0.0023195722606033087], [48, 0.0022996284533292055], [49, 0.0022799500729888678], [50, 0.0022605066187679768], [51, 0.0022412962280213833], [52, 0.002222325187176466], [53, 0.0022036030422896147], [54, 0.0021851020865142345], [55, 0.0021668127737939358], [56, 0.0021487632766366005], [57, 0.002130921697244048], [58, 0.002113297116011381], [59, 0.0020958767272531986], [60, 0.0020786754321306944], [61, 0.0020616641268134117], [62, 0.0020448656287044287], [63, 0.0020282650366425514], [64, 0.0020118418615311384], [65, 0.001995623577386141], [66, 0.001979588298127055], [67, 0.001963744405657053], [68, 0.001948080025613308], [69, 0.0019325832836329937], [70, 0.0019172737374901772], [71, 0.0019021371845155954], [72, 0.0018871667562052608], [73, 0.0018723664106801152], [74, 0.0018577298615127802], [75, 0.001843258156441152], [76, 0.0018289478030055761], [77, 0.0018147948430851102], [78, 0.0018008005572482944], [79, 0.0017869513249024749], [80, 0.0017732609994709492], [81, 0.0017597133992239833], [82, 0.001746302586980164], [83, 0.0017330498667433858], [84, 0.0017199366120621562], [85, 0.0017069594468921423], [86, 0.001694127218797803], [87, 0.0016814216505736113], [88, 0.0016688443720340729], [89, 0.0016564112156629562], [90, 0.001644106931053102], [91, 0.0016319232527166605], [92, 0.0016198687953874469], [93, 0.0016079333145171404], [94, 0.0015961204189807177], [95, 0.0015844342997297645], [96, 0.001572857378050685], [97, 0.0015613982686772943], [98, 0.0015500679146498442], [99, 0.0015388374449685216], [100, 0.001527720014564693], [101, 0.0015167148085311055], [102, 0.0015058189164847136], [103, 0.0014950245385989547], [104, 0.0014843379613012075], [105, 0.0014737538294866681], [106, 0.0014632781967520714], [107, 0.001452892436645925], [108, 0.0014426092384383082], [109, 0.0014324256917461753], [110, 0.0014223366742953658], [111, 0.001412346144206822], [112, 0.0014024510746821761], [113, 0.001392637612298131], [114, 0.0013829206582158804], [115, 0.0013732953229919076], [116, 0.0013637541560456157], [117, 0.0013543033273890615], [118, 0.001344940043054521], [119, 0.0013356548734009266], [120, 0.0013264563167467713], [121, 0.0013173414627090096], [122, 0.001308301230892539], [123, 0.0012993479613214731], [124, 0.0012904724571853876], [125, 0.001281672390177846], [126, 0.00127294915728271], [127, 0.0012643022928386927], [128, 0.0012557252775877714], [129, 0.001247225794941187], [130, 0.0012387949973344803], [131, 0.0012304409174248576], [132, 0.0012221505166962743], [133, 0.0012139339232817292], [134, 0.0012057843850925565], [135, 0.0011977035319432616], [136, 0.0011896848445758224], [137, 0.0011817340273410082], [138, 0.0011738446773961186], [139, 0.0011660224990919232], [140, 0.0011582670267671347], [141, 0.0011505697621032596], [142, 0.0011429303558543324], [143, 0.0011353547452017665], [144, 0.0011278282618150115], [145, 0.001120376749895513], [146, 0.0011129718041047454], [147, 0.001105627161450684], [148, 0.0010983383981510997], [149, 0.0010911072604358196], [150, 0.0010839254828169942], [151, 0.0010768006322905421], [152, 0.0010697267716750503], [153, 0.0010627091396600008], [154, 0.0010557378409430385], [155, 0.0010488262632861733], [156, 0.0010419604368507862], [157, 0.001035145833157003], [158, 0.001028376747854054], [159, 0.0010216583032160997], [160, 0.0010149847948923707], [161, 0.001008361461572349], [162, 0.0010017863241955638], [163, 0.0009952514665201306], [164, 0.0009887679480016232], [165, 0.0009823262225836515], [166, 0.0009759241947904229], [167, 0.0009695764747448266], [168, 0.0009632605942897499], [169, 0.0009569949470460415], [170, 0.0009507680661045015], [171, 0.000944579835049808], [172, 0.0009384391596540809], [173, 0.0009323367848992348], [174, 0.0009262670646421611], [175, 0.0009202460641972721], [176, 0.000914262724108994], [177, 0.0009083151235245168], [178, 0.0009024048340506852], [179, 0.000896535231731832], [180, 0.0008906990406103432], [181, 0.0008849049336276948], [182, 0.0008791369036771357], [183, 0.0008734159055165946], [184, 0.0008677258156239986], [185, 0.000862071814481169], [186, 0.00085645035142079], [187, 0.0008508663740940392], [188, 0.0008453128393739462], [189, 0.000839796441141516], [190, 0.0008343119407072663], [191, 0.0008288557291962206], [192, 0.0008234395645558834], [193, 0.0008180514560081065], [194, 0.0008126929169520736], [195, 0.0008073740755207837], [196, 0.0008020793902687728], [197, 0.0007968139252625406], [198, 0.0007915859459899366], [199, 0.000786385266110301], [200, 0.0007812116527929902], [201, 0.0007760734297335148], [202, 0.0007709587807767093], [203, 0.0007658791728317738], [204, 0.0007608262239955366], [205, 0.000755803135689348], [206, 0.0007508032722398639], [207, 0.0007458378677256405], [208, 0.0007408970850519836], [209, 0.0007359904702752829], [210, 0.0007311050430871546], [211, 0.0007262487197294831], [212, 0.0007214214419946074], [213, 0.0007166197756305337], [214, 0.0007118437206372619], [215, 0.0007070963620208204], [216, 0.0007023743237368762], [217, 0.0006976791773922741], [218, 0.000693012319970876], [219, 0.0006883689202368259], [220, 0.0006837567198090255], [221, 0.0006791647174395621], [222, 0.0006746005965396762], [223, 0.0006700595840811729], [224, 0.0006655462202616036], [225, 0.0006610588170588017], [226, 0.0006565957446582615], [227, 0.000652158516459167], [228, 0.0006477468996308744], [229, 0.0006433593807742], [230, 0.000638995785266161], [231, 0.0006346575682982802], [232, 0.0006303416448645294], [233, 0.0006260568043217063], [234, 0.00062178960070014], [235, 0.000617551791947335], [236, 0.0006133343558758497], [237, 0.0006091431714594364], [238, 0.0006049751536920667], [239, 0.0006008331547491252], [240, 0.0005967156030237675], [241, 0.0005926208687014878], [242, 0.000588550406973809], [243, 0.0005845025880262256], [244, 0.0005804759566672146], [245, 0.0005764775560237467], [246, 0.0005725029041059315], [247, 0.0005685506039299071], [248, 0.0005646232748404145], [249, 0.0005607180646620691], [250, 0.0005568419001065195], [251, 0.0005529819172807038], [252, 0.0005491480114869773], [253, 0.0005453357589431107], [254, 0.0005415478954091668], [255, 0.0005377843044698238], [256, 0.00053404486970976], [257, 0.0005303294165059924], [258, 0.0005266351508907974], [259, 0.0005229647504165769], [260, 0.0005193180404603481], [261, 0.0005156922270543873], [262, 0.0005120898713357747], [263, 0.0005085163284093142], [264, 0.0005049632745794952], [265, 0.0005014307098463178], [266, 0.000497918576002121], [267, 0.0004944346146658063], [268, 0.0004909708513878286], [269, 0.0004875298182014376], [270, 0.0004841152695007622], [271, 0.00048071928904391825], [272, 0.0004773469700012356], [273, 0.00047400081530213356], [274, 0.00047067416016943753], [275, 0.0004673695657402277], [276, 0.00046408941852860153], [277, 0.0004608298186212778], [278, 0.000457593152532354], [279, 0.0004543806135188788], [280, 0.0004511882725637406], [281, 0.00044801976764574647], [282, 0.00044487000559456646], [283, 0.00044174384674988687], [284, 0.0004386424843687564], [285, 0.0004355607379693538], [286, 0.00043250349699519575], [287, 0.0004294619429856539], [288, 0.00042645083158276975], [289, 0.00042345523252151906], [290, 0.0004204836150165647], [291, 0.00041753100231289864], [292, 0.00041460213833488524], [293, 0.0004116920754313469], [294, 0.0004088078858330846], [295, 0.0004059386847075075], [296, 0.00040309751057066023], [297, 0.00040027109207585454], [298, 0.0003974688588641584], [299, 0.00039469069452024996], [300, 0.0003919293521903455], [301, 0.00038918713107705116], [302, 0.0003864697355311364], [303, 0.0003837700642179698], [304, 0.0003810926282312721], [305, 0.00037843387690372765], [306, 0.0003757959639187902], [307, 0.0003731764736585319], [308, 0.0003705787821672857], [309, 0.00036800047382712364], [310, 0.0003654425381682813], [311, 0.0003629026177804917], [312, 0.0003603862423915416], [313, 0.0003578831674531102], [314, 0.00035540226963348687], [315, 0.000352941220626235], [316, 0.00035049987491220236], [317, 0.0003480758750811219], [318, 0.00034567140392027795], [319, 0.000343284074915573], [320, 0.0003409171476960182], [321, 0.00033856937079690397], [322, 0.0003362373390700668], [323, 0.00033392643672414124], [324, 0.0003316322108730674], [325, 0.00032935559283941984], [326, 0.00032709763036109507], [327, 0.0003248592256568372], [328, 0.00032263496541418135], [329, 0.00032043110695667565], [330, 0.0003182433429174125], [331, 0.000316073652356863], [332, 0.00031391982338391244], [333, 0.0003117839223705232], [334, 0.0003096646978519857], [335, 0.0003075631975661963], [336, 0.0003054771514143795], [337, 0.0003034065302927047], [338, 0.0003013553796336055], [339, 0.00029931837343610823], [340, 0.0002972985676024109], [341, 0.0002952968643512577], [342, 0.00029330907273106277], [343, 0.0002913361240644008], [344, 0.00028937796014361084], [345, 0.00028743952861987054], [346, 0.0002855136408470571], [347, 0.0002836052735801786], [348, 0.0002817093045450747], [349, 0.00027982768369838595], [350, 0.0002779642818495631], [351, 0.00027611604309640825], [352, 0.00027427886379882693], [353, 0.0002724596415646374], [354, 0.0002706533414311707], [355, 0.000268862844677642], [356, 0.00026708506629802287], [357, 0.00026532390620559454], [358, 0.0002635733690112829], [359, 0.00026183732552453876], [360, 0.00026011854060925543], [361, 0.00025841023307293653], [362, 0.00025671516777947545], [363, 0.0002550352073740214], [364, 0.00025336837279610336], [365, 0.00025171643937937915], [366, 0.00025007178192026913], [367, 0.0002484466240275651], [368, 0.0002468323800712824], [369, 0.00024522992316633463], [370, 0.00024363827833440155], [371, 0.00024206294619943947], [372, 0.00024049918283708394], [373, 0.00023894786136224866], [374, 0.00023740615870337933], [375, 0.0002358813362661749], [376, 0.00023436507035512477], [377, 0.00023286188661586493], [378, 0.00023137079551815987], [379, 0.00022989082208368927], [380, 0.000228421893552877], [381, 0.0002269657707074657], [382, 0.0002255214494653046], [383, 0.00022408709628507495], [384, 0.0002226653159596026], [385, 0.00022125338728073984], [386, 0.00021985213970765471], [387, 0.00021846414892934263], [388, 0.0002170867082895711], [389, 0.00021571711113210768], [390, 0.0002143588353646919], [391, 0.00021301268134266138], [392, 0.00021167770319152623], [393, 0.00021035296958871186], [394, 0.00020903756376355886], [395, 0.0002077314566122368], [396, 0.0002064371365122497], [397, 0.0002051519841188565], [398, 0.00020387764379847795], [399, 0.0002026106812991202], [400, 0.000201356117031537], [401, 0.00020011050219181925], [402, 0.00019887548114638776], [403, 0.00019764932221733034], [404, 0.0001964327966561541], [405, 0.00019522335787769407], [406, 0.00019402428006287664], [407, 0.00019283553410787135], [408, 0.00019165538833476603], [409, 0.00019048381363973022], [410, 0.00018931909289676696], [411, 0.00018816938973031938], [412, 0.00018702319357544184], [413, 0.0001858870091382414], [414, 0.00018476076365914196], [415, 0.000183642769115977], [416, 0.00018253141024615616], [417, 0.00018142983026336879], [418, 0.00018033479864243418], [419, 0.0001792494731489569], [420, 0.00017817298066802323], [421, 0.00017710606334730983], [422, 0.0001760439481586218], [423, 0.00017498974921181798], [424, 0.00017394580936525017], [425, 0.00017290654068347067], [426, 0.00017187742923852056], [427, 0.00017085605941247195], [428, 0.00016984161629807204], [429, 0.00016883484204299748], [430, 0.00016783647879492491], [431, 0.00016684566799085587], [432, 0.00016586011042818427], [433, 0.00016488358960486948], [434, 0.00016391149256378412], [435, 0.00016294985834974796], [436, 0.00016199410310946405], [437, 0.00016104569658637047], [438, 0.00016010459512472153], [439, 0.00015916925622150302], [440, 0.00015824190631974488], [441, 0.00015732174506410956], [442, 0.00015640800120308995], [443, 0.00015549990348517895], [444, 0.00015459962014574558], [445, 0.00015370416804216802], [446, 0.00015281501691788435], [447, 0.0001519335783086717], [448, 0.000151059080963023], [449, 0.00015019149577710778], [450, 0.00014932930935174227], [451, 0.00014847108104731888], [452, 0.000147623271914199], [453, 0.0001467793481424451], [454, 0.0001459399936720729], [455, 0.00014510878827422857], [456, 0.00014428282156586647], [457, 0.00014346207899507135], [458, 0.0001426493690814823], [459, 0.00014184181054588407], [460, 0.00014103864668868482], [461, 0.0001402420166414231], [462, 0.0001394497521687299], [463, 0.00013866534573026001], [464, 0.00013788454816676676], [465, 0.00013711083738598973], [466, 0.0001363421033602208], [467, 0.0001355776039417833], [468, 0.0001348207879345864], [469, 0.0001340674643870443], [470, 0.00013331901573110372], [471, 0.00013257678074296564], [472, 0.00013184003182686865], [473, 0.00013110738655086607], [474, 0.0001303829048993066], [475, 0.0001296597474720329], [476, 0.00012894267274532467], [477, 0.00012823095312342048], [478, 0.0001275239046663046], [479, 0.00012682216765824705], [480, 0.0001261263678316027], [481, 0.00012543382763396949], [482, 0.0001247465261258185], [483, 0.00012406376481521875], [484, 0.00012338485976215452], [485, 0.00012271244486328214], [486, 0.0001220431731780991], [487, 0.0001213803407154046], [488, 0.00012072061508661136], [489, 0.00012006399629171938], [490, 0.00011941308184759691], [491, 0.00011876782809849828], [492, 0.00011812561569968238], [493, 0.00011748902034014463], [494, 0.00011685543722705916], [495, 0.00011622806778177619], [496, 0.0001156023790827021], [497, 0.00011498157982714474], [498, 0.0001143662811955437], [499, 0.00011375390022294596], [500, 0.00011314506264170632], [501, 0.00011254165292484686], [502, 0.00011194175021955743], [503, 0.00011134596570627764], [504, 0.00011075428483309224], [505, 0.00011016792996088043], [506, 0.00010958188067888841], [507, 0.00010900237248279154], [508, 0.00010842688789125532], [509, 0.00010785416088765487], [510, 0.00010728480265242979], [511, 0.00010672065400285646], [512, 0.00010615859355311841], [513, 0.00010560292867012322], [514, 0.00010504748934181407], [515, 0.00010449596447870135], [516, 0.00010395074787084013], [517, 0.00010340816515963525], [518, 0.00010286820906912908], [519, 0.00010233208740828559], [520, 0.0001017997637973167], [521, 0.0001012712309602648], [522, 0.00010074466990772635], [523, 0.00010022366041084751], [524, 9.970400424208492e-05], [525, 9.91892593447119e-05], [526, 9.867762128124014e-05], [527, 9.81678967946209e-05], [528, 9.766243601916358e-05], [529, 9.716004569781944e-05], [530, 9.666188270784914e-05], [531, 9.616558236302808e-05], [532, 9.567288361722603e-05], [533, 9.518262231722474e-05], [534, 9.469709766563028e-05], [535, 9.42139740800485e-05], [536, 9.373381908517331e-05], [537, 9.325603605248034e-05], [538, 9.278176730731502e-05], [539, 9.231100557371974e-05], [540, 9.18420118978247e-05], [541, 9.137705637840554e-05], [542, 9.091498941415921e-05], [543, 9.045522892847657e-05], [544, 8.999832789413631e-05], [545, 8.9545406808611e-05], [546, 8.909418829716742e-05], [547, 8.864747360348701e-05], [548, 8.820020593702793e-05], [549, 8.775909373071045e-05], [550, 8.731908746995032e-05], [551, 8.688186062499881e-05], [552, 8.644849731354043e-05], [553, 8.60173167893663e-05], [554, 8.558777335565537e-05], [555, 8.516039815731347e-05], [556, 8.473848720313981e-05], [557, 8.431652531726286e-05], [558, 8.389889990212396e-05], [559, 8.348339179065078e-05], [560, 8.306892414111644e-05], [561, 8.265927317552269e-05], [562, 8.225172496167943e-05], [563, 8.184355829143897e-05], [564, 8.144124876707792e-05], [565, 8.10410056146793e-05], [566, 8.064228313742206e-05], [567, 8.0245612480212e-05], [568, 7.985311822267249e-05], [569, 7.946263940539211e-05], [570, 7.907312829047441e-05], [571, 7.868561806390062e-05], [572, 7.830224058125168e-05], [573, 7.792136602802202e-05], [574, 7.754195394227281e-05], [575, 7.716398249613121e-05], [576, 7.678955444134772e-05], [577, 7.641602860530838e-05], [578, 7.604550046380609e-05], [579, 7.567794091301039e-05], [580, 7.531127630500123e-05], [581, 7.494756573578343e-05], [582, 7.458679465344176e-05], [583, 7.422586350003257e-05], [584, 7.386888319160789e-05], [585, 7.351378008024767e-05], [586, 7.316056144190952e-05], [587, 7.280869613168761e-05], [588, 7.246022141771391e-05], [589, 7.211206684587523e-05], [590, 7.17682924005203e-05], [591, 7.142483809730038e-05], [592, 7.108421414159238e-05], [593, 7.074540917528793e-05], [594, 7.04084086464718e-05], [595, 7.007171370787546e-05], [596, 6.973881681915373e-05], [597, 6.940820458112285e-05], [598, 6.907936040079221e-05], [599, 6.875179678900167e-05], [600, 6.84269834891893e-05], [601, 6.810244667576626e-05], [602, 6.778015085728839e-05], [603, 6.74620532663539e-05], [604, 6.714226037729532e-05], [605, 6.682711682515219e-05], [606, 6.651174771832302e-05], [607, 6.620100612053648e-05], [608, 6.588905671378598e-05], [609, 6.558073800988495e-05], [610, 6.527314690174535e-05], [611, 6.496723653981462e-05], [612, 6.466299237217754e-05], [613, 6.436138937715441e-05], [614, 6.406144530046731e-05], [615, 6.376314559020102e-05], [616, 6.346649752231315e-05], [617, 6.317054067039862e-05], [618, 6.287716678343713e-05], [619, 6.258588837226853e-05], [620, 6.229528662515804e-05], [621, 6.200582720339298e-05], [622, 6.171985296532512e-05], [623, 6.143360951682553e-05], [624, 6.115082214819267e-05], [625, 6.086776193114929e-05], [626, 6.0588139604078606e-05], [627, 6.030823351466097e-05], [628, 6.0030826716683805e-05], [629, 5.975359817966819e-05], [630, 5.948068792349659e-05], [631, 5.9207482991041616e-05], [632, 5.893674097023904e-05], [633, 5.866707215318456e-05], [634, 5.839802179252729e-05], [635, 5.8131408877670765e-05], [636, 5.786586189060472e-05], [637, 5.760091880802065e-05], [638, 5.733929356210865e-05], [639, 5.7077813835348934e-05], [640, 5.681828042725101e-05], [641, 5.655978384311311e-05], [642, 5.630367013509385e-05], [643, 5.6047683756332844e-05], [644, 5.579406933975406e-05], [645, 5.5541469919262454e-05], [646, 5.52903329662513e-05], [647, 5.503975989995524e-05], [648, 5.479152605403215e-05], [649, 5.454385245684534e-05], [650, 5.429849261417985e-05], [651, 5.405456613516435e-05], [652, 5.3811185352969915e-05], [653, 5.356923065846786e-05], [654, 5.332869113772176e-05], [655, 5.308955951477401e-05], [656, 5.285139923216775e-05], [657, 5.26155017723795e-05], [658, 5.237927325651981e-05], [659, 5.214486373006366e-05], [660, 5.191226955503225e-05], [661, 5.1680624892469496e-05], [662, 5.1449922466417775e-05], [663, 5.1220169552834705e-05], [664, 5.099262489238754e-05], [665, 5.0766440836014226e-05], [666, 5.054033681517467e-05], [667, 5.0316004490014166e-05], [668, 5.009258893551305e-05], [669, 4.9871359806274995e-05], [670, 4.9650199798634276e-05], [671, 4.9430367653258145e-05], [672, 4.921269282931462e-05], [673, 4.899508712696843e-05], [674, 4.877837636740878e-05], [675, 4.856256055063568e-05], [676, 4.834929859498516e-05], [677, 4.813650230062194e-05], [678, 4.792459003510885e-05], [679, 4.7713969252072275e-05], [680, 4.750504740513861e-05], [681, 4.729575812234543e-05], [682, 4.708939013653435e-05], [683, 4.688265107688494e-05], [684, 4.66780002170708e-05], [685, 4.647379319067113e-05], [686, 4.627044472726993e-05], [687, 4.60675400972832e-05], [688, 4.586790964822285e-05], [689, 4.5666693040402606e-05], [690, 4.546833224594593e-05], [691, 4.527000055531971e-05], [692, 4.5073305955156684e-05], [693, 4.4878237531520426e-05], [694, 4.4683987653115764e-05], [695, 4.4488970161182806e-05], [696, 4.429636101122014e-05], [697, 4.410495967022143e-05], [698, 4.3913580157095566e-05], [699, 4.3724194256355986e-05], [700, 4.3535608710953966e-05], [701, 4.334743061917834e-05], [702, 4.316004924476147e-05], [703, 4.297385748941451e-05], [704, 4.278885171515867e-05], [705, 4.2604628106346354e-05], [706, 4.2421583202667534e-05], [707, 4.223854193696752e-05], [708, 4.205782897770405e-05], [709, 4.187750528217293e-05], [710, 4.1698338463902473e-05], [711, 4.151878601987846e-05], [712, 4.13411580666434e-05], [713, 4.116467243875377e-05], [714, 4.0988561522681266e-05], [715, 4.081321458215825e-05], [716, 4.063975939061493e-05], [717, 4.046591857331805e-05], [718, 4.029282717965543e-05], [719, 4.012161662103608e-05], [720, 3.995152292191051e-05], [721, 3.978066524723545e-05], [722, 3.9612423279322684e-05], [723, 3.9444163121515885e-05], [724, 3.927625948563218e-05], [725, 3.910946179530583e-05], [726, 3.894413384841755e-05], [727, 3.8778784073656425e-05], [728, 3.861527147819288e-05], [729, 3.8452471926575527e-05], [730, 3.828964690910652e-05], [731, 3.8127902371343225e-05], [732, 3.79665034415666e-05], [733, 3.7806908949278295e-05], [734, 3.764801658689976e-05], [735, 3.748982635443099e-05], [736, 3.733197081601247e-05], [737, 3.7174442695686594e-05], [738, 3.7019064620835707e-05], [739, 3.686292620841414e-05], [740, 3.670819933176972e-05], [741, 3.655416003311984e-05], [742, 3.64011648343876e-05], [743, 3.624920645961538e-05], [744, 3.609792111092247e-05], [745, 3.594659938244149e-05], [746, 3.579559415811673e-05], [747, 3.564633152564056e-05], [748, 3.549808752723038e-05], [749, 3.535015639499761e-05], [750, 3.520253085298464e-05], [751, 3.505556742311455e-05], [752, 3.490996823529713e-05], [753, 3.47646746376995e-05], [754, 3.462002860032953e-05], [755, 3.447639028308913e-05], [756, 3.433305028011091e-05], [757, 3.4190703445347026e-05], [758, 3.4048651286866516e-05], [759, 3.390863275853917e-05], [760, 3.376751556061208e-05], [761, 3.362842107890174e-05], [762, 3.348892641952261e-05], [763, 3.335040673846379e-05], [764, 3.321320764371194e-05], [765, 3.3076288673328236e-05], [766, 3.293931149528362e-05], [767, 3.280398595961742e-05], [768, 3.266927524236962e-05], [769, 3.253450631746091e-05], [770, 3.2400690542999655e-05], [771, 3.226681292289868e-05], [772, 3.213490344933234e-05], [773, 3.200292485416867e-05], [774, 3.1871895771473646e-05], [775, 3.174079392920248e-05], [776, 3.161130371154286e-05], [777, 3.14817443722859e-05], [778, 3.135311999358237e-05], [779, 3.12244264932815e-05], [780, 3.109666067757644e-05], [781, 3.096915679634549e-05], [782, 3.084390118601732e-05], [783, 3.0717579647898674e-05], [784, 3.059184382436797e-05], [785, 3.0467354008578695e-05], [786, 3.0344102924573235e-05], [787, 3.022012060682755e-05], [788, 3.009671672771219e-05], [789, 2.9974871722515672e-05], [790, 2.9853274099878035e-05], [791, 2.9731598260696046e-05], [792, 2.9611142963403836e-05], [793, 2.9491580789908767e-05], [794, 2.9371936761890538e-05], [795, 2.925253465946298e-05], [796, 2.9134342184988782e-05], [797, 2.9016069674980827e-05], [798, 2.8899317840114236e-05], [799, 2.878152190533001e-05], [800, 2.866588329197839e-05], [801, 2.8549839043989778e-05], [802, 2.84352991002379e-05], [803, 2.8320357159827836e-05], [804, 2.8205964554217644e-05], [805, 2.8092435968574136e-05], [806, 2.7979136575595476e-05], [807, 2.7867323296959512e-05], [808, 2.7754791517509148e-05], [809, 2.7643116482067853e-05], [810, 2.753228909568861e-05], [811, 2.7422311177360825e-05], [812, 2.731224049057346e-05], [813, 2.7203013814869337e-05], [814, 2.7093694370705634e-05], [815, 2.6984596843249165e-05], [816, 2.6876643460127525e-05], [817, 2.6769524993142113e-05], [818, 2.666292857611552e-05], [819, 2.6555624572210945e-05], [820, 2.645006861712318e-05], [821, 2.634441443660762e-05], [822, 2.6238667487632483e-05], [823, 2.613435390230734e-05], [824, 2.6030855224234983e-05], [825, 2.5926650778274052e-05], [826, 2.5823263058555312e-05], [827, 2.572098674136214e-05], [828, 2.561770634201821e-05], [829, 2.5516441382933408e-05], [830, 2.5415078198420815e-05], [831, 2.531451355025638e-05], [832, 2.5213852495653555e-05], [833, 2.5113387891906314e-05], [834, 2.5013720005517825e-05], [835, 2.491544364602305e-05], [836, 2.481676528987009e-05], [837, 2.4718874556128867e-05], [838, 2.462058728269767e-05], [839, 2.45230839936994e-05], [840, 2.442636468913406e-05], [841, 2.4329838197445497e-05], [842, 2.4233793737948872e-05], [843, 2.413823312963359e-05], [844, 2.4043445591814816e-05], [845, 2.3948552552610636e-05], [846, 2.3854137907619588e-05], [847, 2.3759910618537106e-05], [848, 2.3667029381613247e-05], [849, 2.3573462385684252e-05], [850, 2.348036832700018e-05], [851, 2.338774902455043e-05], [852, 2.3296172003028914e-05], [853, 2.3204778699437156e-05], [854, 2.3113561837817542e-05], [855, 2.3023098037810996e-05], [856, 2.293338366143871e-05], [857, 2.2843274564365856e-05], [858, 2.2753909433959052e-05], [859, 2.266472074552439e-05], [860, 2.2576556148123927e-05], [861, 2.2488562535727397e-05], [862, 2.2399895897251554e-05], [863, 2.2313093722914346e-05], [864, 2.2225334760150872e-05], [865, 2.213831066910643e-05], [866, 2.2052015992812812e-05], [867, 2.1965890482533723e-05], [868, 2.1879934138269164e-05], [869, 2.1795260181534104e-05], [870, 2.171074811485596e-05], [871, 2.162640157621354e-05], [872, 2.154222056560684e-05], [873, 2.1457923139678314e-05], [874, 2.1374622519942932e-05], [875, 2.1291756638674997e-05], [876, 2.1208777980064042e-05], [877, 2.1127054424141534e-05], [878, 2.1044945242465474e-05], [879, 2.0962994312867522e-05], [880, 2.0881747332168743e-05], [881, 2.0800931451958604e-05], [882, 2.072027200483717e-05], [883, 2.0640311049646698e-05], [884, 2.0560504708555527e-05], [885, 2.0480851162574254e-05], [886, 2.0401892470545135e-05], [887, 2.0323086573625915e-05], [888, 2.0243895050953142e-05], [889, 2.016619691858068e-05], [890, 2.0088382370886393e-05], [891, 2.0011249944218434e-05], [892, 1.993373552977573e-05], [893, 1.9857166989822872e-05], [894, 1.9780214643105865e-05], [895, 1.9704471924342215e-05], [896, 1.962860915227793e-05], [897, 1.955315747181885e-05], [898, 1.9477849491522647e-05], [899, 1.9403212718316354e-05], [900, 1.9328717826283537e-05], [901, 1.9254368453403004e-05], [902, 1.9180684830644168e-05], [903, 1.910766150103882e-05], [904, 1.903425800264813e-05], [905, 1.8960477973450907e-05], [906, 1.8888393242377788e-05], [907, 1.881593016150873e-05], [908, 1.874309054983314e-05], [909, 1.8672453734325245e-05], [910, 1.8600918338051997e-05], [911, 1.852952118497342e-05], [912, 1.845928818511311e-05], [913, 1.838867501646746e-05], [914, 1.8317941794521175e-05], [915, 1.8248365449835546e-05], [916, 1.8178157915826887e-05], [917, 1.8109607481164858e-05], [918, 1.804017483664211e-05], [919, 1.7971380657400005e-05], [920, 1.7903472325997427e-05], [921, 1.7834689060691744e-05], [922, 1.7767291865311563e-05], [923, 1.769951995811425e-05], [924, 1.7631879018153995e-05], [925, 1.7564867448527366e-05], [926, 1.7497983208158985e-05], [927, 1.743247230479028e-05], [928, 1.7365591702400707e-05], [929, 1.7299584214924835e-05], [930, 1.7234198821824975e-05], [931, 1.7168935301015154e-05], [932, 1.7103795471484773e-05], [933, 1.7038781152223237e-05], [934, 1.6974379832390696e-05], [935, 1.6910100384848192e-05], [936, 1.6846188373165205e-05], [937, 1.6782398233772255e-05], [938, 1.671848258411046e-05], [939, 1.6655663785059005e-05], [940, 1.65936926350696e-05], [941, 1.6530380889889784e-05], [942, 1.6467918612761423e-05], [943, 1.6405812857556157e-05], [944, 1.634382533666212e-05], [945, 1.6282196156680584e-05], [946, 1.6220683392020874e-05], [947, 1.6159765436896123e-05], [948, 1.60989638970932e-05], [949, 1.6038275134633295e-05], [950, 1.5977941075107083e-05], [951, 1.591795626154635e-05], [952, 1.5858086044318043e-05], [953, 1.579809031682089e-05], [954, 1.5738682122901082e-05], [955, 1.5679857824579813e-05], [956, 1.56209080159897e-05], [957, 1.5562303815386258e-05], [958, 1.5503810573136434e-05], [959, 1.544566111988388e-05], [960, 1.5387622624984942e-05], [961, 1.533039176138118e-05], [962, 1.5272335076588206e-05], [963, 1.5215320672723465e-05], [964, 1.5158643691393081e-05], [965, 1.5101608369150199e-05], [966, 1.504514420958003e-05], [967, 1.4989478586358018e-05], [968, 1.4933222701074556e-05], [969, 1.4877534340484999e-05], [970, 1.4821491276961751e-05], [971, 1.4766011190658901e-05], [972, 1.4711092262587044e-05], [973, 1.465673358325148e-05], [974, 1.460133535147179e-05], [975, 1.454649736842839e-05], [976, 1.4492896298179403e-05], [977, 1.4438941434491426e-05], [978, 1.4385086615220644e-05], [979, 1.433133365935646e-05], [980, 1.4278130947786849e-05], [981, 1.4225027371139731e-05], [982, 1.417247131030308e-05], [983, 1.4119341358309612e-05], [984, 1.4067428310227115e-05], [985, 1.4014493899594527e-05], [986, 1.3962774573883507e-05], [987, 1.3911150745116174e-05], [988, 1.385895666317083e-05], [989, 1.3807747563987505e-05], [990, 1.3756852240476292e-05], [991, 1.3705390301765874e-05], [992, 1.365490516036516e-05], [993, 1.3603853403765243e-05], [994, 1.3553777534980327e-05], [995, 1.3503353329724632e-05], [996, 1.3453461178869475e-05], [997, 1.3403660886979196e-05], [998, 1.3354170732782222e-05], [999, 1.3304555068316404e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcel/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1/2\n",
      "... correct: 1\n",
      "\n",
      "average test loss: 1.3255248177301837e-05, relative correct: 1.0\n",
      "\n",
      "confusion:\n",
      "[[1.0, 1], [1.0, 1]]\n",
      "... done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# debug set\n",
    "net_full = Lin_Net(8, 1, 64, act_function)\n",
    "train_loader_debug, test_loader_debug = make_data(emotion_dataset, \"full\", batch_size, True)\n",
    "train(train_loader_debug, net_full, 1000, criterion, 100, \"../logs/mse_debug\", cuda, 0.1)\n",
    "test(test_loader_debug, net_full, criterion, 100, \"../logs/mse_debug\", cuda)\n",
    "\n",
    "print(\"... done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------- net_lin_emotion_full\")\n",
    "net_full = Lin_Net(8, 1, 64, act_function)\n",
    "train_loader_emotion_full, test_loader_emotion_full = make_data(emotion_dataset, \"full\", batch_size)\n",
    "train(train_loader_emotion_full, net_full, 100, criterion, 5000, \"../logs/mse_emotion_full\", cuda, 0.1)\n",
    "test(test_loader_emotion_full, net_full, criterion, 1000, \"../logs/mse_emotion_full\")\n",
    "\n",
    "print(\"-------- net_lin_emotion_nolex\")\n",
    "net_half = Lin_Net(4, 1, 64, act_function)\n",
    "train_loader_emotion_nolex, test_loader_emotion_nolex = make_data(emotion_dataset, \"nolex\", batch_size)\n",
    "train(train_loader_emotion_nolex, net_half, 100, criterion, 5000, \"../logs/mse_emotion_nolex\", cuda, 0.1)\n",
    "test(test_loader_emotion_nolex, net_half, criterion, 1000, \"../logs/mse_emotion_nolex\")\n",
    "\n",
    "print(\"-------- net_lin_emotion_lex\")\n",
    "net_half = Lin_Net(4, 1, 64, act_function)\n",
    "train_loader_emotion_lex, test_loader_emotion_lex = make_data(emotion_dataset, \"lex\", batch_size)\n",
    "train(train_loader_emotion_lex, net_half, 100, criterion, 5000, \"../logs/mse_emotion_lex\", cuda, 0.1)\n",
    "test(test_loader_emotion_lex, net_half, criterion, 1000, \"../logs/mse_emotion_lex\")\n",
    "\n",
    "print(\"-------- net_lin_tweet_full\")\n",
    "net_full = Lin_Net(8, 1, 64, act_function)\n",
    "train_loader_tweet_full, test_loader_tweet_full = make_data(tweet_dataset, \"full\", batch_size)\n",
    "train(train_loader_tweet_full, net_full, 100, criterion, 5000, \"../logs/mse_tweet_full\", cuda, 0.1)\n",
    "test(test_loader_tweet_full, net_full, criterion, 1000, \"../logs/mse_tweet_full\")\n",
    "\n",
    "print(\"-------- net_lin_tweet_nolex\")\n",
    "net_half = Lin_Net(4, 1, 64, act_function)\n",
    "train_loader_tweet_nolex, test_loader_tweet_nolex = make_data(tweet_dataset, \"nolex\", batch_size)\n",
    "train(train_loader_tweet_nolex, net_half, 100, criterion, 5000, \"../logs/mse_tweet_nolex\", cuda, 0.1)\n",
    "test(test_loader_tweet_nolex, net_half, criterion, 1000, \"../logs/mse_tweet_nolex\")\n",
    "\n",
    "print(\"-------- net_lin_tweet_lex\")\n",
    "net_half = Lin_Net(4, 1, 64, act_function)\n",
    "train_loader_tweet_lex, test_loader_tweet_lex = make_data(tweet_dataset, \"lex\", batch_size)\n",
    "train(train_loader_tweet_lex, net_half, 100, criterion, 5000, \"../logs/mse_tweet_lex\", cuda, 0.1)\n",
    "test(test_loader_tweet_lex, net_half, criterion, 1000, \"../logs/mse_tweet_lex\")\n",
    "\n",
    "print(\"... done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
