{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin_Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, act_function):\n",
    "        super(Lin_Net, self).__init__()\n",
    "        self.act_function = act_function\n",
    "        \n",
    "        self.lin1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.lin3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # act_funtion = F.sigmoid oder F.relu\n",
    "        x = self.act_function(self.lin1(x))\n",
    "        x = self.act_function(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(D.Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = torch.from_numpy(x_tensor)\n",
    "        self.y = torch.from_numpy(y_tensor)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(dataset, features, batch_size, debug=False):\n",
    "    datasets = []\n",
    "    for file in dataset:\n",
    "        datasets.append(pd.read_csv(\"../\" + file))\n",
    "    dataset = pd.concat(datasets, axis=0, ignore_index=True)\n",
    "    \n",
    "    target = dataset[\"affect\"]\n",
    "    dataset_full = dataset[[\"word_count\", \"upper_word_count\", \"ent_word_count\", \"h_count\", \"s_count\", \"a_count\", \"f_count\", \"cons_punct_count\"]]\n",
    "    dataset_nolex = dataset[[\"word_count\", \"upper_word_count\", \"ent_word_count\", \"cons_punct_count\"]]\n",
    "    dataset_lex = dataset[[\"h_count\", \"s_count\", \"a_count\", \"f_count\"]]\n",
    "    \n",
    "    # make train and test sets\n",
    "    if features == \"full\": \n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_full, target, test_size=0.2)\n",
    "    elif features == \"nolex\":\n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_nolex, target, test_size=0.2)\n",
    "    elif features == \"lex\": \n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_lex, target, test_size=0.2)\n",
    "\n",
    "    # make data loaders\n",
    "    train_data = MyDataset(train_x.to_numpy(), train_y.to_numpy())\n",
    "    test_data = MyDataset(test_x.to_numpy(), test_y.to_numpy())\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    \n",
    "    if debug: \n",
    "        dataset_full = dataset_full.iloc[:256]\n",
    "        target = target[:256]\n",
    "        train_x, test_x, train_y, test_y = train_test_split(dataset_full, target, test_size=0.8)\n",
    "        train_data = MyDataset(train_x.to_numpy(), train_y.to_numpy())\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "        test_loader = DataLoader(dataset=train_data, batch_size=1)\n",
    "    return train_loader, test_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(summary, file):\n",
    "    log = open(file, \"a\")\n",
    "    log.write(summary)\n",
    "    log.close()\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, epochs, criterion, print_every, save_name, cuda, lr):\n",
    "    open(\"../logs/\" + save_name + \"_train\", \"w\").close()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.5)\n",
    "    error_curve = []\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        for index, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.float(), targets.float()\n",
    "            print(type(targets), targets.shape)\n",
    "            print(targets)\n",
    "            print(type(inputs), inputs.shape)\n",
    "            print(inputs)\n",
    "            if cuda: \n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "                net = net.cuda()\n",
    "            pred = net(inputs)    \n",
    "            loss = criterion(pred, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if (epoch % print_every == 0):\n",
    "            log(\"epoch {}/{} \\n... loss: {}\\n\".format((epoch), epochs, loss.item()), \n",
    "                \"../logs/\" + save_name + \"_train\")\n",
    "            torch.save(net.state_dict(), \"nets/\" + save_name + str(epoch) + \".pt\")  \n",
    "            error_curve.append([epoch, loss.item()])\n",
    "    log(\"\\n\" + str(error_curve), \"../logs/\" + save_name + \"_train\")\n",
    "    plt.clf()\n",
    "    plt.plot([item[0] for item in error_curve], [item[1] for item in error_curve])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.savefig(\"../img/\" + save_name+\"_train_error.png\")\n",
    "\n",
    "def test(test_loader, net, criterion, print_every, save_name, cuda):\n",
    "    open(save_name + \"_test\", \"w\").close()\n",
    "    confusion = []\n",
    "    net.eval()\n",
    "    loss_sum, correct, correct2 = 0, 0, 0\n",
    "    for index, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        \n",
    "        if cuda: \n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            net = net.cuda()\n",
    "        pred = net(inputs)\n",
    "        pred_class = round(pred.item())\n",
    "        loss_sum += criterion(pred, targets).item()\n",
    "        confusion.append([targets.item(), pred_class])\n",
    "        \n",
    "        # correct? \n",
    "        if pred_class == targets.item():\n",
    "            correct += 1\n",
    "        \n",
    "        if ((index) % print_every == 0):\n",
    "            log(\"batch: {}/{}\\n... correct: {}\\n\".\n",
    "                format((index), len(test_loader), correct), \n",
    "                save_name + \"_test\")\n",
    "           \n",
    "    # give end report\n",
    "    log(\"average test loss: {}, relative correct: {}\\n\\nconfusion:\\n{}\".\n",
    "        format((loss_sum / len(test_loader)), (correct / len(test_loader)),str(confusion)), \n",
    "        save_name + \"_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating variables\n"
     ]
    }
   ],
   "source": [
    "# create variables \n",
    "print(\"creating variables\")\n",
    "emotion_dataset = [\"emotion_classification_1_clean.csv\", \"emotion_classification_2_clean.csv\", \"emotion_classification_3_clean.csv\", \"emotion_classification_4_clean.csv\", \"emotion_classification_5_clean.csv\", \"emotion_classification_6_clean.csv\", \"emotion_classification_7_clean.csv\", \"emotion_classification_8_clean.csv\"]\n",
    "tweet_dataset = [\"crowdflower_clean.csv\", \"emoint_clean.csv\", \"tec_clean.csv\"]\n",
    "act_function = torch.sigmoid\n",
    "criterion = nn.MSELoss()\n",
    "cuda = torch.cuda.is_available()\n",
    "batch_size = 64\n",
    "epochs = 201\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([51])\n",
      "tensor([2., 3., 1., 2., 3., 1., 1., 1., 3., 0., 3., 1., 3., 0., 0., 0., 0., 3.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 3., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 3., 1., 1., 3., 0., 1., 0., 0.])\n",
      "<class 'torch.Tensor'> torch.Size([51, 8])\n",
      "tensor([[3.3000e+01, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [5.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [5.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [5.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [4.7000e+01, 0.0000e+00, 0.0000e+00, 1.3500e-01, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [3.4000e+01, 0.0000e+00, 0.0000e+00, 1.4000e-02, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.1000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00,\n",
      "         1.4000e-02, 0.0000e+00],\n",
      "        [1.4000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4000e-02, 0.0000e+00],\n",
      "        [1.4000e+01, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.2000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.7000e+01, 0.0000e+00, 5.9000e-02, 1.4000e-02, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.8000e+01, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         1.4000e-02, 0.0000e+00],\n",
      "        [1.0000e+01, 0.0000e+00, 1.0000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.8000e+01, 0.0000e+00, 1.1100e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4000e-02, 0.0000e+00],\n",
      "        [6.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [6.0000e+00, 0.0000e+00, 0.0000e+00, 2.7000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [7.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [9.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.4000e+01, 0.0000e+00, 4.2000e-02, 1.4000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.9000e+01, 0.0000e+00, 0.0000e+00, 2.7000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         1.4000e-02, 0.0000e+00],\n",
      "        [1.3000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [4.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [4.1000e+01, 0.0000e+00, 0.0000e+00, 2.7000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.5000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+01, 0.0000e+00, 1.0000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [4.7000e+01, 0.0000e+00, 0.0000e+00, 4.1000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [8.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [3.3000e+01, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.5000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00,\n",
      "         1.4000e-02, 0.0000e+00],\n",
      "        [2.9000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+01, 0.0000e+00, 0.0000e+00, 1.4000e-02, 5.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.6000e+01, 0.0000e+00, 0.0000e+00, 2.7000e-02, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [8.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [9.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.3000e+01, 0.0000e+00, 0.0000e+00, 2.7000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [3.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.7000e-02, 0.0000e+00],\n",
      "        [7.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.5000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4000e-02, 0.0000e+00],\n",
      "        [2.8000e+01, 0.0000e+00, 1.0700e-01, 1.4000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.3000e+01, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.3000e+01, 0.0000e+00, 0.0000e+00, 2.7000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         2.7000e-02, 0.0000e+00],\n",
      "        [1.4000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.1000e+01, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.4000e+01, 0.0000e+00, 0.0000e+00, 1.4000e-02, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.3000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.9000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7000e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.4000e+01, 0.0000e+00, 0.0000e+00, 4.1000e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [7.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]])\n",
      "epoch 0/201 \n",
      "... loss: 2.1424717903137207\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nets/mse_debug0.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4e41e130c458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLin_Net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader_debug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader_debug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"full\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_debug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mse_debug\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#test(test_loader_debug, net_full, criterion, epochs, \"mse_debug\", cuda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-06363b74b5a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, net, epochs, criterion, print_every, save_name, cuda, lr)\u001b[0m\n\u001b[1;32m     23\u001b[0m             log(\"epoch {}/{} \\n... loss: {}\\n\".format((epoch), epochs, loss.item()), \n\u001b[1;32m     24\u001b[0m                 \"../logs/\" + save_name + \"_train\")\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nets/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msave_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0merror_curve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_curve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../logs/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msave_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nets/mse_debug0.pt'"
     ]
    }
   ],
   "source": [
    "# debug set\n",
    "net_full = Lin_Net(8, 1, 64, act_function)\n",
    "train_loader_debug, test_loader_debug = make_data(emotion_dataset, \"full\", batch_size, True)\n",
    "train(train_loader_debug, net_full, epochs, criterion, print_every, \"mse_debug\", cuda, 0.1)\n",
    "#test(test_loader_debug, net_full, criterion, epochs, \"mse_debug\", cuda)\n",
    "\n",
    "print(\"... done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------- net_lin_emotion_full\")\n",
    "#net_full = Lin_Net(8, 1, 64, act_function)\n",
    "#train_loader_emotion_full, test_loader_emotion_full = make_data(emotion_dataset, \"full\", batch_size)\n",
    "#train(train_loader_emotion_full, net_full, print_every, criterion, epochs, \"mse_emotion_full\", cuda, 0.1)\n",
    "#test(test_loader_emotion_full, net_full, criterion, print_every0, \"mse_emotion_full\")\n",
    "\n",
    "print(\"-------- net_lin_emotion_nolex\")\n",
    "#net_half = Lin_Net(4, 1, 64, act_function)\n",
    "#train_loader_emotion_nolex, test_loader_emotion_nolex = make_data(emotion_dataset, \"nolex\", batch_size)\n",
    "#train(train_loader_emotion_nolex, net_half, print_every, criterion, epochs, \"mse_emotion_nolex\", cuda, 0.1)\n",
    "#test(test_loader_emotion_nolex, net_half, criterion, print_every0, \"mse_emotion_nolex\")\n",
    "\n",
    "print(\"-------- net_lin_emotion_lex\")\n",
    "#net_half = Lin_Net(4, 1, 64, act_function)\n",
    "#train_loader_emotion_lex, test_loader_emotion_lex = make_data(emotion_dataset, \"lex\", batch_size)\n",
    "#train(train_loader_emotion_lex, net_half, print_every, criterion, epochs, \"mse_emotion_lex\", cuda, 0.1)\n",
    "#test(test_loader_emotion_lex, net_half, criterion, print_every0, \"mse_emotion_lex\")\n",
    "\n",
    "print(\"-------- net_lin_tweet_full\")\n",
    "#net_full = Lin_Net(8, 1, 64, act_function)\n",
    "#train_loader_tweet_full, test_loader_tweet_full = make_data(tweet_dataset, \"full\", batch_size)\n",
    "#train(train_loader_tweet_full, net_full, print_every, criterion, epochs, \"mse_tweet_full\", cuda, 0.1)\n",
    "#test(test_loader_tweet_full, net_full, criterion, print_every0, \"mse_tweet_full\")\n",
    "\n",
    "print(\"-------- net_lin_tweet_nolex\")\n",
    "#net_half = Lin_Net(4, 1, 64, act_function)\n",
    "#train_loader_tweet_nolex, test_loader_tweet_nolex = make_data(tweet_dataset, \"nolex\", batch_size)\n",
    "#train(train_loader_tweet_nolex, net_half, print_every, criterion, epochs, \"mse_tweet_nolex\", cuda, 0.1)\n",
    "#test(test_loader_tweet_nolex, net_half, criterion, print_every0, \"mse_tweet_nolex\")\n",
    "\n",
    "print(\"-------- net_lin_tweet_lex\")\n",
    "#net_half = Lin_Net(4, 1, 64, act_function)\n",
    "#train_loader_tweet_lex, test_loader_tweet_lex = make_data(tweet_dataset, \"lex\", batch_size)\n",
    "#train(train_loader_tweet_lex, net_half, print_every, criterion, epochs, \"mse_tweet_lex\", cuda, 0.1)\n",
    "#test(test_loader_tweet_lex, net_half, criterion, print_every0, \"mse_tweet_lex\")\n",
    "\n",
    "print(\"... done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
